{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 50 CPUs with lowest load: [7, 6, 3, 5, 4, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_cpu_load():\n",
    "    # Get CPU usage for each core\n",
    "    cpu_loads = psutil.cpu_percent(interval=1, percpu=True)\n",
    "    return cpu_loads\n",
    "\n",
    "def select_k_cpus_with_lowest_load(k):\n",
    "    # Get CPU usage for each core\n",
    "    cpu_loads = get_cpu_load()\n",
    "    \n",
    "    # Create a list of tuples (core_id, load)\n",
    "    cpu_load_tuples = list(enumerate(cpu_loads))\n",
    "    \n",
    "    # Sort the list based on load\n",
    "    sorted_cpu_loads = sorted(cpu_load_tuples, key=lambda x: x[1])\n",
    "    \n",
    "    # Get the IDs of the K cores with lowest load\n",
    "    selected_cpus = [core[0] for core in sorted_cpu_loads[:k]]\n",
    "    \n",
    "    return selected_cpus\n",
    "\n",
    "# Example usage\n",
    "k = 50  # Number of CPUs with lowest load\n",
    "selected_cpus = select_k_cpus_with_lowest_load(k)\n",
    "print(f\"Selected {k} CPUs with lowest load:\", selected_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Process' object has no attribute 'cpu_affinity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Set the CPU affinity to only CPU core 0\u001b[39;00m\n\u001b[1;32m     18\u001b[0m cpu_list \u001b[38;5;241m=\u001b[39m selected_cpus\n\u001b[0;32m---> 19\u001b[0m \u001b[43mset_cpu_affinity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpu_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[163], line 7\u001b[0m, in \u001b[0;36mset_cpu_affinity\u001b[0;34m(pid, cpu_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     p \u001b[38;5;241m=\u001b[39m psutil\u001b[38;5;241m.\u001b[39mProcess(pid)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_affinity\u001b[49m(cpu_list)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU affinity for process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m set to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcpu_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m psutil\u001b[38;5;241m.\u001b[39mNoSuchProcess:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Process' object has no attribute 'cpu_affinity'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "def set_cpu_affinity(pid, cpu_list):\n",
    "    try:\n",
    "        p = psutil.Process(pid)\n",
    "        p.cpu_affinity(cpu_list)\n",
    "        print(f\"CPU affinity for process {pid} set to: {cpu_list}\")\n",
    "    except psutil.NoSuchProcess:\n",
    "        print(f\"Process with PID {pid} does not exist.\")\n",
    "    except psutil.AccessDenied:\n",
    "        print(\"Permission denied. You may need sudo privileges to set CPU affinity.\")\n",
    "\n",
    "# Get the process ID of the current process\n",
    "pid = os.getpid()\n",
    "\n",
    "# Set the CPU affinity to only CPU core 0\n",
    "cpu_list = selected_cpus\n",
    "set_cpu_affinity(pid, cpu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class ResNet20Cifar100(tf.keras.Model):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(ResNet20Cifar100, self).__init__()\n",
    "\n",
    "        # Initial Conv Layer\n",
    "        self.conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "\n",
    "        # Layer 1 Block 1\n",
    "        self.layer1_0_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_0_bn1 = layers.BatchNormalization()\n",
    "        self.layer1_0_relu1 = layers.ReLU()\n",
    "        self.layer1_0_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_0_bn2 = layers.BatchNormalization()\n",
    "        self.layer1_0_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 1 Block 2\n",
    "        self.layer1_1_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_1_bn1 = layers.BatchNormalization()\n",
    "        self.layer1_1_relu1 = layers.ReLU()\n",
    "        self.layer1_1_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_1_bn2 = layers.BatchNormalization()\n",
    "        self.layer1_1_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 1 Block 3\n",
    "        self.layer1_2_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_2_bn1 = layers.BatchNormalization()\n",
    "        self.layer1_2_relu1 = layers.ReLU()\n",
    "        self.layer1_2_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_2_bn2 = layers.BatchNormalization()\n",
    "        self.layer1_2_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 2 Block 1 (with downsampling)\n",
    "        self.layer2_0_conv1 = layers.Conv2D(32, kernel_size=3, strides=2, padding='same', use_bias=False)\n",
    "        self.layer2_0_bn1 = layers.BatchNormalization()\n",
    "        self.layer2_0_relu1 = layers.ReLU()\n",
    "        self.layer2_0_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_0_bn2 = layers.BatchNormalization()\n",
    "        self.layer2_0_relu2 = layers.ReLU()\n",
    "        self.layer2_0_downsample = models.Sequential([\n",
    "            layers.Conv2D(32, kernel_size=1, strides=2, use_bias=False),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "\n",
    "        # Layer 2 Block 2\n",
    "        self.layer2_1_conv1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_1_bn1 = layers.BatchNormalization()\n",
    "        self.layer2_1_relu1 = layers.ReLU()\n",
    "        self.layer2_1_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_1_bn2 = layers.BatchNormalization()\n",
    "        self.layer2_1_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 2 Block 3\n",
    "        self.layer2_2_conv1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_2_bn1 = layers.BatchNormalization()\n",
    "        self.layer2_2_relu1 = layers.ReLU()\n",
    "        self.layer2_2_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_2_bn2 = layers.BatchNormalization()\n",
    "        self.layer2_2_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 3 Block 1 (with downsampling)\n",
    "        self.layer3_0_conv1 = layers.Conv2D(64, kernel_size=3, strides=2, padding='same', use_bias=False)\n",
    "        self.layer3_0_bn1 = layers.BatchNormalization()\n",
    "        self.layer3_0_relu1 = layers.ReLU()\n",
    "        self.layer3_0_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_0_bn2 = layers.BatchNormalization()\n",
    "        self.layer3_0_downsample = models.Sequential([\n",
    "            layers.Conv2D(64, kernel_size=1, strides=2, use_bias=False),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "        self.layer3_0_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 3 Block 2\n",
    "        self.layer3_1_conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_1_bn1 = layers.BatchNormalization()\n",
    "        self.layer3_1_relu1 = layers.ReLU()\n",
    "        self.layer3_1_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_1_bn2 = layers.BatchNormalization()\n",
    "        self.layer3_1_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 3 Block 3\n",
    "        self.layer3_2_conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_2_bn1 = layers.BatchNormalization()\n",
    "        self.layer3_2_relu1 = layers.ReLU()\n",
    "        self.layer3_2_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_2_bn2 = layers.BatchNormalization()\n",
    "        self.layer3_2_relu2 = layers.ReLU()\n",
    "\n",
    "        # Pooling and classification layers\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # Initial layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        # Layer 1 Block 1\n",
    "        residual = x\n",
    "        x = self.layer1_0_conv1(x)\n",
    "        x = self.layer1_0_bn1(x, training=training)\n",
    "        x = self.layer1_0_relu1(x)\n",
    "        x = self.layer1_0_conv2(x)\n",
    "        x = self.layer1_0_bn2(x, training=training)\n",
    "        x += residual  # Add operation\n",
    "        x = self.layer1_0_relu2(x)\n",
    "\n",
    "        # Layer 1 Block 2\n",
    "        residual = x\n",
    "        x = self.layer1_1_conv1(x)\n",
    "        x = self.layer1_1_bn1(x, training=training)\n",
    "        x = self.layer1_1_relu1(x)\n",
    "        x = self.layer1_1_conv2(x)\n",
    "        x = self.layer1_1_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer1_1_relu2(x)\n",
    "\n",
    "        # Layer 1 Block 3\n",
    "        residual = x\n",
    "        x = self.layer1_2_conv1(x)\n",
    "        x = self.layer1_2_bn1(x, training=training)\n",
    "        x = self.layer1_2_relu1(x)\n",
    "        x = self.layer1_2_conv2(x)\n",
    "        x = self.layer1_2_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer1_2_relu2(x)\n",
    "\n",
    "        # Layer 2 Block 1 (with downsampling)\n",
    "        residual = self.layer2_0_downsample(x, training=training)\n",
    "        x = self.layer2_0_conv1(x)\n",
    "        x = self.layer2_0_bn1(x, training=training)\n",
    "        x = self.layer2_0_relu1(x)\n",
    "        x = self.layer2_0_conv2(x)\n",
    "        x = self.layer2_0_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer2_0_relu2(x)\n",
    "\n",
    "        # Layer 2 Block 2\n",
    "        residual = x\n",
    "        x = self.layer2_1_conv1(x)\n",
    "        x = self.layer2_1_bn1(x, training=training)\n",
    "        x = self.layer2_1_relu1(x)\n",
    "        x = self.layer2_1_conv2(x)\n",
    "        x = self.layer2_1_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer2_1_relu2(x)\n",
    "\n",
    "        # Layer 2 Block 3\n",
    "        residual = x\n",
    "        x = self.layer2_2_conv1(x)\n",
    "        x = self.layer2_2_bn1(x, training=training)\n",
    "        x = self.layer2_2_relu1(x)\n",
    "        x = self.layer2_2_conv2(x)\n",
    "        x = self.layer2_2_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer2_2_relu2(x)\n",
    "\n",
    "        # Layer 3 Block 1 (with downsampling)\n",
    "        residual = self.layer3_0_downsample(x, training=training)\n",
    "        x = self.layer3_0_conv1(x)\n",
    "        x = self.layer3_0_bn1(x, training=training)\n",
    "        x = self.layer3_0_relu1(x)\n",
    "        x = self.layer3_0_conv2(x)\n",
    "        x = self.layer3_0_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer3_0_relu2(x)\n",
    "\n",
    "        # Layer 3 Block 2\n",
    "        residual = x\n",
    "        x = self.layer3_1_conv1(x)\n",
    "        x = self.layer3_1_bn1(x, training=training)\n",
    "        x = self.layer3_1_relu1(x)\n",
    "        x = self.layer3_1_conv2(x)\n",
    "        x = self.layer3_1_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer3_1_relu2(x)\n",
    "\n",
    "        # Layer 3 Block 3\n",
    "        residual = x\n",
    "        x = self.layer3_2_conv1(x)\n",
    "        x = self.layer3_2_bn1(x, training=training)\n",
    "        x = self.layer3_2_relu1(x)\n",
    "        x = self.layer3_2_conv2(x)\n",
    "        x = self.layer3_2_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer3_2_relu2(x)\n",
    "\n",
    "        # Pooling and classification\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 39\n"
     ]
    }
   ],
   "source": [
    "# load onnx file - dense model trained on cifar100 with resnet20 architecture\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnx_path = \"../../models/resnet20/resnet20_cifar100_dense_v2.onnx\"\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# get the input name for the model\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs\n",
    "\n",
    "# load the image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Load the image\n",
    "image = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_np = image.numpy()\n",
    "\n",
    "# Run the model\n",
    "ort_inputs = {input_name: image_np}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = np.argmax(ort_outs[0])\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 3.39998975e-02  2.80818880e-01  2.88518127e-02  2.35133663e-01\n",
      "  -4.50945124e-02  1.41298950e-01 -1.07140519e-01  1.06228121e-01\n",
      "  -2.25494113e-02 -4.96961735e-02 -1.30520046e-01  1.95211321e-01\n",
      "   5.70189469e-02  3.33459675e-01  4.16270867e-02  1.68443292e-01\n",
      "   6.35142326e-02  7.92288557e-02 -7.75319040e-02  9.19887703e-03\n",
      "  -4.10111994e-01  9.74192470e-02 -5.90176396e-02 -2.44346447e-02\n",
      "   3.14892232e-02  6.19500950e-02 -1.99786216e-01 -4.23391163e-03\n",
      "   1.23593517e-01 -1.39187545e-01 -6.95504472e-02 -1.80358306e-01\n",
      "   2.45609701e-01  1.91297814e-01  2.32555121e-01  1.88099518e-01\n",
      "  -2.66738832e-01 -1.17541447e-01  3.29392254e-01 -9.36297178e-02\n",
      "  -1.50422931e-01  1.53820798e-01 -1.72431961e-01 -4.81876507e-02\n",
      "   2.80555695e-01 -7.48685002e-02 -2.74330229e-02  2.48542950e-01\n",
      "  -7.25215897e-02 -1.48755219e-02 -7.08135515e-02 -8.44100788e-02\n",
      "  -9.35274065e-02  1.39584601e-01  1.77368864e-01  1.42620340e-01\n",
      "   7.96907917e-02  2.39593927e-02  1.10571340e-01  7.25339651e-02\n",
      "   1.48904011e-01 -5.92236556e-02  6.45985156e-02  2.81331211e-01\n",
      "   1.50968716e-01  1.67520672e-01  1.77971378e-01 -7.13161007e-02\n",
      "  -5.03839031e-02 -1.20602325e-01  2.53217816e-01  1.01530610e-03\n",
      "   9.15421471e-02 -1.44552618e-01 -4.73388359e-02 -1.71365365e-01\n",
      "  -4.03269269e-02 -4.67101820e-02  6.53717220e-02 -2.35298909e-02\n",
      "  -1.84959337e-01  6.89407513e-02  2.23080933e-01 -1.15440711e-02\n",
      "   2.55621612e-01 -6.30097184e-03 -2.63406157e-01 -4.12895679e-02\n",
      "  -8.22703540e-02  2.00382292e-01  1.81112016e-04  4.52568121e-02\n",
      "  -1.42262757e-01 -2.53655106e-01 -4.46696788e-01 -9.12463516e-02\n",
      "  -1.43699527e-01  7.55182728e-02 -3.90408486e-02  4.24210161e-01]], shape=(1, 100), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to res_net20_cifar100_1_dense_1_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpjirqzjhy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpjirqzjhy/assets\n",
      "INFO:absl:Writing fingerprint to /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpjirqzjhy/fingerprint.pb\n",
      "INFO:absl:Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ResNet20Cifar100(num_classes=100)\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "cifar100 = tf.keras.datasets.cifar100\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Compile the model (necessary for training, but for inference, itâ€™s optional)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Perform inference with a sample image from CIFAR-100\n",
    "sample_image = train_images[0:1]  # Select one sample\n",
    "sample_image = tf.convert_to_tensor(sample_image, dtype=tf.float32)\n",
    "\n",
    "# Ensure the model is in evaluation mode (no training mode needed)\n",
    "predictions = model(sample_image, training=False)  # training=False ensures evaluation mode\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# Convert the model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert() # experimental_new_converter=False\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('../../models/resnet20/resnet20.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net20_cifar100_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          multiple                  432       \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  multiple                  64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_19 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          multiple                  2304      \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  multiple                  64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_20 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          multiple                  2304      \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  multiple                  64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_21 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          multiple                  2304      \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  multiple                  64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_22 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          multiple                  2304      \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  multiple                  64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          multiple                  2304      \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  multiple                  64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_24 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          multiple                  2304      \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  multiple                  64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_25 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          multiple                  4608      \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  multiple                  128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_26 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          multiple                  9216      \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  multiple                  128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_27 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 16, 16, 32)        640       \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          multiple                  9216      \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  multiple                  128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_28 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          multiple                  9216      \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  multiple                  128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_29 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          multiple                  9216      \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  multiple                  128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_30 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          multiple                  9216      \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  multiple                  128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_31 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          multiple                  18432     \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  multiple                  256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_32 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          multiple                  36864     \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  multiple                  256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 8, 8, 64)          2304      \n",
      "                                                                 \n",
      " re_lu_33 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          multiple                  36864     \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  multiple                  256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_34 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          multiple                  36864     \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  multiple                  256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_35 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          multiple                  36864     \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  multiple                  256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_36 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          multiple                  36864     \n",
      "                                                                 \n",
      " batch_normalization_41 (Ba  multiple                  256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " re_lu_37 (ReLU)             multiple                  0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1  multiple                  0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  6500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 279892 (1.07 MB)\n",
      "Trainable params: 278324 (1.06 MB)\n",
      "Non-trainable params: 1568 (6.12 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to .h5 file\n",
    "# model.save_weights(\"resnet20.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 7.npy and forward it to the model\n",
    "import numpy as np\n",
    "data = np.load('7.npy')\n",
    "# reshape data to 4D\n",
    "data = np.reshape(data, (1, 3,32,32))\n",
    "\n",
    "# forward the data to the model\n",
    "data = tf.convert_to_tensor(data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/zkml_bench_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 27, 28, 29, 30}\n",
      "Add inputs:  [29, 27]\n",
      "True True\n",
      "{0, 32, 33, 27, 28, 29, 30, 31}\n",
      "Add inputs:  [32, 30]\n",
      "True True\n",
      "{0, 32, 33, 34, 35, 36, 27, 28, 29, 30, 31}\n",
      "Add inputs:  [35, 33]\n",
      "True True\n",
      "{0, 32, 33, 34, 35, 36, 37, 38, 39, 40, 27, 28, 29, 30, 31}\n",
      "Add inputs:  [38, 39]\n",
      "True True\n",
      "{0, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 27, 28, 29, 30, 31}\n",
      "Add inputs:  [42, 40]\n",
      "True True\n",
      "{0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46}\n",
      "Add inputs:  [45, 43]\n",
      "True True\n",
      "{0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50}\n",
      "Add inputs:  [48, 49]\n",
      "True True\n",
      "{0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53}\n",
      "Add inputs:  [52, 50]\n",
      "True True\n",
      "{0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56}\n",
      "Add inputs:  [55, 53]\n",
      "True True\n",
      "[{'layer_type': 'Conv2D', 'inp_idxes': [0, 4, 1], 'inp_shapes': [[1, 32, 32, 3], [16, 3, 3, 3], [16]], 'out_idxes': [27], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [27, 5, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [28], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [28, 6, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [29], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [29, 27], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [30], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [30, 7, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [31], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [31, 8, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [32], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [32, 30], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [33], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [33, 9, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [34], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [34, 10, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [35], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [35, 33], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [36], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [36, 11, 2], 'inp_shapes': [[1, 32, 32, 16], [32, 3, 3, 16], [32]], 'out_idxes': [37], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [37, 12, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [38], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [36, 13, 2], 'inp_shapes': [[1, 32, 32, 16], [32, 1, 1, 16], [32]], 'out_idxes': [39], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [38, 39], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [40], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [40, 14, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [41], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [41, 15, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [42], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [42, 40], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [43], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [43, 16, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [44], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [44, 17, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [45], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [45, 43], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [46], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [46, 18, 3], 'inp_shapes': [[1, 16, 16, 32], [64, 3, 3, 32], [64]], 'out_idxes': [47], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [47, 19, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [48], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [46, 20, 3], 'inp_shapes': [[1, 16, 16, 32], [64, 1, 1, 32], [64]], 'out_idxes': [49], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [48, 49], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [50], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [50, 21, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [51], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [51, 22, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [52], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [52, 50], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [53], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [53, 23, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [54], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [54, 24, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [55], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [55, 53], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [56], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [56, 25], 'inp_shapes': [[1, 8, 8, 64], [2]], 'out_idxes': [57], 'out_shapes': [[1, 64]], 'params': [1, 2], 'mask': []}, {'layer_type': 'FullyConnected', 'inp_idxes': [57, 26], 'inp_shapes': [[1, 64], [100, 64]], 'out_idxes': [58], 'out_shapes': [[1, 100]], 'params': [0], 'mask': []}]\n",
      "\n",
      "keep tensors: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, -1}\n",
      "skipping generated tensor: 0, b'serving_default_input_1:0'\n",
      "skipping generated tensor: 27, b'res_net20_cifar100_1/re_lu_19/Relu;res_net20_cifar100_1/batch_normalization_21/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_21/Conv2D'\n",
      "skipping generated tensor: 28, b'res_net20_cifar100_1/re_lu_20/Relu;res_net20_cifar100_1/batch_normalization_22/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_22/Conv2D'\n",
      "skipping generated tensor: 29, b'res_net20_cifar100_1/batch_normalization_23/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_23/Conv2D'\n",
      "skipping generated tensor: 30, b'res_net20_cifar100_1/re_lu_21/Relu;res_net20_cifar100_1/add'\n",
      "skipping generated tensor: 31, b'res_net20_cifar100_1/re_lu_22/Relu;res_net20_cifar100_1/batch_normalization_24/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_24/Conv2D'\n",
      "skipping generated tensor: 32, b'res_net20_cifar100_1/batch_normalization_25/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_25/Conv2D'\n",
      "skipping generated tensor: 33, b'res_net20_cifar100_1/re_lu_23/Relu;res_net20_cifar100_1/add_1'\n",
      "skipping generated tensor: 34, b'res_net20_cifar100_1/re_lu_24/Relu;res_net20_cifar100_1/batch_normalization_26/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_26/Conv2D'\n",
      "skipping generated tensor: 35, b'res_net20_cifar100_1/batch_normalization_27/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_21/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_27/Conv2D'\n",
      "skipping generated tensor: 36, b'res_net20_cifar100_1/re_lu_25/Relu;res_net20_cifar100_1/add_2'\n",
      "skipping generated tensor: 37, b'res_net20_cifar100_1/re_lu_26/Relu;res_net20_cifar100_1/batch_normalization_28/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_28/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_28/Conv2D'\n",
      "skipping generated tensor: 38, b'res_net20_cifar100_1/batch_normalization_29/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_28/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_29/Conv2D'\n",
      "skipping generated tensor: 39, b'res_net20_cifar100_1/sequential_2/batch_normalization_30/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_28/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/sequential_2/conv2d_30/Conv2D'\n",
      "skipping generated tensor: 40, b'res_net20_cifar100_1/re_lu_27/Relu;res_net20_cifar100_1/add_3'\n",
      "skipping generated tensor: 41, b'res_net20_cifar100_1/re_lu_28/Relu;res_net20_cifar100_1/batch_normalization_31/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_28/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_31/Conv2D'\n",
      "skipping generated tensor: 42, b'res_net20_cifar100_1/batch_normalization_32/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_28/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_32/Conv2D'\n",
      "skipping generated tensor: 43, b'res_net20_cifar100_1/re_lu_29/Relu;res_net20_cifar100_1/add_4'\n",
      "skipping generated tensor: 44, b'res_net20_cifar100_1/re_lu_30/Relu;res_net20_cifar100_1/batch_normalization_33/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_28/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_33/Conv2D'\n",
      "skipping generated tensor: 45, b'res_net20_cifar100_1/batch_normalization_34/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_28/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_34/Conv2D'\n",
      "skipping generated tensor: 46, b'res_net20_cifar100_1/re_lu_31/Relu;res_net20_cifar100_1/add_5'\n",
      "skipping generated tensor: 47, b'res_net20_cifar100_1/re_lu_32/Relu;res_net20_cifar100_1/batch_normalization_35/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_35/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_35/Conv2D'\n",
      "skipping generated tensor: 48, b'res_net20_cifar100_1/batch_normalization_36/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_35/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_36/Conv2D'\n",
      "skipping generated tensor: 49, b'res_net20_cifar100_1/sequential_3/batch_normalization_37/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_35/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/sequential_3/conv2d_37/Conv2D'\n",
      "skipping generated tensor: 50, b'res_net20_cifar100_1/re_lu_33/Relu;res_net20_cifar100_1/add_6'\n",
      "skipping generated tensor: 51, b'res_net20_cifar100_1/re_lu_34/Relu;res_net20_cifar100_1/batch_normalization_38/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_35/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_38/Conv2D'\n",
      "skipping generated tensor: 52, b'res_net20_cifar100_1/batch_normalization_39/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_35/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_39/Conv2D'\n",
      "skipping generated tensor: 53, b'res_net20_cifar100_1/re_lu_35/Relu;res_net20_cifar100_1/add_7'\n",
      "skipping generated tensor: 54, b'res_net20_cifar100_1/re_lu_36/Relu;res_net20_cifar100_1/batch_normalization_40/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_35/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_40/Conv2D'\n",
      "skipping generated tensor: 55, b'res_net20_cifar100_1/batch_normalization_41/FusedBatchNormV3;res_net20_cifar100_1/batch_normalization_35/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_1/conv2d_41/Conv2D'\n",
      "skipping generated tensor: 56, b'res_net20_cifar100_1/re_lu_37/Relu;res_net20_cifar100_1/add_8'\n",
      "skipping generated tensor: 57, b'res_net20_cifar100_1/global_average_pooling2d_1/Mean'\n",
      "\n",
      "{'layer_type': 'FullyConnected', 'inp_idxes': [57, 26], 'inp_shapes': [[1, 64], [100, 64]], 'out_idxes': [58], 'out_shapes': [[1, 100]], 'params': [0], 'mask': []}\n",
      "dict_keys(['global_sf', 'k', 'num_cols', 'num_random', 'inp_idxes', 'out_idxes', 'layers', 'tensors', 'use_selectors', 'commit_before', 'commit_after'])\n",
      "[58]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/converter.py', '--model', '../../models/resnet20/resnet20.tflite', '--model_output', 'converted_model_new.msgpack', '--config_output', 'config_new.msgpack', '--scale_factor', '4096', '--k', '21', '--num_cols', '128', '--num_randoms', '262144'], returncode=0)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert model\n",
    "# !python ./tools/converter.py --model ./model.tflite --model_output converted_model_new.msgpack --config_output config_new.msgpack --scale_factor 512 --k 20 --num_cols 20 --num_randoms 4096\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/converter.py', \n",
    "    '--model', '../../models/resnet20/resnet20.tflite',\n",
    "    # '--model', '../../models/resnet20/resnet20_cifar100_dense.tflite',\n",
    "    '--model_output', 'converted_model_new.msgpack',\n",
    "    '--config_output', 'config_new.msgpack',\n",
    "    '--scale_factor', '4096',\n",
    "    '--k', '21',\n",
    "    '--num_cols', '128',\n",
    "    # '--num_randoms', '16384'\n",
    "    '--num_randoms', '262144'\n",
    "]\n",
    "\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/input_converter.py', '--model_config', 'converted_model_new.msgpack', '--inputs', '7.npy', '--output', 'example_inp_new.msgpack'], returncode=0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert input\n",
    "import subprocess\n",
    "\n",
    "# !python ./tools/input_converter.py --model_config converted_model_new.msgpack --inputs 7.npy --output example_inp_new.msgpack\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/input_converter.py', \n",
    "    '--model_config', 'converted_model_new.msgpack',\n",
    "    '--inputs', '7.npy',\n",
    "    '--output', 'example_inp_new.msgpack'\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command_dir:  ./bin/m1_mac/\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "command_dir = './bin/m1_mac/' if platform.processor() == \"arm\" else './bin/'\n",
    "print(\"command_dir: \", command_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer 0, type: Conv2D, inp_idxes: [0, 4, 1], out_idxes: [27], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 1, type: Conv2D, inp_idxes: [27, 5, 1], out_idxes: [28], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 2, type: Conv2D, inp_idxes: [28, 6, 1], out_idxes: [29], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 3, type: Add, inp_idxes: [29, 27], out_idxes: [30], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 4, type: Conv2D, inp_idxes: [30, 7, 1], out_idxes: [31], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 5, type: Conv2D, inp_idxes: [31, 8, 1], out_idxes: [32], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 6, type: Add, inp_idxes: [32, 30], out_idxes: [33], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 7, type: Conv2D, inp_idxes: [33, 9, 1], out_idxes: [34], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 8, type: Conv2D, inp_idxes: [34, 10, 1], out_idxes: [35], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 9, type: Add, inp_idxes: [35, 33], out_idxes: [36], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 10, type: Conv2D, inp_idxes: [36, 11, 2], out_idxes: [37], layer_params: [0, 0, 1, 2, 2]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 11, type: Conv2D, inp_idxes: [37, 12, 2], out_idxes: [38], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 12, type: Conv2D, inp_idxes: [36, 13, 2], out_idxes: [39], layer_params: [0, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 13, type: Add, inp_idxes: [38, 39], out_idxes: [40], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 14, type: Conv2D, inp_idxes: [40, 14, 2], out_idxes: [41], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 15, type: Conv2D, inp_idxes: [41, 15, 2], out_idxes: [42], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 16, type: Add, inp_idxes: [42, 40], out_idxes: [43], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 17, type: Conv2D, inp_idxes: [43, 16, 2], out_idxes: [44], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 18, type: Conv2D, inp_idxes: [44, 17, 2], out_idxes: [45], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 19, type: Add, inp_idxes: [45, 43], out_idxes: [46], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 20, type: Conv2D, inp_idxes: [46, 18, 3], out_idxes: [47], layer_params: [0, 0, 1, 2, 2]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 21, type: Conv2D, inp_idxes: [47, 19, 3], out_idxes: [48], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 22, type: Conv2D, inp_idxes: [46, 20, 3], out_idxes: [49], layer_params: [0, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 23, type: Add, inp_idxes: [48, 49], out_idxes: [50], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 24, type: Conv2D, inp_idxes: [50, 21, 3], out_idxes: [51], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 25, type: Conv2D, inp_idxes: [51, 22, 3], out_idxes: [52], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 26, type: Add, inp_idxes: [52, 50], out_idxes: [53], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 27, type: Conv2D, inp_idxes: [53, 23, 3], out_idxes: [54], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 28, type: Conv2D, inp_idxes: [54, 24, 3], out_idxes: [55], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 29, type: Add, inp_idxes: [55, 53], out_idxes: [56], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 30, type: Mean, inp_idxes: [56, 25], out_idxes: [57], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 64]\n",
      "\n",
      "Processing layer 31, type: FullyConnected, inp_idxes: [57, 26], out_idxes: [58], layer_params: [0]\n",
      "Out 0 shape: [1, 100]\n",
      "\n",
      "final out[0] x: 123 (0.030029296875)\n",
      "final out[1] x: 1105 (0.269775390625)\n",
      "final out[2] x: 68 (0.0166015625)\n",
      "final out[3] x: 897 (0.218994140625)\n",
      "final out[4] x: -151 (-0.036865234375)\n",
      "final out[5] x: 481 (0.117431640625)\n",
      "final out[6] x: -542 (-0.13232421875)\n",
      "final out[7] x: 488 (0.119140625)\n",
      "final out[8] x: -146 (-0.03564453125)\n",
      "final out[9] x: -137 (-0.033447265625)\n",
      "final out[10] x: -596 (-0.1455078125)\n",
      "final out[11] x: 785 (0.191650390625)\n",
      "final out[12] x: 310 (0.07568359375)\n",
      "final out[13] x: 1383 (0.337646484375)\n",
      "final out[14] x: 163 (0.039794921875)\n",
      "final out[15] x: 729 (0.177978515625)\n",
      "final out[16] x: 426 (0.10400390625)\n",
      "final out[17] x: 445 (0.108642578125)\n",
      "final out[18] x: -384 (-0.09375)\n",
      "final out[19] x: -40 (-0.009765625)\n",
      "final out[20] x: -1729 (-0.422119140625)\n",
      "final out[21] x: 268 (0.0654296875)\n",
      "final out[22] x: -283 (-0.069091796875)\n",
      "final out[23] x: -151 (-0.036865234375)\n",
      "final out[24] x: 52 (0.0126953125)\n",
      "final out[25] x: 365 (0.089111328125)\n",
      "final out[26] x: -961 (-0.234619140625)\n",
      "final out[27] x: -6 (-0.00146484375)\n",
      "final out[28] x: 542 (0.13232421875)\n",
      "final out[29] x: -617 (-0.150634765625)\n",
      "final out[30] x: -364 (-0.0888671875)\n",
      "final out[31] x: -691 (-0.168701171875)\n",
      "final out[32] x: 1216 (0.296875)\n",
      "final out[33] x: 881 (0.215087890625)\n",
      "final out[34] x: 1095 (0.267333984375)\n",
      "final out[35] x: 714 (0.17431640625)\n",
      "final out[36] x: -1164 (-0.2841796875)\n",
      "final out[37] x: -532 (-0.1298828125)\n",
      "final out[38] x: 1432 (0.349609375)\n",
      "final out[39] x: -429 (-0.104736328125)\n",
      "final out[40] x: -699 (-0.170654296875)\n",
      "final out[41] x: 763 (0.186279296875)\n",
      "final out[42] x: -752 (-0.18359375)\n",
      "final out[43] x: -254 (-0.06201171875)\n",
      "final out[44] x: 1133 (0.276611328125)\n",
      "final out[45] x: -291 (-0.071044921875)\n",
      "final out[46] x: -85 (-0.020751953125)\n",
      "final out[47] x: 1258 (0.30712890625)\n",
      "final out[48] x: -431 (-0.105224609375)\n",
      "final out[49] x: 31 (0.007568359375)\n",
      "final out[50] x: -250 (-0.06103515625)\n",
      "final out[51] x: -472 (-0.115234375)\n",
      "final out[52] x: -367 (-0.089599609375)\n",
      "final out[53] x: 549 (0.134033203125)\n",
      "final out[54] x: 781 (0.190673828125)\n",
      "final out[55] x: 531 (0.129638671875)\n",
      "final out[56] x: 286 (0.06982421875)\n",
      "final out[57] x: 118 (0.02880859375)\n",
      "final out[58] x: 408 (0.099609375)\n",
      "final out[59] x: 306 (0.07470703125)\n",
      "final out[60] x: 530 (0.12939453125)\n",
      "final out[61] x: -316 (-0.0771484375)\n",
      "final out[62] x: 234 (0.05712890625)\n",
      "final out[63] x: 1139 (0.278076171875)\n",
      "final out[64] x: 547 (0.133544921875)\n",
      "final out[65] x: 801 (0.195556640625)\n",
      "final out[66] x: 675 (0.164794921875)\n",
      "final out[67] x: -142 (-0.03466796875)\n",
      "final out[68] x: -237 (-0.057861328125)\n",
      "final out[69] x: -598 (-0.14599609375)\n",
      "final out[70] x: 1094 (0.26708984375)\n",
      "final out[71] x: -160 (-0.0390625)\n",
      "final out[72] x: 547 (0.133544921875)\n",
      "final out[73] x: -600 (-0.146484375)\n",
      "final out[74] x: -179 (-0.043701171875)\n",
      "final out[75] x: -607 (-0.148193359375)\n",
      "final out[76] x: -183 (-0.044677734375)\n",
      "final out[77] x: -100 (-0.0244140625)\n",
      "final out[78] x: 252 (0.0615234375)\n",
      "final out[79] x: 56 (0.013671875)\n",
      "final out[80] x: -802 (-0.19580078125)\n",
      "final out[81] x: 308 (0.0751953125)\n",
      "final out[82] x: 1074 (0.26220703125)\n",
      "final out[83] x: -1 (-0.000244140625)\n",
      "final out[84] x: 1031 (0.251708984375)\n",
      "final out[85] x: -37 (-0.009033203125)\n",
      "final out[86] x: -1120 (-0.2734375)\n",
      "final out[87] x: -348 (-0.0849609375)\n",
      "final out[88] x: -328 (-0.080078125)\n",
      "final out[89] x: 713 (0.174072265625)\n",
      "final out[90] x: 104 (0.025390625)\n",
      "final out[91] x: 332 (0.0810546875)\n",
      "final out[92] x: -592 (-0.14453125)\n",
      "final out[93] x: -982 (-0.23974609375)\n",
      "final out[94] x: -1977 (-0.482666015625)\n",
      "final out[95] x: -310 (-0.07568359375)\n",
      "final out[96] x: -645 (-0.157470703125)\n",
      "final out[97] x: 325 (0.079345703125)\n",
      "final out[98] x: -278 (-0.06787109375)\n",
      "final out[99] x: 1796 (0.4384765625)\n",
      "final out idxes: [58]\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['./bin/m1_mac/test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']' died with <Signals.SIGKILL: 9>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m command \u001b[38;5;241m=\u001b[39m [command_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_circuit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverted_model_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample_inp_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkzg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run the command\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['./bin/m1_mac/test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']' died with <Signals.SIGKILL: 9>."
     ]
    }
   ],
   "source": [
    "# !./bin/test_circuit ./converted_model_new.msgpack ./example_inp_new.msgpack kzg\n",
    "\n",
    "\n",
    "# Command to run\n",
    "command = [command_dir + 'test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m command \u001b[38;5;241m=\u001b[39m [command_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_circuit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverted_model_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample_inp_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkzg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Run the command\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:507\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    509\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1126\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1189\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1917\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1875\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1875\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1879\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Command to run\n",
    "command = [command_dir + 'time_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !onnx2tf -i ./model_simplified.onnx -o model_tf --not_use_onnxsim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx_tf.backend import prepare\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.python.framework import convert_to_constants\n",
    "# import numpy as np\n",
    "\n",
    "# # Step 1: Convert ONNX model to TensorFlow\n",
    "# def onnx_to_tf(onnx_model_path, output_tf_model_path):\n",
    "#     onnx_model = onnx.load(onnx_model_path)\n",
    "#     tf_rep = prepare(onnx_model)\n",
    "#     tf_rep.export_graph(output_tf_model_path)\n",
    "#     print(f\"ONNX model converted to TensorFlow and saved at {output_tf_model_path}\")\n",
    "\n",
    "# # Step 2: Modify the TensorFlow computation graph\n",
    "# def modify_tf_model_graph(concrete_func):\n",
    "#     frozen_func = convert_to_constants.convert_variables_to_constants_v2(concrete_func)\n",
    "#     frozen_func.graph.as_graph_def()\n",
    "\n",
    "#     modified_graph_def = tf.compat.v1.GraphDef()\n",
    "\n",
    "#     for node in frozen_func.graph.as_graph_def().node:\n",
    "#         if \"Dense\" in node.op:  # Check for fully connected layer\n",
    "#             # Find the input to the dense layer and check its shape\n",
    "#             input_node = node.input[0]\n",
    "            \n",
    "#             # Get the input tensor shape properly using frozen_func inputs\n",
    "#             input_tensor = None\n",
    "#             for input_tensor_item in frozen_func.inputs:\n",
    "#                 if input_node in input_tensor_item.name or input_tensor_item.name.startswith(input_node):\n",
    "#                     input_tensor = input_tensor_item\n",
    "#                     break\n",
    "\n",
    "#             if input_tensor is None:\n",
    "#                 print(f\"Input tensor {input_node} not found in frozen_func.inputs. Skipping node {node.name}.\")\n",
    "#                 continue\n",
    "            \n",
    "#             input_shape = input_tensor.shape.as_list()\n",
    "\n",
    "#             if len(input_shape) > 2:\n",
    "#                 print(f\"Input to {node.name} is more than 2D: {input_shape}, adding Flatten.\")\n",
    "#                 # Modify the graph to add a Flatten operation before this node\n",
    "#                 flatten_node = tf.raw_ops.Flatten(input=input_node, name=f\"{node.name}_flatten\")\n",
    "#                 node.input[0] = flatten_node.name  # Redirect input to the Flatten node\n",
    "        \n",
    "#         modified_graph_def.node.extend([node])\n",
    "\n",
    "#     return modified_graph_def\n",
    "\n",
    "# # Step 3: Convert TensorFlow Model to TFLite\n",
    "# def tf_to_tflite(concrete_func, output_tflite_path):\n",
    "#     converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "#     tflite_model = converter.convert()\n",
    "\n",
    "#     # Save the TFLite model\n",
    "#     with open(output_tflite_path, 'wb') as f:\n",
    "#         f.write(tflite_model)\n",
    "#     print(f\"TensorFlow model converted to TFLite and saved at {output_tflite_path}\")\n",
    "\n",
    "# # Main function to handle everything\n",
    "# def convert_onnx_to_tflite(onnx_model_path, output_tf_model_path, output_tflite_path):\n",
    "#     # Step 1: Convert ONNX to TensorFlow\n",
    "#     onnx_to_tf(onnx_model_path, output_tf_model_path)\n",
    "\n",
    "#     # Step 2: Load the converted TensorFlow SavedModel\n",
    "#     loaded_model = tf.saved_model.load(output_tf_model_path)\n",
    "    \n",
    "#     # Get the concrete function from the loaded model\n",
    "#     concrete_func = loaded_model.signatures['serving_default']\n",
    "\n",
    "#     # Step 3: Modify the TensorFlow computation graph (add reshape/flatten layers if needed)\n",
    "#     modified_graph = modify_tf_model_graph(concrete_func)\n",
    "\n",
    "#     # Step 4: Convert the modified TensorFlow model to TFLite\n",
    "#     tf_to_tflite(concrete_func, output_tflite_path)\n",
    "\n",
    "# # Example usage\n",
    "# onnx_model_path = 'resnet20_cifar100_dense.onnx'  # Replace with your ONNX model path\n",
    "# output_tf_model_path = 'converted_model'  # Path to save the converted TensorFlow model\n",
    "# output_tflite_path = 'final_model.tflite'  # Path to save the TFLite model\n",
    "\n",
    "# convert_onnx_to_tflite(onnx_model_path, output_tf_model_path, output_tflite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# model_path = '/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/frameworks/zkml/tmp/inputs/unpruned.pth.tar'\n",
    "# model_state_dict = torch.load(model_path)  # Load your PyTorch model\n",
    "# model \n",
    "\n",
    "# # Export to ONNX with opset version 10\n",
    "# dummy_input = torch.randn(1, 3, 224, 224)  # Adjust to your input size\n",
    "# torch.onnx.export(model, dummy_input, \"model_opset_10.onnx\", opset_version=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx import helper\n",
    "# from onnx import TensorProto\n",
    "\n",
    "# # Load the ONNX model\n",
    "# model = onnx.load('./tmp/inputs/model_simplified.onnx')\n",
    "\n",
    "# # Find the Reshape node\n",
    "# reshape_node = None\n",
    "# for node in model.graph.node:\n",
    "#     if node.op_type == 'Reshape':\n",
    "#         reshape_node = node\n",
    "#         break\n",
    "\n",
    "# if reshape_node is None:\n",
    "#     raise ValueError(\"Reshape node not found in the model.\")\n",
    "\n",
    "# # Create an Identity node after the Reshape\n",
    "# identity_output = reshape_node.output[0] + '_identity'\n",
    "# identity_node = helper.make_node(\n",
    "#     'Identity',\n",
    "#     inputs=[reshape_node.output[0]],\n",
    "#     outputs=[identity_output],\n",
    "#     name='Identity_after_Reshape'\n",
    "# )\n",
    "\n",
    "# # Update the next node to use the output of the Identity node\n",
    "# for node in model.graph.node:\n",
    "#     for idx, inp in enumerate(node.input):\n",
    "#         if inp == reshape_node.output[0]:\n",
    "#             node.input[idx] = identity_output\n",
    "\n",
    "# # Add the Identity node to the graph\n",
    "# model.graph.node.append(identity_node)\n",
    "\n",
    "# # Save the modified model\n",
    "# onnx.save(model, 'modified_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx import version_converter\n",
    "\n",
    "# # Load the ONNX model\n",
    "# onnx_model_path = '/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/frameworks/zkml/tmp/inputs/resnet20_cifar100_dense.onnx'  # Replace with your ONNX file path\n",
    "# onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "# # Check the current opset version of the model\n",
    "# current_opset = onnx_model.opset_import[0].version\n",
    "# print(f\"Current opset version: {current_opset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Convert the ONNX model to opset version 10\n",
    "# converted_model = version_converter.convert_version(onnx_model, 14)\n",
    "\n",
    "# # Save the converted model\n",
    "# converted_model_path = 'model_opset_10.onnx'  # Replace with your desired output path\n",
    "# onnx.save(converted_model, converted_model_path)\n",
    "\n",
    "# print(f\"Model saved with opset version 10 at {converted_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Load the TensorFlow SavedModel\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(\"model_tf\")\n",
    "\n",
    "# # (Optional) Enable optimizations\n",
    "# # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# # Convert the model\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the TFLite model\n",
    "# with open(\"model.tflite\", \"wb\") as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from onnx_tf.backend import prepare\n",
    "# import onnx\n",
    "\n",
    "# # Load the ONNX model\n",
    "# onnx_model = onnx.load(\"./tmp/inputs/resnet20_cifar_dense.onnx\")\n",
    "\n",
    "# # Convert the ONNX model to TensorFlow\n",
    "# tf_rep = prepare(onnx_model)\n",
    "\n",
    "# # Export the TensorFlow model\n",
    "# tf_rep.export_graph(\"model_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx_tf.backend import prepare\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "\n",
    "# # Step 1: Load the ONNX model\n",
    "# onnx_model_path = './tmp/inputs/resnet20_cifar_dense.onnx' # Replace with your ONNX model path\n",
    "# onnx_model = onnx.load(onnx_model_path)\n",
    "# print(\"ONNX model loaded successfully.\")\n",
    "\n",
    "# # Step 2: Convert ONNX model to TensorFlow SavedModel\n",
    "# print(\"Converting ONNX model to TensorFlow format...\")\n",
    "# tf_rep = prepare(onnx_model)\n",
    "\n",
    "# # Define the path to save the TensorFlow SavedModel\n",
    "# tf_model_path = 'saved_model'\n",
    "# if not os.path.exists(tf_model_path):\n",
    "#     os.makedirs(tf_model_path)\n",
    "\n",
    "# # Export the TensorFlow model\n",
    "# tf_rep.export_graph(tf_model_path)\n",
    "# print(f\"TensorFlow SavedModel exported to {tf_model_path}.\")\n",
    "\n",
    "# # Step 3: Convert TensorFlow SavedModel to TFLite model\n",
    "# print(\"Converting TensorFlow SavedModel to TFLite format...\")\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "\n",
    "# # Optional: Set optimization flags (e.g., for quantization)\n",
    "# # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# # Perform the conversion\n",
    "# tflite_model = converter.convert()\n",
    "# print(\"Conversion to TFLite format completed.\")\n",
    "\n",
    "# # Step 4: Save the TFLite model\n",
    "# tflite_model_path = 'model.tflite'  # Replace with your desired TFLite model path\n",
    "# with open(tflite_model_path, 'wb') as f:\n",
    "#     f.write(tflite_model)\n",
    "# print(f\"TFLite model saved to {tflite_model_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zkml_bench_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
