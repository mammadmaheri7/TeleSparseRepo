{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class ResNet20Cifar100(tf.keras.Model):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(ResNet20Cifar100, self).__init__()\n",
    "\n",
    "        # Initial Conv Layer\n",
    "        self.conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "\n",
    "        # Layer 1 Block 1\n",
    "        self.layer1_0_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_0_bn1 = layers.BatchNormalization()\n",
    "        self.layer1_0_relu1 = layers.ReLU()\n",
    "        self.layer1_0_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_0_bn2 = layers.BatchNormalization()\n",
    "        self.layer1_0_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 1 Block 2\n",
    "        self.layer1_1_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_1_bn1 = layers.BatchNormalization()\n",
    "        self.layer1_1_relu1 = layers.ReLU()\n",
    "        self.layer1_1_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_1_bn2 = layers.BatchNormalization()\n",
    "        self.layer1_1_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 1 Block 3\n",
    "        self.layer1_2_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_2_bn1 = layers.BatchNormalization()\n",
    "        self.layer1_2_relu1 = layers.ReLU()\n",
    "        self.layer1_2_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer1_2_bn2 = layers.BatchNormalization()\n",
    "        self.layer1_2_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 2 Block 1 (with downsampling)\n",
    "        self.layer2_0_conv1 = layers.Conv2D(32, kernel_size=3, strides=2, padding='same', use_bias=False)\n",
    "        self.layer2_0_bn1 = layers.BatchNormalization()\n",
    "        self.layer2_0_relu1 = layers.ReLU()\n",
    "        self.layer2_0_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_0_bn2 = layers.BatchNormalization()\n",
    "        self.layer2_0_relu2 = layers.ReLU()\n",
    "        self.layer2_0_downsample = models.Sequential([\n",
    "            layers.Conv2D(32, kernel_size=1, strides=2, use_bias=False),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "\n",
    "        # Layer 2 Block 2\n",
    "        self.layer2_1_conv1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_1_bn1 = layers.BatchNormalization()\n",
    "        self.layer2_1_relu1 = layers.ReLU()\n",
    "        self.layer2_1_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_1_bn2 = layers.BatchNormalization()\n",
    "        self.layer2_1_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 2 Block 3\n",
    "        self.layer2_2_conv1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_2_bn1 = layers.BatchNormalization()\n",
    "        self.layer2_2_relu1 = layers.ReLU()\n",
    "        self.layer2_2_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer2_2_bn2 = layers.BatchNormalization()\n",
    "        self.layer2_2_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 3 Block 1 (with downsampling)\n",
    "        self.layer3_0_conv1 = layers.Conv2D(64, kernel_size=3, strides=2, padding='same', use_bias=False)\n",
    "        self.layer3_0_bn1 = layers.BatchNormalization()\n",
    "        self.layer3_0_relu1 = layers.ReLU()\n",
    "        self.layer3_0_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_0_bn2 = layers.BatchNormalization()\n",
    "        self.layer3_0_downsample = models.Sequential([\n",
    "            layers.Conv2D(64, kernel_size=1, strides=2, use_bias=False),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "        self.layer3_0_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 3 Block 2\n",
    "        self.layer3_1_conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_1_bn1 = layers.BatchNormalization()\n",
    "        self.layer3_1_relu1 = layers.ReLU()\n",
    "        self.layer3_1_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_1_bn2 = layers.BatchNormalization()\n",
    "        self.layer3_1_relu2 = layers.ReLU()\n",
    "\n",
    "        # Layer 3 Block 3\n",
    "        self.layer3_2_conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_2_bn1 = layers.BatchNormalization()\n",
    "        self.layer3_2_relu1 = layers.ReLU()\n",
    "        self.layer3_2_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "        self.layer3_2_bn2 = layers.BatchNormalization()\n",
    "        self.layer3_2_relu2 = layers.ReLU()\n",
    "\n",
    "        # Pooling and classification layers\n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # Initial layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        # Layer 1 Block 1\n",
    "        residual = x\n",
    "        x = self.layer1_0_conv1(x)\n",
    "        x = self.layer1_0_bn1(x, training=training)\n",
    "        x = self.layer1_0_relu1(x)\n",
    "        x = self.layer1_0_conv2(x)\n",
    "        x = self.layer1_0_bn2(x, training=training)\n",
    "        x += residual  # Add operation\n",
    "        x = self.layer1_0_relu2(x)\n",
    "\n",
    "        # Layer 1 Block 2\n",
    "        residual = x\n",
    "        x = self.layer1_1_conv1(x)\n",
    "        x = self.layer1_1_bn1(x, training=training)\n",
    "        x = self.layer1_1_relu1(x)\n",
    "        x = self.layer1_1_conv2(x)\n",
    "        x = self.layer1_1_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer1_1_relu2(x)\n",
    "\n",
    "        # Layer 1 Block 3\n",
    "        residual = x\n",
    "        x = self.layer1_2_conv1(x)\n",
    "        x = self.layer1_2_bn1(x, training=training)\n",
    "        x = self.layer1_2_relu1(x)\n",
    "        x = self.layer1_2_conv2(x)\n",
    "        x = self.layer1_2_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer1_2_relu2(x)\n",
    "\n",
    "        # Layer 2 Block 1 (with downsampling)\n",
    "        residual = self.layer2_0_downsample(x, training=training)\n",
    "        x = self.layer2_0_conv1(x)\n",
    "        x = self.layer2_0_bn1(x, training=training)\n",
    "        x = self.layer2_0_relu1(x)\n",
    "        x = self.layer2_0_conv2(x)\n",
    "        x = self.layer2_0_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer2_0_relu2(x)\n",
    "\n",
    "        # Layer 2 Block 2\n",
    "        residual = x\n",
    "        x = self.layer2_1_conv1(x)\n",
    "        x = self.layer2_1_bn1(x, training=training)\n",
    "        x = self.layer2_1_relu1(x)\n",
    "        x = self.layer2_1_conv2(x)\n",
    "        x = self.layer2_1_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer2_1_relu2(x)\n",
    "\n",
    "        # Layer 2 Block 3\n",
    "        residual = x\n",
    "        x = self.layer2_2_conv1(x)\n",
    "        x = self.layer2_2_bn1(x, training=training)\n",
    "        x = self.layer2_2_relu1(x)\n",
    "        x = self.layer2_2_conv2(x)\n",
    "        x = self.layer2_2_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer2_2_relu2(x)\n",
    "\n",
    "        # Layer 3 Block 1 (with downsampling)\n",
    "        residual = self.layer3_0_downsample(x, training=training)\n",
    "        x = self.layer3_0_conv1(x)\n",
    "        x = self.layer3_0_bn1(x, training=training)\n",
    "        x = self.layer3_0_relu1(x)\n",
    "        x = self.layer3_0_conv2(x)\n",
    "        x = self.layer3_0_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer3_0_relu2(x)\n",
    "\n",
    "        # Layer 3 Block 2\n",
    "        residual = x\n",
    "        x = self.layer3_1_conv1(x)\n",
    "        x = self.layer3_1_bn1(x, training=training)\n",
    "        x = self.layer3_1_relu1(x)\n",
    "        x = self.layer3_1_conv2(x)\n",
    "        x = self.layer3_1_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer3_1_relu2(x)\n",
    "\n",
    "        # Layer 3 Block 3\n",
    "        residual = x\n",
    "        x = self.layer3_2_conv1(x)\n",
    "        x = self.layer3_2_bn1(x, training=training)\n",
    "        x = self.layer3_2_relu1(x)\n",
    "        x = self.layer3_2_conv2(x)\n",
    "        x = self.layer3_2_bn2(x, training=training)\n",
    "        x += residual\n",
    "        x = self.layer3_2_relu2(x)\n",
    "\n",
    "        # Pooling and classification\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.02319046  0.09040488  0.17464879 -0.18580529 -0.2603389  -0.14727576\n",
      "  -0.11792352  0.10791898  0.12220275  0.3389794   0.1419803  -0.05223288\n",
      "   0.10334254  0.04306893  0.11316299  0.2082336   0.22006941  0.00218584\n",
      "  -0.1031503   0.2537732   0.05372621 -0.06419809  0.02358134 -0.27564636\n",
      "   0.00236805  0.05413433 -0.03560496  0.06373198 -0.24118027 -0.10048033\n",
      "   0.04051803 -0.21544896  0.16970938  0.27298257  0.1724781   0.05703834\n",
      "   0.29317352 -0.03834959 -0.02623548 -0.15549783 -0.16595185  0.18636723\n",
      "   0.16470961  0.16572204  0.01755742 -0.30014247 -0.13401368 -0.12308196\n",
      "  -0.02732134  0.29434842  0.01014673  0.01289519  0.26732656 -0.0024655\n",
      "   0.01835042 -0.15265046  0.32173222  0.1473306   0.43412974 -0.17355756\n",
      "  -0.0359081   0.15350258  0.0217164  -0.05186245  0.01286696 -0.01913833\n",
      "  -0.011057   -0.17544183 -0.04441772 -0.24213904 -0.07106921 -0.12055694\n",
      "   0.15901747 -0.08730578  0.28107846  0.07711687 -0.24941704 -0.01000583\n",
      "   0.20198253 -0.21223857  0.04014826 -0.3703138   0.15195061 -0.20178817\n",
      "   0.06778874 -0.07245029 -0.11188355 -0.20926496  0.10028038 -0.15613519\n",
      "  -0.2978078   0.26376957 -0.05353849 -0.01436861 -0.03514456 -0.15492819\n",
      "  -0.08182941  0.23181489 -0.24551912  0.09175409]], shape=(1, 100), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `_wrapped_model` contains input name(s) resource with unsupported characters which will be renamed to res_net20_cifar100_5_dense_5_biasadd_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpc81c0k27/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpc81c0k27/assets\n",
      "INFO:absl:Writing fingerprint to /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpc81c0k27/fingerprint.pb\n",
      "INFO:absl:Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "model = ResNet20Cifar100(num_classes=100)\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "cifar100 = tf.keras.datasets.cifar100\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Compile the model (necessary for training, but for inference, itâ€™s optional)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Perform inference with a sample image from CIFAR-100\n",
    "sample_image = train_images[0:1]  # Select one sample\n",
    "sample_image = tf.convert_to_tensor(sample_image, dtype=tf.float32)\n",
    "\n",
    "# Ensure the model is in evaluation mode (no training mode needed)\n",
    "predictions = model(sample_image, training=False)  # training=False ensures evaluation mode\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# Convert the model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert() # experimental_new_converter=False\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 7.npy and forward it to the model\n",
    "import numpy as np\n",
    "data = np.load('7.npy')\n",
    "# reshape data to 4D\n",
    "data = np.reshape(data, (1, 32, 32, 3))\n",
    "\n",
    "# forward the data to the model\n",
    "data = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "predictions = model(data, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/zkml_bench_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "{0, 27, 28, 29, 30}\n",
      "Add inputs:  [29, 27]\n",
      "True True\n",
      "{0, 32, 33, 27, 28, 29, 30, 31}\n",
      "Add inputs:  [32, 30]\n",
      "True True\n",
      "{0, 32, 33, 34, 35, 36, 27, 28, 29, 30, 31}\n",
      "Add inputs:  [35, 33]\n",
      "True True\n",
      "{0, 32, 33, 34, 35, 36, 37, 38, 39, 40, 27, 28, 29, 30, 31}\n",
      "Add inputs:  [38, 39]\n",
      "True True\n",
      "{0, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 27, 28, 29, 30, 31}\n",
      "Add inputs:  [42, 40]\n",
      "True True\n",
      "{0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46}\n",
      "Add inputs:  [45, 43]\n",
      "True True\n",
      "{0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50}\n",
      "Add inputs:  [48, 49]\n",
      "True True\n",
      "{0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53}\n",
      "Add inputs:  [52, 50]\n",
      "True True\n",
      "{0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56}\n",
      "Add inputs:  [55, 53]\n",
      "True True\n",
      "[{'layer_type': 'Conv2D', 'inp_idxes': [0, 4, 1], 'inp_shapes': [[1, 32, 32, 3], [16, 3, 3, 3], [16]], 'out_idxes': [27], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [27, 5, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [28], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [28, 6, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [29], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [29, 27], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [30], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [30, 7, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [31], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [31, 8, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [32], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [32, 30], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [33], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [33, 9, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [34], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [34, 10, 1], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [35], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [35, 33], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [36], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [36, 11, 2], 'inp_shapes': [[1, 32, 32, 16], [32, 3, 3, 16], [32]], 'out_idxes': [37], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [37, 12, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [38], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [36, 13, 2], 'inp_shapes': [[1, 32, 32, 16], [32, 1, 1, 16], [32]], 'out_idxes': [39], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [38, 39], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [40], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [40, 14, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [41], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [41, 15, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [42], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [42, 40], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [43], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [43, 16, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [44], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [44, 17, 2], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [45], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [45, 43], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [46], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [46, 18, 3], 'inp_shapes': [[1, 16, 16, 32], [64, 3, 3, 32], [64]], 'out_idxes': [47], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [47, 19, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [48], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [46, 20, 3], 'inp_shapes': [[1, 16, 16, 32], [64, 1, 1, 32], [64]], 'out_idxes': [49], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [48, 49], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [50], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [50, 21, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [51], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [51, 22, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [52], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [52, 50], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [53], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [53, 23, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [54], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [54, 24, 3], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [55], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [55, 53], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [56], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [56, 25], 'inp_shapes': [[1, 8, 8, 64], [2]], 'out_idxes': [57], 'out_shapes': [[1, 64]], 'params': [1, 2], 'mask': []}, {'layer_type': 'FullyConnected', 'inp_idxes': [57, 26], 'inp_shapes': [[1, 64], [100, 64]], 'out_idxes': [58], 'out_shapes': [[1, 100]], 'params': [0], 'mask': []}]\n",
      "\n",
      "keep tensors: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, -1}\n",
      "skipping generated tensor: 0, b'serving_default_input_1:0'\n",
      "skipping generated tensor: 27, b'res_net20_cifar100_5/re_lu_90/Relu;res_net20_cifar100_5/batch_normalization_105/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_105/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_105/Conv2D'\n",
      "skipping generated tensor: 28, b'res_net20_cifar100_5/re_lu_91/Relu;res_net20_cifar100_5/batch_normalization_106/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_105/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_106/Conv2D'\n",
      "skipping generated tensor: 29, b'res_net20_cifar100_5/batch_normalization_107/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_105/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_107/Conv2D'\n",
      "skipping generated tensor: 30, b'res_net20_cifar100_5/re_lu_92/Relu;res_net20_cifar100_5/add'\n",
      "skipping generated tensor: 31, b'res_net20_cifar100_5/re_lu_93/Relu;res_net20_cifar100_5/batch_normalization_108/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_105/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_108/Conv2D'\n",
      "skipping generated tensor: 32, b'res_net20_cifar100_5/batch_normalization_109/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_105/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_109/Conv2D'\n",
      "skipping generated tensor: 33, b'res_net20_cifar100_5/re_lu_94/Relu;res_net20_cifar100_5/add_1'\n",
      "skipping generated tensor: 34, b'res_net20_cifar100_5/re_lu_95/Relu;res_net20_cifar100_5/batch_normalization_110/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_105/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_110/Conv2D'\n",
      "skipping generated tensor: 35, b'res_net20_cifar100_5/batch_normalization_111/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_105/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_111/Conv2D'\n",
      "skipping generated tensor: 36, b'res_net20_cifar100_5/re_lu_96/Relu;res_net20_cifar100_5/add_2'\n",
      "skipping generated tensor: 37, b'res_net20_cifar100_5/re_lu_97/Relu;res_net20_cifar100_5/batch_normalization_112/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_112/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_112/Conv2D'\n",
      "skipping generated tensor: 38, b'res_net20_cifar100_5/batch_normalization_113/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_112/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_113/Conv2D'\n",
      "skipping generated tensor: 39, b'res_net20_cifar100_5/sequential_10/batch_normalization_114/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_112/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/sequential_10/conv2d_114/Conv2D'\n",
      "skipping generated tensor: 40, b'res_net20_cifar100_5/re_lu_98/Relu;res_net20_cifar100_5/add_3'\n",
      "skipping generated tensor: 41, b'res_net20_cifar100_5/re_lu_99/Relu;res_net20_cifar100_5/batch_normalization_115/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_112/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_115/Conv2D'\n",
      "skipping generated tensor: 42, b'res_net20_cifar100_5/batch_normalization_116/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_112/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_116/Conv2D'\n",
      "skipping generated tensor: 43, b'res_net20_cifar100_5/re_lu_100/Relu;res_net20_cifar100_5/add_4'\n",
      "skipping generated tensor: 44, b'res_net20_cifar100_5/re_lu_101/Relu;res_net20_cifar100_5/batch_normalization_117/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_112/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_117/Conv2D'\n",
      "skipping generated tensor: 45, b'res_net20_cifar100_5/batch_normalization_118/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_112/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_118/Conv2D'\n",
      "skipping generated tensor: 46, b'res_net20_cifar100_5/re_lu_102/Relu;res_net20_cifar100_5/add_5'\n",
      "skipping generated tensor: 47, b'res_net20_cifar100_5/re_lu_103/Relu;res_net20_cifar100_5/batch_normalization_119/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_119/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_119/Conv2D'\n",
      "skipping generated tensor: 48, b'res_net20_cifar100_5/batch_normalization_120/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_119/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_120/Conv2D'\n",
      "skipping generated tensor: 49, b'res_net20_cifar100_5/sequential_11/batch_normalization_121/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_119/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/sequential_11/conv2d_121/Conv2D'\n",
      "skipping generated tensor: 50, b'res_net20_cifar100_5/re_lu_104/Relu;res_net20_cifar100_5/add_6'\n",
      "skipping generated tensor: 51, b'res_net20_cifar100_5/re_lu_105/Relu;res_net20_cifar100_5/batch_normalization_122/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_119/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_122/Conv2D'\n",
      "skipping generated tensor: 52, b'res_net20_cifar100_5/batch_normalization_123/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_119/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_123/Conv2D'\n",
      "skipping generated tensor: 53, b'res_net20_cifar100_5/re_lu_106/Relu;res_net20_cifar100_5/add_7'\n",
      "skipping generated tensor: 54, b'res_net20_cifar100_5/re_lu_107/Relu;res_net20_cifar100_5/batch_normalization_124/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_119/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_124/Conv2D'\n",
      "skipping generated tensor: 55, b'res_net20_cifar100_5/batch_normalization_125/FusedBatchNormV3;res_net20_cifar100_5/batch_normalization_119/FusedBatchNormV3/ReadVariableOp;res_net20_cifar100_5/conv2d_125/Conv2D'\n",
      "skipping generated tensor: 56, b'res_net20_cifar100_5/re_lu_108/Relu;res_net20_cifar100_5/add_8'\n",
      "skipping generated tensor: 57, b'res_net20_cifar100_5/global_average_pooling2d_5/Mean'\n",
      "\n",
      "{'layer_type': 'FullyConnected', 'inp_idxes': [57, 26], 'inp_shapes': [[1, 64], [100, 64]], 'out_idxes': [58], 'out_shapes': [[1, 100]], 'params': [0], 'mask': []}\n",
      "dict_keys(['global_sf', 'k', 'num_cols', 'num_random', 'inp_idxes', 'out_idxes', 'layers', 'tensors', 'use_selectors', 'commit_before', 'commit_after'])\n",
      "[58]\n"
     ]
    }
   ],
   "source": [
    "# convert model\n",
    "!python ./tools/converter.py --model ./model.tflite --model_output converted_model_new.msgpack --config_output config_new.msgpack --scale_factor 512 --k 20 --num_cols 20 --num_randoms 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input\n",
    "!python ./tools/input_converter.py --model_config converted_model_new.msgpack --inputs 7.npy --output example_inp_new.msgpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer 0, type: Conv2D, inp_idxes: [0, 4, 1], out_idxes: [27], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 1, type: Conv2D, inp_idxes: [27, 5, 1], out_idxes: [28], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 2, type: Conv2D, inp_idxes: [28, 6, 1], out_idxes: [29], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 3, type: Add, inp_idxes: [29, 27], out_idxes: [30], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 4, type: Conv2D, inp_idxes: [30, 7, 1], out_idxes: [31], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 5, type: Conv2D, inp_idxes: [31, 8, 1], out_idxes: [32], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 6, type: Add, inp_idxes: [32, 30], out_idxes: [33], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 7, type: Conv2D, inp_idxes: [33, 9, 1], out_idxes: [34], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 8, type: Conv2D, inp_idxes: [34, 10, 1], out_idxes: [35], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 9, type: Add, inp_idxes: [35, 33], out_idxes: [36], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 10, type: Conv2D, inp_idxes: [36, 11, 2], out_idxes: [37], layer_params: [0, 0, 1, 2, 2]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 11, type: Conv2D, inp_idxes: [37, 12, 2], out_idxes: [38], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 12, type: Conv2D, inp_idxes: [36, 13, 2], out_idxes: [39], layer_params: [0, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 13, type: Add, inp_idxes: [38, 39], out_idxes: [40], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 14, type: Conv2D, inp_idxes: [40, 14, 2], out_idxes: [41], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 15, type: Conv2D, inp_idxes: [41, 15, 2], out_idxes: [42], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 16, type: Add, inp_idxes: [42, 40], out_idxes: [43], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 17, type: Conv2D, inp_idxes: [43, 16, 2], out_idxes: [44], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 18, type: Conv2D, inp_idxes: [44, 17, 2], out_idxes: [45], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 19, type: Add, inp_idxes: [45, 43], out_idxes: [46], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 20, type: Conv2D, inp_idxes: [46, 18, 3], out_idxes: [47], layer_params: [0, 0, 1, 2, 2]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 21, type: Conv2D, inp_idxes: [47, 19, 3], out_idxes: [48], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 22, type: Conv2D, inp_idxes: [46, 20, 3], out_idxes: [49], layer_params: [0, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 23, type: Add, inp_idxes: [48, 49], out_idxes: [50], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 24, type: Conv2D, inp_idxes: [50, 21, 3], out_idxes: [51], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 25, type: Conv2D, inp_idxes: [51, 22, 3], out_idxes: [52], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 26, type: Add, inp_idxes: [52, 50], out_idxes: [53], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 27, type: Conv2D, inp_idxes: [53, 23, 3], out_idxes: [54], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 28, type: Conv2D, inp_idxes: [54, 24, 3], out_idxes: [55], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 29, type: Add, inp_idxes: [55, 53], out_idxes: [56], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 30, type: Mean, inp_idxes: [56, 25], out_idxes: [57], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 64]\n",
      "\n",
      "Processing layer 31, type: FullyConnected, inp_idxes: [57, 26], out_idxes: [58], layer_params: [0]\n",
      "Out 0 shape: [1, 100]\n",
      "\n",
      "final out[0] x: 11 (0.021484375)\n",
      "final out[1] x: 61 (0.119140625)\n",
      "final out[2] x: 107 (0.208984375)\n",
      "final out[3] x: -102 (-0.19921875)\n",
      "final out[4] x: -156 (-0.3046875)\n",
      "final out[5] x: -82 (-0.16015625)\n",
      "final out[6] x: -82 (-0.16015625)\n",
      "final out[7] x: 65 (0.126953125)\n",
      "final out[8] x: 73 (0.142578125)\n",
      "final out[9] x: 216 (0.421875)\n",
      "final out[10] x: 97 (0.189453125)\n",
      "final out[11] x: -39 (-0.076171875)\n",
      "final out[12] x: 60 (0.1171875)\n",
      "final out[13] x: 48 (0.09375)\n",
      "final out[14] x: 67 (0.130859375)\n",
      "final out[15] x: 157 (0.306640625)\n",
      "final out[16] x: 139 (0.271484375)\n",
      "final out[17] x: -2 (-0.00390625)\n",
      "final out[18] x: -62 (-0.12109375)\n",
      "final out[19] x: 170 (0.33203125)\n",
      "final out[20] x: 34 (0.06640625)\n",
      "final out[21] x: -52 (-0.1015625)\n",
      "final out[22] x: 15 (0.029296875)\n",
      "final out[23] x: -177 (-0.345703125)\n",
      "final out[24] x: -16 (-0.03125)\n",
      "final out[25] x: 28 (0.0546875)\n",
      "final out[26] x: -25 (-0.048828125)\n",
      "final out[27] x: 35 (0.068359375)\n",
      "final out[28] x: -161 (-0.314453125)\n",
      "final out[29] x: -75 (-0.146484375)\n",
      "final out[30] x: 17 (0.033203125)\n",
      "final out[31] x: -131 (-0.255859375)\n",
      "final out[32] x: 102 (0.19921875)\n",
      "final out[33] x: 173 (0.337890625)\n",
      "final out[34] x: 118 (0.23046875)\n",
      "final out[35] x: 38 (0.07421875)\n",
      "final out[36] x: 191 (0.373046875)\n",
      "final out[37] x: -35 (-0.068359375)\n",
      "final out[38] x: -10 (-0.01953125)\n",
      "final out[39] x: -111 (-0.216796875)\n",
      "final out[40] x: -86 (-0.16796875)\n",
      "final out[41] x: 108 (0.2109375)\n",
      "final out[42] x: 97 (0.189453125)\n",
      "final out[43] x: 100 (0.1953125)\n",
      "final out[44] x: 9 (0.017578125)\n",
      "final out[45] x: -204 (-0.3984375)\n",
      "final out[46] x: -91 (-0.177734375)\n",
      "final out[47] x: -82 (-0.16015625)\n",
      "final out[48] x: -25 (-0.048828125)\n",
      "final out[49] x: 180 (0.3515625)\n",
      "final out[50] x: 18 (0.03515625)\n",
      "final out[51] x: 8 (0.015625)\n",
      "final out[52] x: 171 (0.333984375)\n",
      "final out[53] x: 5 (0.009765625)\n",
      "final out[54] x: 3 (0.005859375)\n",
      "final out[55] x: -108 (-0.2109375)\n",
      "final out[56] x: 215 (0.419921875)\n",
      "final out[57] x: 91 (0.177734375)\n",
      "final out[58] x: 258 (0.50390625)\n",
      "final out[59] x: -122 (-0.23828125)\n",
      "final out[60] x: -26 (-0.05078125)\n",
      "final out[61] x: 83 (0.162109375)\n",
      "final out[62] x: 5 (0.009765625)\n",
      "final out[63] x: -36 (-0.0703125)\n",
      "final out[64] x: 12 (0.0234375)\n",
      "final out[65] x: -5 (-0.009765625)\n",
      "final out[66] x: -21 (-0.041015625)\n",
      "final out[67] x: -124 (-0.2421875)\n",
      "final out[68] x: -22 (-0.04296875)\n",
      "final out[69] x: -146 (-0.28515625)\n",
      "final out[70] x: -36 (-0.0703125)\n",
      "final out[71] x: -79 (-0.154296875)\n",
      "final out[72] x: 118 (0.23046875)\n",
      "final out[73] x: -57 (-0.111328125)\n",
      "final out[74] x: 170 (0.33203125)\n",
      "final out[75] x: 57 (0.111328125)\n",
      "final out[76] x: -145 (-0.283203125)\n",
      "final out[77] x: -6 (-0.01171875)\n",
      "final out[78] x: 126 (0.24609375)\n",
      "final out[79] x: -120 (-0.234375)\n",
      "final out[80] x: 29 (0.056640625)\n",
      "final out[81] x: -232 (-0.453125)\n",
      "final out[82] x: 118 (0.23046875)\n",
      "final out[83] x: -147 (-0.287109375)\n",
      "final out[84] x: 57 (0.111328125)\n",
      "final out[85] x: -45 (-0.087890625)\n",
      "final out[86] x: -73 (-0.142578125)\n",
      "final out[87] x: -151 (-0.294921875)\n",
      "final out[88] x: 45 (0.087890625)\n",
      "final out[89] x: -93 (-0.181640625)\n",
      "final out[90] x: -196 (-0.3828125)\n",
      "final out[91] x: 178 (0.34765625)\n",
      "final out[92] x: -33 (-0.064453125)\n",
      "final out[93] x: 9 (0.017578125)\n",
      "final out[94] x: -14 (-0.02734375)\n",
      "final out[95] x: -88 (-0.171875)\n",
      "final out[96] x: -63 (-0.123046875)\n",
      "final out[97] x: 151 (0.294921875)\n",
      "final out[98] x: -136 (-0.265625)\n",
      "final out[99] x: 63 (0.123046875)\n",
      "final out idxes: [58]\n",
      "Processing layer 0, type: Conv2D, inp_idxes: [0, 4, 1], out_idxes: [27], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 1, type: Conv2D, inp_idxes: [27, 5, 1], out_idxes: [28], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 2, type: Conv2D, inp_idxes: [28, 6, 1], out_idxes: [29], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 3, type: Add, inp_idxes: [29, 27], out_idxes: [30], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 4, type: Conv2D, inp_idxes: [30, 7, 1], out_idxes: [31], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 5, type: Conv2D, inp_idxes: [31, 8, 1], out_idxes: [32], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 6, type: Add, inp_idxes: [32, 30], out_idxes: [33], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 7, type: Conv2D, inp_idxes: [33, 9, 1], out_idxes: [34], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 8, type: Conv2D, inp_idxes: [34, 10, 1], out_idxes: [35], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 9, type: Add, inp_idxes: [35, 33], out_idxes: [36], layer_params: [1]\n",
      "Out 0 shape: [1, 32, 32, 16]\n",
      "\n",
      "Processing layer 10, type: Conv2D, inp_idxes: [36, 11, 2], out_idxes: [37], layer_params: [0, 0, 1, 2, 2]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 11, type: Conv2D, inp_idxes: [37, 12, 2], out_idxes: [38], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 12, type: Conv2D, inp_idxes: [36, 13, 2], out_idxes: [39], layer_params: [0, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 13, type: Add, inp_idxes: [38, 39], out_idxes: [40], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 14, type: Conv2D, inp_idxes: [40, 14, 2], out_idxes: [41], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 15, type: Conv2D, inp_idxes: [41, 15, 2], out_idxes: [42], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 16, type: Add, inp_idxes: [42, 40], out_idxes: [43], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 17, type: Conv2D, inp_idxes: [43, 16, 2], out_idxes: [44], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 18, type: Conv2D, inp_idxes: [44, 17, 2], out_idxes: [45], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 19, type: Add, inp_idxes: [45, 43], out_idxes: [46], layer_params: [1]\n",
      "Out 0 shape: [1, 16, 16, 32]\n",
      "\n",
      "Processing layer 20, type: Conv2D, inp_idxes: [46, 18, 3], out_idxes: [47], layer_params: [0, 0, 1, 2, 2]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 21, type: Conv2D, inp_idxes: [47, 19, 3], out_idxes: [48], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 22, type: Conv2D, inp_idxes: [46, 20, 3], out_idxes: [49], layer_params: [0, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 23, type: Add, inp_idxes: [48, 49], out_idxes: [50], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 24, type: Conv2D, inp_idxes: [50, 21, 3], out_idxes: [51], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 25, type: Conv2D, inp_idxes: [51, 22, 3], out_idxes: [52], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 26, type: Add, inp_idxes: [52, 50], out_idxes: [53], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 27, type: Conv2D, inp_idxes: [53, 23, 3], out_idxes: [54], layer_params: [0, 0, 1, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 28, type: Conv2D, inp_idxes: [54, 24, 3], out_idxes: [55], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 29, type: Add, inp_idxes: [55, 53], out_idxes: [56], layer_params: [1]\n",
      "Out 0 shape: [1, 8, 8, 64]\n",
      "\n",
      "Processing layer 30, type: Mean, inp_idxes: [56, 25], out_idxes: [57], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 64]\n",
      "\n",
      "Processing layer 31, type: FullyConnected, inp_idxes: [57, 26], out_idxes: [58], layer_params: [0]\n",
      "Out 0 shape: [1, 100]\n",
      "\n",
      "final out[0] x: 11 (0.021484375)\n",
      "final out[1] x: 61 (0.119140625)\n",
      "final out[2] x: 107 (0.208984375)\n",
      "final out[3] x: -102 (-0.19921875)\n",
      "final out[4] x: -156 (-0.3046875)\n",
      "final out[5] x: -82 (-0.16015625)\n",
      "final out[6] x: -82 (-0.16015625)\n",
      "final out[7] x: 65 (0.126953125)\n",
      "final out[8] x: 73 (0.142578125)\n",
      "final out[9] x: 216 (0.421875)\n",
      "final out[10] x: 97 (0.189453125)\n",
      "final out[11] x: -39 (-0.076171875)\n",
      "final out[12] x: 60 (0.1171875)\n",
      "final out[13] x: 48 (0.09375)\n",
      "final out[14] x: 67 (0.130859375)\n",
      "final out[15] x: 157 (0.306640625)\n",
      "final out[16] x: 139 (0.271484375)\n",
      "final out[17] x: -2 (-0.00390625)\n",
      "final out[18] x: -62 (-0.12109375)\n",
      "final out[19] x: 170 (0.33203125)\n",
      "final out[20] x: 34 (0.06640625)\n",
      "final out[21] x: -52 (-0.1015625)\n",
      "final out[22] x: 15 (0.029296875)\n",
      "final out[23] x: -177 (-0.345703125)\n",
      "final out[24] x: -16 (-0.03125)\n",
      "final out[25] x: 28 (0.0546875)\n",
      "final out[26] x: -25 (-0.048828125)\n",
      "final out[27] x: 35 (0.068359375)\n",
      "final out[28] x: -161 (-0.314453125)\n",
      "final out[29] x: -75 (-0.146484375)\n",
      "final out[30] x: 17 (0.033203125)\n",
      "final out[31] x: -131 (-0.255859375)\n",
      "final out[32] x: 102 (0.19921875)\n",
      "final out[33] x: 173 (0.337890625)\n",
      "final out[34] x: 118 (0.23046875)\n",
      "final out[35] x: 38 (0.07421875)\n",
      "final out[36] x: 191 (0.373046875)\n",
      "final out[37] x: -35 (-0.068359375)\n",
      "final out[38] x: -10 (-0.01953125)\n",
      "final out[39] x: -111 (-0.216796875)\n",
      "final out[40] x: -86 (-0.16796875)\n",
      "final out[41] x: 108 (0.2109375)\n",
      "final out[42] x: 97 (0.189453125)\n",
      "final out[43] x: 100 (0.1953125)\n",
      "final out[44] x: 9 (0.017578125)\n",
      "final out[45] x: -204 (-0.3984375)\n",
      "final out[46] x: -91 (-0.177734375)\n",
      "final out[47] x: -82 (-0.16015625)\n",
      "final out[48] x: -25 (-0.048828125)\n",
      "final out[49] x: 180 (0.3515625)\n",
      "final out[50] x: 18 (0.03515625)\n",
      "final out[51] x: 8 (0.015625)\n",
      "final out[52] x: 171 (0.333984375)\n",
      "final out[53] x: 5 (0.009765625)\n",
      "final out[54] x: 3 (0.005859375)\n",
      "final out[55] x: -108 (-0.2109375)\n",
      "final out[56] x: 215 (0.419921875)\n",
      "final out[57] x: 91 (0.177734375)\n",
      "final out[58] x: 258 (0.50390625)\n",
      "final out[59] x: -122 (-0.23828125)\n",
      "final out[60] x: -26 (-0.05078125)\n",
      "final out[61] x: 83 (0.162109375)\n",
      "final out[62] x: 5 (0.009765625)\n",
      "final out[63] x: -36 (-0.0703125)\n",
      "final out[64] x: 12 (0.0234375)\n",
      "final out[65] x: -5 (-0.009765625)\n",
      "final out[66] x: -21 (-0.041015625)\n",
      "final out[67] x: -124 (-0.2421875)\n",
      "final out[68] x: -22 (-0.04296875)\n",
      "final out[69] x: -146 (-0.28515625)\n",
      "final out[70] x: -36 (-0.0703125)\n",
      "final out[71] x: -79 (-0.154296875)\n",
      "final out[72] x: 118 (0.23046875)\n",
      "final out[73] x: -57 (-0.111328125)\n",
      "final out[74] x: 170 (0.33203125)\n",
      "final out[75] x: 57 (0.111328125)\n",
      "final out[76] x: -145 (-0.283203125)\n",
      "final out[77] x: -6 (-0.01171875)\n",
      "final out[78] x: 126 (0.24609375)\n",
      "final out[79] x: -120 (-0.234375)\n",
      "final out[80] x: 29 (0.056640625)\n",
      "final out[81] x: -232 (-0.453125)\n",
      "final out[82] x: 118 (0.23046875)\n",
      "final out[83] x: -147 (-0.287109375)\n",
      "final out[84] x: 57 (0.111328125)\n",
      "final out[85] x: -45 (-0.087890625)\n",
      "final out[86] x: -73 (-0.142578125)\n",
      "final out[87] x: -151 (-0.294921875)\n",
      "final out[88] x: 45 (0.087890625)\n",
      "final out[89] x: -93 (-0.181640625)\n",
      "final out[90] x: -196 (-0.3828125)\n",
      "final out[91] x: 178 (0.34765625)\n",
      "final out[92] x: -33 (-0.064453125)\n",
      "final out[93] x: 9 (0.017578125)\n",
      "final out[94] x: -14 (-0.02734375)\n",
      "final out[95] x: -88 (-0.171875)\n",
      "final out[96] x: -63 (-0.123046875)\n",
      "final out[97] x: 151 (0.294921875)\n",
      "final out[98] x: -136 (-0.265625)\n",
      "final out[99] x: 63 (0.123046875)\n",
      "final out idxes: [58]\n"
     ]
    }
   ],
   "source": [
    "!./bin/test_circuit ./converted_model_new.msgpack ./example_inp_new.msgpack kzg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./bin/time_circuit ./converted_model_new.msgpack ./example_inp_new.msgpack kzg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !onnx2tf -i ./model_simplified.onnx -o model_tf --not_use_onnxsim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx_tf.backend import prepare\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.python.framework import convert_to_constants\n",
    "# import numpy as np\n",
    "\n",
    "# # Step 1: Convert ONNX model to TensorFlow\n",
    "# def onnx_to_tf(onnx_model_path, output_tf_model_path):\n",
    "#     onnx_model = onnx.load(onnx_model_path)\n",
    "#     tf_rep = prepare(onnx_model)\n",
    "#     tf_rep.export_graph(output_tf_model_path)\n",
    "#     print(f\"ONNX model converted to TensorFlow and saved at {output_tf_model_path}\")\n",
    "\n",
    "# # Step 2: Modify the TensorFlow computation graph\n",
    "# def modify_tf_model_graph(concrete_func):\n",
    "#     frozen_func = convert_to_constants.convert_variables_to_constants_v2(concrete_func)\n",
    "#     frozen_func.graph.as_graph_def()\n",
    "\n",
    "#     modified_graph_def = tf.compat.v1.GraphDef()\n",
    "\n",
    "#     for node in frozen_func.graph.as_graph_def().node:\n",
    "#         if \"Dense\" in node.op:  # Check for fully connected layer\n",
    "#             # Find the input to the dense layer and check its shape\n",
    "#             input_node = node.input[0]\n",
    "            \n",
    "#             # Get the input tensor shape properly using frozen_func inputs\n",
    "#             input_tensor = None\n",
    "#             for input_tensor_item in frozen_func.inputs:\n",
    "#                 if input_node in input_tensor_item.name or input_tensor_item.name.startswith(input_node):\n",
    "#                     input_tensor = input_tensor_item\n",
    "#                     break\n",
    "\n",
    "#             if input_tensor is None:\n",
    "#                 print(f\"Input tensor {input_node} not found in frozen_func.inputs. Skipping node {node.name}.\")\n",
    "#                 continue\n",
    "            \n",
    "#             input_shape = input_tensor.shape.as_list()\n",
    "\n",
    "#             if len(input_shape) > 2:\n",
    "#                 print(f\"Input to {node.name} is more than 2D: {input_shape}, adding Flatten.\")\n",
    "#                 # Modify the graph to add a Flatten operation before this node\n",
    "#                 flatten_node = tf.raw_ops.Flatten(input=input_node, name=f\"{node.name}_flatten\")\n",
    "#                 node.input[0] = flatten_node.name  # Redirect input to the Flatten node\n",
    "        \n",
    "#         modified_graph_def.node.extend([node])\n",
    "\n",
    "#     return modified_graph_def\n",
    "\n",
    "# # Step 3: Convert TensorFlow Model to TFLite\n",
    "# def tf_to_tflite(concrete_func, output_tflite_path):\n",
    "#     converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "#     tflite_model = converter.convert()\n",
    "\n",
    "#     # Save the TFLite model\n",
    "#     with open(output_tflite_path, 'wb') as f:\n",
    "#         f.write(tflite_model)\n",
    "#     print(f\"TensorFlow model converted to TFLite and saved at {output_tflite_path}\")\n",
    "\n",
    "# # Main function to handle everything\n",
    "# def convert_onnx_to_tflite(onnx_model_path, output_tf_model_path, output_tflite_path):\n",
    "#     # Step 1: Convert ONNX to TensorFlow\n",
    "#     onnx_to_tf(onnx_model_path, output_tf_model_path)\n",
    "\n",
    "#     # Step 2: Load the converted TensorFlow SavedModel\n",
    "#     loaded_model = tf.saved_model.load(output_tf_model_path)\n",
    "    \n",
    "#     # Get the concrete function from the loaded model\n",
    "#     concrete_func = loaded_model.signatures['serving_default']\n",
    "\n",
    "#     # Step 3: Modify the TensorFlow computation graph (add reshape/flatten layers if needed)\n",
    "#     modified_graph = modify_tf_model_graph(concrete_func)\n",
    "\n",
    "#     # Step 4: Convert the modified TensorFlow model to TFLite\n",
    "#     tf_to_tflite(concrete_func, output_tflite_path)\n",
    "\n",
    "# # Example usage\n",
    "# onnx_model_path = 'resnet20_cifar100_dense.onnx'  # Replace with your ONNX model path\n",
    "# output_tf_model_path = 'converted_model'  # Path to save the converted TensorFlow model\n",
    "# output_tflite_path = 'final_model.tflite'  # Path to save the TFLite model\n",
    "\n",
    "# convert_onnx_to_tflite(onnx_model_path, output_tf_model_path, output_tflite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# model_path = '/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/frameworks/zkml/tmp/inputs/unpruned.pth.tar'\n",
    "# model_state_dict = torch.load(model_path)  # Load your PyTorch model\n",
    "# model \n",
    "\n",
    "# # Export to ONNX with opset version 10\n",
    "# dummy_input = torch.randn(1, 3, 224, 224)  # Adjust to your input size\n",
    "# torch.onnx.export(model, dummy_input, \"model_opset_10.onnx\", opset_version=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx import helper\n",
    "# from onnx import TensorProto\n",
    "\n",
    "# # Load the ONNX model\n",
    "# model = onnx.load('./tmp/inputs/model_simplified.onnx')\n",
    "\n",
    "# # Find the Reshape node\n",
    "# reshape_node = None\n",
    "# for node in model.graph.node:\n",
    "#     if node.op_type == 'Reshape':\n",
    "#         reshape_node = node\n",
    "#         break\n",
    "\n",
    "# if reshape_node is None:\n",
    "#     raise ValueError(\"Reshape node not found in the model.\")\n",
    "\n",
    "# # Create an Identity node after the Reshape\n",
    "# identity_output = reshape_node.output[0] + '_identity'\n",
    "# identity_node = helper.make_node(\n",
    "#     'Identity',\n",
    "#     inputs=[reshape_node.output[0]],\n",
    "#     outputs=[identity_output],\n",
    "#     name='Identity_after_Reshape'\n",
    "# )\n",
    "\n",
    "# # Update the next node to use the output of the Identity node\n",
    "# for node in model.graph.node:\n",
    "#     for idx, inp in enumerate(node.input):\n",
    "#         if inp == reshape_node.output[0]:\n",
    "#             node.input[idx] = identity_output\n",
    "\n",
    "# # Add the Identity node to the graph\n",
    "# model.graph.node.append(identity_node)\n",
    "\n",
    "# # Save the modified model\n",
    "# onnx.save(model, 'modified_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx import version_converter\n",
    "\n",
    "# # Load the ONNX model\n",
    "# onnx_model_path = '/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/frameworks/zkml/tmp/inputs/resnet20_cifar100_dense.onnx'  # Replace with your ONNX file path\n",
    "# onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "# # Check the current opset version of the model\n",
    "# current_opset = onnx_model.opset_import[0].version\n",
    "# print(f\"Current opset version: {current_opset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Convert the ONNX model to opset version 10\n",
    "# converted_model = version_converter.convert_version(onnx_model, 14)\n",
    "\n",
    "# # Save the converted model\n",
    "# converted_model_path = 'model_opset_10.onnx'  # Replace with your desired output path\n",
    "# onnx.save(converted_model, converted_model_path)\n",
    "\n",
    "# print(f\"Model saved with opset version 10 at {converted_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Load the TensorFlow SavedModel\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(\"model_tf\")\n",
    "\n",
    "# # (Optional) Enable optimizations\n",
    "# # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# # Convert the model\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the TFLite model\n",
    "# with open(\"model.tflite\", \"wb\") as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from onnx_tf.backend import prepare\n",
    "# import onnx\n",
    "\n",
    "# # Load the ONNX model\n",
    "# onnx_model = onnx.load(\"./tmp/inputs/resnet20_cifar_dense.onnx\")\n",
    "\n",
    "# # Convert the ONNX model to TensorFlow\n",
    "# tf_rep = prepare(onnx_model)\n",
    "\n",
    "# # Export the TensorFlow model\n",
    "# tf_rep.export_graph(\"model_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx_tf.backend import prepare\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "\n",
    "# # Step 1: Load the ONNX model\n",
    "# onnx_model_path = './tmp/inputs/resnet20_cifar_dense.onnx' # Replace with your ONNX model path\n",
    "# onnx_model = onnx.load(onnx_model_path)\n",
    "# print(\"ONNX model loaded successfully.\")\n",
    "\n",
    "# # Step 2: Convert ONNX model to TensorFlow SavedModel\n",
    "# print(\"Converting ONNX model to TensorFlow format...\")\n",
    "# tf_rep = prepare(onnx_model)\n",
    "\n",
    "# # Define the path to save the TensorFlow SavedModel\n",
    "# tf_model_path = 'saved_model'\n",
    "# if not os.path.exists(tf_model_path):\n",
    "#     os.makedirs(tf_model_path)\n",
    "\n",
    "# # Export the TensorFlow model\n",
    "# tf_rep.export_graph(tf_model_path)\n",
    "# print(f\"TensorFlow SavedModel exported to {tf_model_path}.\")\n",
    "\n",
    "# # Step 3: Convert TensorFlow SavedModel to TFLite model\n",
    "# print(\"Converting TensorFlow SavedModel to TFLite format...\")\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "\n",
    "# # Optional: Set optimization flags (e.g., for quantization)\n",
    "# # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# # Perform the conversion\n",
    "# tflite_model = converter.convert()\n",
    "# print(\"Conversion to TFLite format completed.\")\n",
    "\n",
    "# # Step 4: Save the TFLite model\n",
    "# tflite_model_path = 'model.tflite'  # Replace with your desired TFLite model path\n",
    "# with open(tflite_model_path, 'wb') as f:\n",
    "#     f.write(tflite_model)\n",
    "# print(f\"TFLite model saved to {tflite_model_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zkml_bench_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
