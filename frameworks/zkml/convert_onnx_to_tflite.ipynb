{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 50 CPUs with lowest load: [7, 6, 3, 5, 4, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_cpu_load():\n",
    "    # Get CPU usage for each core\n",
    "    cpu_loads = psutil.cpu_percent(interval=1, percpu=True)\n",
    "    return cpu_loads\n",
    "\n",
    "def select_k_cpus_with_lowest_load(k):\n",
    "    # Get CPU usage for each core\n",
    "    cpu_loads = get_cpu_load()\n",
    "    \n",
    "    # Create a list of tuples (core_id, load)\n",
    "    cpu_load_tuples = list(enumerate(cpu_loads))\n",
    "    \n",
    "    # Sort the list based on load\n",
    "    sorted_cpu_loads = sorted(cpu_load_tuples, key=lambda x: x[1])\n",
    "    \n",
    "    # Get the IDs of the K cores with lowest load\n",
    "    selected_cpus = [core[0] for core in sorted_cpu_loads[:k]]\n",
    "    \n",
    "    return selected_cpus\n",
    "\n",
    "# Example usage\n",
    "k = 50  # Number of CPUs with lowest load\n",
    "selected_cpus = select_k_cpus_with_lowest_load(k)\n",
    "print(f\"Selected {k} CPUs with lowest load:\", selected_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "def set_cpu_affinity(pid, cpu_list):\n",
    "    try:\n",
    "        p = psutil.Process(pid)\n",
    "        p.cpu_affinity(cpu_list)\n",
    "        print(f\"CPU affinity for process {pid} set to: {cpu_list}\")\n",
    "    except psutil.NoSuchProcess:\n",
    "        print(f\"Process with PID {pid} does not exist.\")\n",
    "    except psutil.AccessDenied:\n",
    "        print(\"Permission denied. You may need sudo privileges to set CPU affinity.\")\n",
    "\n",
    "# Get the process ID of the current process\n",
    "pid = os.getpid()\n",
    "\n",
    "# Set the CPU affinity to only CPU core 0\n",
    "cpu_list = selected_cpus\n",
    "set_cpu_affinity(pid, cpu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# class ResNet20Cifar100(tf.keras.Model):\n",
    "#     def __init__(self, num_classes=100):\n",
    "#         super(ResNet20Cifar100, self).__init__()\n",
    "\n",
    "#         # Initial Conv Layer\n",
    "#         self.conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.bn1 = layers.BatchNormalization()\n",
    "#         self.relu1 = layers.ReLU()\n",
    "\n",
    "#         # Layer 1 Block 1\n",
    "#         self.layer1_0_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_0_bn1 = layers.BatchNormalization()\n",
    "#         self.layer1_0_relu1 = layers.ReLU()\n",
    "#         self.layer1_0_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_0_bn2 = layers.BatchNormalization()\n",
    "#         self.layer1_0_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 1 Block 2\n",
    "#         self.layer1_1_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_1_bn1 = layers.BatchNormalization()\n",
    "#         self.layer1_1_relu1 = layers.ReLU()\n",
    "#         self.layer1_1_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_1_bn2 = layers.BatchNormalization()\n",
    "#         self.layer1_1_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 1 Block 3\n",
    "#         self.layer1_2_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_2_bn1 = layers.BatchNormalization()\n",
    "#         self.layer1_2_relu1 = layers.ReLU()\n",
    "#         self.layer1_2_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_2_bn2 = layers.BatchNormalization()\n",
    "#         self.layer1_2_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 2 Block 1 (with downsampling)\n",
    "#         self.layer2_0_conv1 = layers.Conv2D(32, kernel_size=3, strides=2, padding='same', use_bias=False)\n",
    "#         self.layer2_0_bn1 = layers.BatchNormalization()\n",
    "#         self.layer2_0_relu1 = layers.ReLU()\n",
    "#         self.layer2_0_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_0_bn2 = layers.BatchNormalization()\n",
    "#         self.layer2_0_relu2 = layers.ReLU()\n",
    "#         self.layer2_0_downsample = models.Sequential([\n",
    "#             layers.Conv2D(32, kernel_size=1, strides=2, use_bias=False),\n",
    "#             layers.BatchNormalization()\n",
    "#         ])\n",
    "\n",
    "#         # Layer 2 Block 2\n",
    "#         self.layer2_1_conv1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_1_bn1 = layers.BatchNormalization()\n",
    "#         self.layer2_1_relu1 = layers.ReLU()\n",
    "#         self.layer2_1_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_1_bn2 = layers.BatchNormalization()\n",
    "#         self.layer2_1_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 2 Block 3\n",
    "#         self.layer2_2_conv1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_2_bn1 = layers.BatchNormalization()\n",
    "#         self.layer2_2_relu1 = layers.ReLU()\n",
    "#         self.layer2_2_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_2_bn2 = layers.BatchNormalization()\n",
    "#         self.layer2_2_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 3 Block 1 (with downsampling)\n",
    "#         self.layer3_0_conv1 = layers.Conv2D(64, kernel_size=3, strides=2, padding='same', use_bias=False)\n",
    "#         self.layer3_0_bn1 = layers.BatchNormalization()\n",
    "#         self.layer3_0_relu1 = layers.ReLU()\n",
    "#         self.layer3_0_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_0_bn2 = layers.BatchNormalization()\n",
    "#         self.layer3_0_downsample = models.Sequential([\n",
    "#             layers.Conv2D(64, kernel_size=1, strides=2, use_bias=False),\n",
    "#             layers.BatchNormalization()\n",
    "#         ])\n",
    "#         self.layer3_0_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 3 Block 2\n",
    "#         self.layer3_1_conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_1_bn1 = layers.BatchNormalization()\n",
    "#         self.layer3_1_relu1 = layers.ReLU()\n",
    "#         self.layer3_1_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_1_bn2 = layers.BatchNormalization()\n",
    "#         self.layer3_1_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 3 Block 3\n",
    "#         self.layer3_2_conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_2_bn1 = layers.BatchNormalization()\n",
    "#         self.layer3_2_relu1 = layers.ReLU()\n",
    "#         self.layer3_2_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_2_bn2 = layers.BatchNormalization()\n",
    "#         self.layer3_2_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Pooling and classification layers\n",
    "#         self.avgpool = layers.GlobalAveragePooling2D()\n",
    "#         self.fc = layers.Dense(num_classes)\n",
    "\n",
    "#     def call(self, x, training=False):\n",
    "#         # Initial layer\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x, training=training)\n",
    "#         x = self.relu1(x)\n",
    "\n",
    "#         # Layer 1 Block 1\n",
    "#         residual = x\n",
    "#         x = self.layer1_0_conv1(x)\n",
    "#         x = self.layer1_0_bn1(x, training=training)\n",
    "#         x = self.layer1_0_relu1(x)\n",
    "#         x = self.layer1_0_conv2(x)\n",
    "#         x = self.layer1_0_bn2(x, training=training)\n",
    "#         x += residual  # Add operation\n",
    "#         x = self.layer1_0_relu2(x)\n",
    "\n",
    "#         # Layer 1 Block 2\n",
    "#         residual = x\n",
    "#         x = self.layer1_1_conv1(x)\n",
    "#         x = self.layer1_1_bn1(x, training=training)\n",
    "#         x = self.layer1_1_relu1(x)\n",
    "#         x = self.layer1_1_conv2(x)\n",
    "#         x = self.layer1_1_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer1_1_relu2(x)\n",
    "\n",
    "#         # Layer 1 Block 3\n",
    "#         residual = x\n",
    "#         x = self.layer1_2_conv1(x)\n",
    "#         x = self.layer1_2_bn1(x, training=training)\n",
    "#         x = self.layer1_2_relu1(x)\n",
    "#         x = self.layer1_2_conv2(x)\n",
    "#         x = self.layer1_2_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer1_2_relu2(x)\n",
    "\n",
    "#         # Layer 2 Block 1 (with downsampling)\n",
    "#         residual = self.layer2_0_downsample(x, training=training)\n",
    "#         x = self.layer2_0_conv1(x)\n",
    "#         x = self.layer2_0_bn1(x, training=training)\n",
    "#         x = self.layer2_0_relu1(x)\n",
    "#         x = self.layer2_0_conv2(x)\n",
    "#         x = self.layer2_0_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer2_0_relu2(x)\n",
    "\n",
    "#         # Layer 2 Block 2\n",
    "#         residual = x\n",
    "#         x = self.layer2_1_conv1(x)\n",
    "#         x = self.layer2_1_bn1(x, training=training)\n",
    "#         x = self.layer2_1_relu1(x)\n",
    "#         x = self.layer2_1_conv2(x)\n",
    "#         x = self.layer2_1_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer2_1_relu2(x)\n",
    "\n",
    "#         # Layer 2 Block 3\n",
    "#         residual = x\n",
    "#         x = self.layer2_2_conv1(x)\n",
    "#         x = self.layer2_2_bn1(x, training=training)\n",
    "#         x = self.layer2_2_relu1(x)\n",
    "#         x = self.layer2_2_conv2(x)\n",
    "#         x = self.layer2_2_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer2_2_relu2(x)\n",
    "\n",
    "#         # Layer 3 Block 1 (with downsampling)\n",
    "#         residual = self.layer3_0_downsample(x, training=training)\n",
    "#         x = self.layer3_0_conv1(x)\n",
    "#         x = self.layer3_0_bn1(x, training=training)\n",
    "#         x = self.layer3_0_relu1(x)\n",
    "#         x = self.layer3_0_conv2(x)\n",
    "#         x = self.layer3_0_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer3_0_relu2(x)\n",
    "\n",
    "#         # Layer 3 Block 2\n",
    "#         residual = x\n",
    "#         x = self.layer3_1_conv1(x)\n",
    "#         x = self.layer3_1_bn1(x, training=training)\n",
    "#         x = self.layer3_1_relu1(x)\n",
    "#         x = self.layer3_1_conv2(x)\n",
    "#         x = self.layer3_1_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer3_1_relu2(x)\n",
    "\n",
    "#         # Layer 3 Block 3\n",
    "#         residual = x\n",
    "#         x = self.layer3_2_conv1(x)\n",
    "#         x = self.layer3_2_bn1(x, training=training)\n",
    "#         x = self.layer3_2_relu1(x)\n",
    "#         x = self.layer3_2_conv2(x)\n",
    "#         x = self.layer3_2_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer3_2_relu2(x)\n",
    "\n",
    "#         # Pooling and classification\n",
    "#         x = self.avgpool(x)\n",
    "#         x = self.fc(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet20_CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 11:43:27.220444: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730893407.236682 3287694 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730893407.242233 3287694 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 11:43:27.260427: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../models/resnet20/unpruned.pth.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights successfully loaded!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m pytorch_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../models/resnet20/unpruned.pth.tar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load your PyTorch model\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# state_dict = pytorch_model['state_dict']  # or pytorch_model.state_dict() if it's a torch.nn.Module\u001b[39;00m\n\u001b[1;32m    124\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m pytorch_model\n",
      "File \u001b[0;32m~/.conda/envs/zkml_bench_env/lib/python3.9/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/zkml_bench_env/lib/python3.9/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/zkml_bench_env/lib/python3.9/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../models/resnet20/unpruned.pth.tar'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Dense, Add, Input, ReLU, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import torch\n",
    "\n",
    "# Define Keras model with named layers that match PyTorch `state_dict` keys\n",
    "def build_keras_model():\n",
    "    input = Input(shape=(32, 32, 3))  # Adjust based on input shape (e.g., CIFAR-10 dimensions)\n",
    "    x = Conv2D(16, (3, 3), padding='same', name='conv1',use_bias=False)(input)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Residual block layers\n",
    "    x = residual_block(x, filters=16, block_prefix='layer1.0')\n",
    "    x = residual_block(x, filters=16, block_prefix='layer1.1')\n",
    "    x = residual_block(x, filters=16, block_prefix='layer1.2')\n",
    "    \n",
    "    x = residual_block(x, filters=32, block_prefix='layer2.0', downsample=True)\n",
    "    x = residual_block(x, filters=32, block_prefix='layer2.1')\n",
    "    x = residual_block(x, filters=32, block_prefix='layer2.2')\n",
    "    \n",
    "    x = residual_block(x, filters=64, block_prefix='layer3.0', downsample=True)\n",
    "    x = residual_block(x, filters=64, block_prefix='layer3.1')\n",
    "    x = residual_block(x, filters=64, block_prefix='layer3.2')\n",
    "    \n",
    "    # Fully connected (dense) layer\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Dense(100, name='fc',use_bias=True)(x)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Helper function to create a named residual block\n",
    "def residual_block(x, filters, block_prefix, downsample=False):\n",
    "    identity = x\n",
    "    if downsample:\n",
    "        identity = Conv2D(filters, (1, 1), strides=2, name=f'{block_prefix}.downsample.0',use_bias=False)(identity)\n",
    "        identity = BatchNormalization(name=f'{block_prefix}.downsample.1')(identity)\n",
    "        x = Conv2D(filters, (3, 3), strides=2, padding='same', name=f'{block_prefix}.conv1',use_bias=False)(x)\n",
    "    else:\n",
    "        x = Conv2D(filters, (3, 3), padding='same', name=f'{block_prefix}.conv1',use_bias=False)(x)\n",
    "    \n",
    "    x = BatchNormalization(name=f'{block_prefix}.bn1')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters, (3, 3), padding='same', name=f'{block_prefix}.conv2',use_bias=False)(x)\n",
    "    x = BatchNormalization(name=f'{block_prefix}.bn2')(x)\n",
    "    \n",
    "    x = Add()([x, identity])\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_pytorch_weights_to_keras(pytorch_state_dict, keras_model):\n",
    "    for layer in keras_model.layers:\n",
    "        print(\"=== Layer === : \", layer.name)\n",
    "        # Prepare PyTorch keys for corresponding Keras layer\n",
    "        layer_name = layer.name\n",
    "        if isinstance(layer, Conv2D):\n",
    "            # weight_orig_key = f'{layer_name}.weight_orig'\n",
    "            weight_orig_key = f'{layer_name}.weight'\n",
    "            # weight_mask_key = f'{layer_name}.weight_mask'\n",
    "            if weight_orig_key in pytorch_state_dict:\n",
    "                print(\"shape pytroch: \", pytorch_state_dict[weight_orig_key].shape,\" \\t shape keras: \", layer.get_weights()[0].shape)\n",
    "\n",
    "                layer.set_weights([pytorch_state_dict[weight_orig_key].numpy().transpose(2, 3, 1, 0)])\n",
    "            # elif weight_mask_key in pytorch_state_dict:\n",
    "            #     layer.set_weights([pytorch_state_dict[weight_mask_key].numpy()])\n",
    "            else:\n",
    "                print(f\"Error: Weights not found for layer {layer_name}\")\n",
    "                return\n",
    "            \n",
    "            # check if conv needs bias\n",
    "            if len(layer.get_weights()) > 1:\n",
    "                bias_key = f'{layer_name}.bias'\n",
    "                if bias_key in pytorch_state_dict:\n",
    "                    layer.set_weights([pytorch_state_dict[weight_orig_key].numpy().transpose(2, 3, 1, 0), pytorch_state_dict[bias_key].numpy()])\n",
    "                else:\n",
    "                    print(f\"Error: Bias not found for layer {layer_name}\")\n",
    "                    return\n",
    "\n",
    "        elif isinstance(layer, BatchNormalization):\n",
    "            weight_key = f'{layer_name}.weight'\n",
    "            bias_key = f'{layer_name}.bias'\n",
    "            mean_key = f'{layer_name}.running_mean'\n",
    "            var_key = f'{layer_name}.running_var'\n",
    "            if all(key in pytorch_state_dict for key in [weight_key, bias_key, mean_key, var_key]):\n",
    "                layer.set_weights([\n",
    "                    pytorch_state_dict[weight_key].numpy(),\n",
    "                    pytorch_state_dict[bias_key].numpy(),\n",
    "                    pytorch_state_dict[mean_key].numpy(),\n",
    "                    pytorch_state_dict[var_key].numpy()\n",
    "                ])\n",
    "            else:\n",
    "                print(f\"Error: Weights not found for layer {layer_name}\")\n",
    "                return\n",
    "\n",
    "        elif isinstance(layer, Dense):\n",
    "            weight_orig_key = f'{layer_name}.weight'\n",
    "            # weight_mask_key = f'{layer_name}.weight_mask'\n",
    "            bias_key = f'{layer_name}.bias'\n",
    "            if weight_orig_key in pytorch_state_dict and bias_key in pytorch_state_dict:\n",
    "                layer.set_weights([\n",
    "                    pytorch_state_dict[weight_orig_key].numpy().T,  # Keras uses [input_dim, output_dim]\n",
    "                    pytorch_state_dict[bias_key].numpy()\n",
    "                ])\n",
    "            # elif weight_mask_key in pytorch_state_dict and bias_key in pytorch_state_dict:\n",
    "            #     layer.set_weights([\n",
    "            #         pytorch_state_dict[weight_mask_key].numpy().T,\n",
    "            #         pytorch_state_dict[bias_key].numpy()\n",
    "            #     ])\n",
    "            else:\n",
    "                print(f\"Error: Weights not found for layer {layer_name}\")\n",
    "                return\n",
    "            \n",
    "        else:\n",
    "            print(f\"------------- Skipping layer {layer_name}\")\n",
    "\n",
    "    print(\"Weights successfully loaded!\")\n",
    "\n",
    "# Example usage:\n",
    "pytorch_model = torch.load('../../models/resnet20/unpruned.pth.tar',map_location=\"cpu\")  # Load your PyTorch model\n",
    "# state_dict = pytorch_model['state_dict']  # or pytorch_model.state_dict() if it's a torch.nn.Module\n",
    "state_dict = pytorch_model\n",
    "keras_model = build_keras_model()\n",
    "\n",
    "# load the weights\n",
    "def apply_mask_and_zero_out(state_dict):\n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for key, value in state_dict.items():\n",
    "        if \"weight_mask\" in key:\n",
    "            # Extract corresponding weight_orig and weight_mask\n",
    "            weight_orig_key = key.replace(\"weight_mask\", \"weight_orig\")\n",
    "            weight_mask = value\n",
    "            weight_orig = state_dict[weight_orig_key]\n",
    "\n",
    "            # Apply the mask: keep values in weight_orig corresponding to mask = 1, zero out others\n",
    "            new_weights = weight_orig * weight_mask\n",
    "\n",
    "            # Update the new_state_dict with the proper key (removing _orig)\n",
    "            new_key = weight_orig_key.replace(\"weight_orig\", \"weight\")\n",
    "            new_state_dict[new_key] = new_weights\n",
    "        else:\n",
    "            # Keep other parameters (bias, running_mean, running_var, etc.) as they are\n",
    "            if \"weight_orig\" not in key and \"weight_mask\" not in key:\n",
    "                new_state_dict[key] = value\n",
    "    return new_state_dict\n",
    "\n",
    "new_state_dict = apply_mask_and_zero_out(state_dict)\n",
    "load_pytorch_weights_to_keras(new_state_dict, keras_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy of keras_model on CIFAR-100 test set\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "cifar100_nm = [[0.5071,0.4867,0.4408],[0.2675,0.2565,0.2761]]\n",
    "\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "# apply cifar100_nm to x_test\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_test = x_test - cifar100_nm[1]\n",
    "x_test = x_test / cifar100_nm[0]\n",
    "y_test = to_categorical(y_test, num_classes=100)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_train = x_train - cifar100_nm[1]\n",
    "x_train = x_train / cifar100_nm[0]\n",
    "y_train = to_categorical(y_train, num_classes=100)\n",
    "\n",
    "# train the model\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# define small learning rate\n",
    "keras_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=loss, metrics=['accuracy'])\n",
    "keras_model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "keras_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# set model on evaluation mode\n",
    "_, accuracy = keras_model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"Accuracy on CIFAR-100 test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "y_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.7843741  -1.4789039   2.3753865   3.5402687   1.8999168  -3.2317297\n",
      "   2.7143314   0.63953024  2.6151376  -1.4918125   0.06948037  1.1175079\n",
      "  -3.8698897  -0.5297159   3.7554712   4.4577184   0.49322167  0.47873765\n",
      "  -0.8673161   9.253324   -2.5381029   0.33410478 -1.0929856  -3.568278\n",
      "  -2.3266678   0.6484118   0.5271331  -2.5334227  -2.5681252   1.016406\n",
      "  -3.968857    3.4909167   1.3832017  -0.15196204  2.0189972   0.94015527\n",
      "   0.36541107  2.5023901   4.491131   -2.931189   -1.0155636   2.521766\n",
      "   2.1847847   3.0698605  -1.908736   -0.16996153  0.75252354 -1.1392367\n",
      "   3.3628707  -0.62917477  2.9287121   2.1253362  -1.5417162  -3.2286441\n",
      "   2.4740171   1.7161465  -0.81996936  1.3826659  -2.413763    0.25392666\n",
      "  -1.7173617  -1.7794143   1.0224409  -2.70311     1.2284832   3.569923\n",
      "   2.3190382   0.7575056  -2.7425761  -3.0991342   1.2331629  -5.880378\n",
      "   0.7281624  -3.0917003   1.8738917   0.2389269  -2.4675617  -0.11519422\n",
      "  -0.6453781  -0.8296769   1.3465298  -3.8121881   0.73303056 -1.5333856\n",
      "  -0.26830685 -1.8492717  -1.1058418  -2.1134307   4.289868    2.8305826\n",
      "  -0.5931842  -1.3261147   2.2445416  -2.142495   -3.8754482  -5.634035\n",
      "  -1.7085124   0.08085093 -0.9341868  -2.2095299 ]], shape=(1, 100), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz/assets\n",
      "2024-11-05 01:28:40.839995: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-11-05 01:28:40.840312: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-11-05 01:28:40.841398: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz\n",
      "2024-11-05 01:28:40.846239: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-11-05 01:28:40.846245: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz\n",
      "2024-11-05 01:28:40.865756: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-11-05 01:28:41.006232: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz\n",
      "2024-11-05 01:28:41.043913: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 202518 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = keras_model\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "cifar100 = tf.keras.datasets.cifar100\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "# apply cifar100_nm to x_test\n",
    "train_images = train_images.astype('float32')\n",
    "train_images = train_images - cifar100_nm[1]\n",
    "train_images = train_images / cifar100_nm[0]\n",
    "train_labels = train_labels.astype('int32')\n",
    "test_images = test_images.astype('float32')\n",
    "test_images = test_images - cifar100_nm[1]\n",
    "test_images = test_images / cifar100_nm[0]\n",
    "test_labels = test_labels.astype('int32')\n",
    "\n",
    "\n",
    "# Compile the model (necessary for training, but for inference, it’s optional)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Perform inference with a sample image from CIFAR-100\n",
    "sample_image = train_images[0:1]  # Select one sample\n",
    "sample_image = tf.convert_to_tensor(sample_image, dtype=tf.float32)\n",
    "\n",
    "# Ensure the model is in evaluation mode (no training mode needed)\n",
    "predictions = model(sample_image, training=False)  # training=False ensures evaluation mode\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# Convert the model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert() # experimental_new_converter=False\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('../../models/resnet20/resnet20.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on CIFAR-100 test set: 66.12%\n"
     ]
    }
   ],
   "source": [
    "# compute acc of tflite model\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path='../../models/resnet20/resnet20.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on cifar100 test set\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(test_images)):\n",
    "    input_data = test_images[i:i+1]\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    pred_label = np.argmax(output_data)\n",
    "    true_label = test_labels[i]\n",
    "    if pred_label == true_label:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on CIFAR-100 test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, 32, 32, 16)           432       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)    (None, 32, 32, 16)           64        ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)             (None, 32, 32, 16)           0         ['bn1[0][0]']                 \n",
      "                                                                                                  \n",
      " layer1.0.conv1 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_38[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.0.bn1 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.0.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)             (None, 32, 32, 16)           0         ['layer1.0.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer1.0.conv2 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_39[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.0.bn2 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.0.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 32, 32, 16)           0         ['layer1.0.bn2[0][0]',        \n",
      "                                                                     're_lu_38[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)             (None, 32, 32, 16)           0         ['add_18[0][0]']              \n",
      "                                                                                                  \n",
      " layer1.1.conv1 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_40[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.1.bn1 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.1.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)             (None, 32, 32, 16)           0         ['layer1.1.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer1.1.conv2 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_41[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.1.bn2 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.1.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 32, 32, 16)           0         ['layer1.1.bn2[0][0]',        \n",
      "                                                                     're_lu_40[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)             (None, 32, 32, 16)           0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " layer1.2.conv1 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_42[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.2.bn1 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.2.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)             (None, 32, 32, 16)           0         ['layer1.2.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer1.2.conv2 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_43[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.2.bn2 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.2.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, 32, 32, 16)           0         ['layer1.2.bn2[0][0]',        \n",
      "                                                                     're_lu_42[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)             (None, 32, 32, 16)           0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " layer2.0.conv1 (Conv2D)     (None, 16, 16, 32)           4608      ['re_lu_44[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.0.bn1 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.0.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)             (None, 16, 16, 32)           0         ['layer2.0.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer2.0.conv2 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_45[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.0.downsample.0 (Con  (None, 16, 16, 32)           512       ['re_lu_44[0][0]']            \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.0.bn2 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.0.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " layer2.0.downsample.1 (Bat  (None, 16, 16, 32)           128       ['layer2.0.downsample.0[0][0]'\n",
      " chNormalization)                                                   ]                             \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, 16, 16, 32)           0         ['layer2.0.bn2[0][0]',        \n",
      "                                                                     'layer2.0.downsample.1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)             (None, 16, 16, 32)           0         ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " layer2.1.conv1 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_46[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.1.bn1 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.1.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)             (None, 16, 16, 32)           0         ['layer2.1.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer2.1.conv2 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_47[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.1.bn2 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.1.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, 16, 16, 32)           0         ['layer2.1.bn2[0][0]',        \n",
      "                                                                     're_lu_46[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)             (None, 16, 16, 32)           0         ['add_22[0][0]']              \n",
      "                                                                                                  \n",
      " layer2.2.conv1 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_48[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.2.bn1 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.2.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)             (None, 16, 16, 32)           0         ['layer2.2.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer2.2.conv2 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_49[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.2.bn2 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.2.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, 16, 16, 32)           0         ['layer2.2.bn2[0][0]',        \n",
      "                                                                     're_lu_48[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)             (None, 16, 16, 32)           0         ['add_23[0][0]']              \n",
      "                                                                                                  \n",
      " layer3.0.conv1 (Conv2D)     (None, 8, 8, 64)             18432     ['re_lu_50[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.0.bn1 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.0.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)             (None, 8, 8, 64)             0         ['layer3.0.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer3.0.conv2 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_51[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.0.downsample.0 (Con  (None, 8, 8, 64)             2048      ['re_lu_50[0][0]']            \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.0.bn2 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.0.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " layer3.0.downsample.1 (Bat  (None, 8, 8, 64)             256       ['layer3.0.downsample.0[0][0]'\n",
      " chNormalization)                                                   ]                             \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, 8, 8, 64)             0         ['layer3.0.bn2[0][0]',        \n",
      "                                                                     'layer3.0.downsample.1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)             (None, 8, 8, 64)             0         ['add_24[0][0]']              \n",
      "                                                                                                  \n",
      " layer3.1.conv1 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.1.bn1 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.1.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)             (None, 8, 8, 64)             0         ['layer3.1.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer3.1.conv2 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_53[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.1.bn2 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.1.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, 8, 8, 64)             0         ['layer3.1.bn2[0][0]',        \n",
      "                                                                     're_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)             (None, 8, 8, 64)             0         ['add_25[0][0]']              \n",
      "                                                                                                  \n",
      " layer3.2.conv1 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_54[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.2.bn1 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.2.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)             (None, 8, 8, 64)             0         ['layer3.2.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer3.2.conv2 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_55[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.2.bn2 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.2.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, 8, 8, 64)             0         ['layer3.2.bn2[0][0]',        \n",
      "                                                                     're_lu_54[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)             (None, 8, 8, 64)             0         ['add_26[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['re_lu_56[0][0]']            \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " fc (Dense)                  (None, 100)                  6500      ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 279892 (1.07 MB)\n",
      "Trainable params: 278324 (1.06 MB)\n",
      "Non-trainable params: 1568 (6.12 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to .h5 file\n",
    "# model.save_weights(\"resnet20.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 7.npy and forward it to the model\n",
    "import numpy as np\n",
    "data = np.load('7.npy')\n",
    "# reshape data to 4D\n",
    "data = np.reshape(data, (1, 3,32,32))\n",
    "\n",
    "# forward the data to the model\n",
    "data = tf.convert_to_tensor(data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/zkml_bench_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 46, 47, 48, 49}\n",
      "Add inputs:  [48, 46]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52}\n",
      "Add inputs:  [51, 49]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55}\n",
      "Add inputs:  [54, 52]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59}\n",
      "Add inputs:  [57, 58]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62}\n",
      "Add inputs:  [61, 59]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65}\n",
      "Add inputs:  [64, 62]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69}\n",
      "Add inputs:  [67, 68]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72}\n",
      "Add inputs:  [71, 69]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75}\n",
      "Add inputs:  [74, 72]\n",
      "True True\n",
      "[{'layer_type': 'Conv2D', 'inp_idxes': [0, 22, 1], 'inp_shapes': [[1, 32, 32, 3], [16, 3, 3, 3], [16]], 'out_idxes': [46], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [46, 23, 2], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [47], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [47, 24, 11], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [48], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [48, 46], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [49], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [49, 25, 3], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [50], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [50, 26, 12], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [51], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [51, 49], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [52], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [52, 27, 4], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [53], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [53, 28, 13], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [54], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [54, 52], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [55], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [55, 29, 5], 'inp_shapes': [[1, 32, 32, 16], [32, 3, 3, 16], [32]], 'out_idxes': [56], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [56, 30, 14], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [57], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [55, 31, 15], 'inp_shapes': [[1, 32, 32, 16], [32, 1, 1, 16], [32]], 'out_idxes': [58], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [57, 58], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [59], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [59, 32, 6], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [60], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [60, 33, 16], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [61], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [61, 59], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [62], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [62, 34, 7], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [63], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [63, 35, 17], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [64], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [64, 62], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [65], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [65, 36, 8], 'inp_shapes': [[1, 16, 16, 32], [64, 3, 3, 32], [64]], 'out_idxes': [66], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [66, 37, 18], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [67], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [65, 38, 19], 'inp_shapes': [[1, 16, 16, 32], [64, 1, 1, 32], [64]], 'out_idxes': [68], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [67, 68], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [69], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [69, 39, 9], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [70], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [70, 40, 20], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [71], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [71, 69], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [72], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [72, 41, 10], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [73], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [73, 42, 21], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [74], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [74, 72], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [75], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [75, 44], 'inp_shapes': [[1, 8, 8, 64], [2]], 'out_idxes': [76], 'out_shapes': [[1, 64]], 'params': [1, 2], 'mask': []}, {'layer_type': 'FullyConnected', 'inp_idxes': [76, 45, 43], 'inp_shapes': [[1, 64], [100, 64], [100]], 'out_idxes': [77], 'out_shapes': [[1, 100]], 'params': [0], 'mask': []}]\n",
      "\n",
      "keep tensors: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76}\n",
      "skipping generated tensor: 0, b'serving_default_input_3:0'\n",
      "skipping generated tensor: 46, b'model_2/re_lu_38/Relu;model_2/bn1/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/conv1/Conv2D'\n",
      "skipping generated tensor: 47, b'model_2/re_lu_39/Relu;model_2/layer1.0.bn1/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.0.conv1/Conv2D'\n",
      "skipping generated tensor: 48, b'model_2/layer1.0.bn2/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.0.conv2/Conv2D'\n",
      "skipping generated tensor: 49, b'model_2/re_lu_40/Relu;model_2/add_18/add'\n",
      "skipping generated tensor: 50, b'model_2/re_lu_41/Relu;model_2/layer1.1.bn1/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.1.conv1/Conv2D'\n",
      "skipping generated tensor: 51, b'model_2/layer1.1.bn2/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.1.conv2/Conv2D'\n",
      "skipping generated tensor: 52, b'model_2/re_lu_42/Relu;model_2/add_19/add'\n",
      "skipping generated tensor: 53, b'model_2/re_lu_43/Relu;model_2/layer1.2.bn1/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.2.conv1/Conv2D'\n",
      "skipping generated tensor: 54, b'model_2/layer1.2.bn2/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D'\n",
      "skipping generated tensor: 55, b'model_2/re_lu_44/Relu;model_2/add_20/add'\n",
      "skipping generated tensor: 56, b'model_2/re_lu_45/Relu;model_2/layer2.0.bn1/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.0.conv1/Conv2D'\n",
      "skipping generated tensor: 57, b'model_2/layer2.0.bn2/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.0.conv2/Conv2D'\n",
      "skipping generated tensor: 58, b'model_2/layer2.0.downsample.1/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.0.downsample.0/Conv2D'\n",
      "skipping generated tensor: 59, b'model_2/re_lu_46/Relu;model_2/add_21/add'\n",
      "skipping generated tensor: 60, b'model_2/re_lu_47/Relu;model_2/layer2.1.bn1/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.1.conv1/Conv2D'\n",
      "skipping generated tensor: 61, b'model_2/layer2.1.bn2/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.1.conv2/Conv2D'\n",
      "skipping generated tensor: 62, b'model_2/re_lu_48/Relu;model_2/add_22/add'\n",
      "skipping generated tensor: 63, b'model_2/re_lu_49/Relu;model_2/layer2.2.bn1/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.2.conv1/Conv2D'\n",
      "skipping generated tensor: 64, b'model_2/layer2.2.bn2/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D'\n",
      "skipping generated tensor: 65, b'model_2/re_lu_50/Relu;model_2/add_23/add'\n",
      "skipping generated tensor: 66, b'model_2/re_lu_51/Relu;model_2/layer3.0.bn1/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.0.conv1/Conv2D'\n",
      "skipping generated tensor: 67, b'model_2/layer3.0.bn2/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.0.conv2/Conv2D'\n",
      "skipping generated tensor: 68, b'model_2/layer3.0.downsample.1/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.0.downsample.0/Conv2D'\n",
      "skipping generated tensor: 69, b'model_2/re_lu_52/Relu;model_2/add_24/add'\n",
      "skipping generated tensor: 70, b'model_2/re_lu_53/Relu;model_2/layer3.1.bn1/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.1.conv1/Conv2D'\n",
      "skipping generated tensor: 71, b'model_2/layer3.1.bn2/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.1.conv2/Conv2D'\n",
      "skipping generated tensor: 72, b'model_2/re_lu_54/Relu;model_2/add_25/add'\n",
      "skipping generated tensor: 73, b'model_2/re_lu_55/Relu;model_2/layer3.2.bn1/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.2.conv1/Conv2D'\n",
      "skipping generated tensor: 74, b'model_2/layer3.2.bn2/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D'\n",
      "skipping generated tensor: 75, b'model_2/re_lu_56/Relu;model_2/add_26/add'\n",
      "skipping generated tensor: 76, b'model_2/global_average_pooling2d_2/Mean'\n",
      "\n",
      "{'layer_type': 'FullyConnected', 'inp_idxes': [76, 45, 43], 'inp_shapes': [[1, 64], [100, 64], [100]], 'out_idxes': [77], 'out_shapes': [[1, 100]], 'params': [0], 'mask': []}\n",
      "dict_keys(['global_sf', 'k', 'num_cols', 'num_random', 'inp_idxes', 'out_idxes', 'layers', 'tensors', 'use_selectors', 'commit_before', 'commit_after'])\n",
      "[77]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/converter.py', '--model', '../../models/resnet20/resnet20.tflite', '--model_output', 'converted_model_new.msgpack', '--config_output', 'config_new.msgpack', '--scale_factor', '4096', '--k', '21', '--num_cols', '128', '--num_randoms', '262144'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert model\n",
    "# !python ./tools/converter.py --model ./model.tflite --model_output converted_model_new.msgpack --config_output config_new.msgpack --scale_factor 512 --k 20 --num_cols 20 --num_randoms 4096\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/converter.py', \n",
    "    '--model', '../../models/resnet20/resnet20.tflite',\n",
    "    # '--model', '../../models/resnet20/resnet20_cifar100_dense.tflite',\n",
    "    '--model_output', 'converted_model_new.msgpack',\n",
    "    '--config_output', 'config_new.msgpack',\n",
    "    '--scale_factor', '4096',\n",
    "    '--k', '21',\n",
    "    '--num_cols', '128',\n",
    "    # '--num_randoms', '16384'\n",
    "    '--num_randoms', '262144'\n",
    "]\n",
    "\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/input_converter.py', '--model_config', 'converted_model_new.msgpack', '--inputs', '7.npy', '--output', 'example_inp_new.msgpack'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert input\n",
    "import subprocess\n",
    "\n",
    "# !python ./tools/input_converter.py --model_config converted_model_new.msgpack --inputs 7.npy --output example_inp_new.msgpack\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/input_converter.py', \n",
    "    '--model_config', 'converted_model_new.msgpack',\n",
    "    '--inputs', '7.npy',\n",
    "    '--output', 'example_inp_new.msgpack'\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command_dir:  ./bin/m1_mac/\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "command_dir = './bin/m1_mac/' if platform.processor() == \"arm\" else './bin/'\n",
    "print(\"command_dir: \", command_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./bin/test_circuit ./converted_model_new.msgpack ./example_inp_new.msgpack kzg\n",
    "\n",
    "# Command to run\n",
    "command = [command_dir + 'test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m command \u001b[38;5;241m=\u001b[39m [command_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_circuit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverted_model_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample_inp_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkzg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Run the command\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:507\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    509\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1126\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1189\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1917\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1875\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1875\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1879\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Command to run\n",
    "command = [command_dir + 'time_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# efficientb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 20:44:13.448833: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:44:13.492928: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 20:44:13.494079: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 20:44:14.273247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Dense, Add, Input, ReLU, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 20:44:26.228463: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "def build_keras_model():\n",
    "    # keras_model = EfficientNetB0(weights='imagenet', include_top=True)\n",
    "    keras_model = EfficientNetB0(weights='imagenet')\n",
    "    return keras_model\n",
    "\n",
    "\n",
    "# pytorch_model = torch.load('../../models/efficientnetb0/unpruned.pth.tar',map_location=\"cpu\")  # Load your PyTorch model\n",
    "# state_dict = pytorch_model['state_dict']  # or pytorch_model.state_dict() if it's a torch.nn.Module\n",
    "# state_dict = pytorch_model\n",
    "keras_model = build_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50017 files belonging to 1000 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 21:03:59.222944: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 30115835904 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Load imageneet dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import numpy as np\n",
    "\n",
    "# Path to your ImageNet validation directory\n",
    "imagenet_test_dir = '/media/mmaheri/mohamad_ssd/imagenet/val'  # Update this with your path\n",
    "\n",
    "keras_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # appropriate for integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Prepare the test dataset\n",
    "batch_size = 32  # Adjust this based on memory availability\n",
    "img_size = (224, 224)  # EfficientNetB0 expects 224x224 images\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    imagenet_test_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=img_size\n",
    ")\n",
    "\n",
    "# Preprocessing: EfficientNet requires special input preprocessing\n",
    "def preprocess(image, label):\n",
    "    image = preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# sampled_images, sampled_labels = next(iter(test_dataset))\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate over the entire test dataset\n",
    "for images, labels in test_dataset:\n",
    "    all_images.append(images)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "# Concatenate all images and labels\n",
    "all_images = tf.concat(all_images, axis=0)\n",
    "all_labels = tf.concat(all_labels, axis=0)\n",
    "all_labels_one_hot = tf.keras.utils.to_categorical(all_labels, num_classes=1000)\n",
    "\n",
    "# sampled_images, sampled_labels_one_hot = all_images[0:128] , all_labels_one_hot[0:128]\n",
    "sampled_images, sampled_labels_one_hot = all_images[0:] , all_labels_one_hot[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imagenet dataset\n",
    "# from benchmark import cnn_datasets\n",
    "# # define object for args\n",
    "# class Args:\n",
    "#     def __init__(self):\n",
    "#         self.model = 'efficientnetb0'\n",
    "#         self.imagenet_dir = '/media/mmaheri/mohamad_ssd/imagenet/'\n",
    "#         self.ignore_train_loader = True\n",
    "\n",
    "# args = Args()\n",
    "# tests, true_labels = cnn_datasets(dataset_name=\"imagenet\",args=args)\n",
    "\n",
    "# sampled_images = tests\n",
    "# sampled_labels_one_hot = tf.keras.utils.to_categorical(true_labels, num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "# import random\n",
    "\n",
    "\n",
    "# def load_imagenet_test_subset(data_dir, batch_size, target_size=(224, 224), sample_size=100):\n",
    "#     test_dataset = image_dataset_from_directory(\n",
    "#         data_dir,\n",
    "#         labels='inferred',\n",
    "#         label_mode='int',\n",
    "#         color_mode='rgb',\n",
    "#         batch_size=batch_size,\n",
    "#         image_size=target_size,\n",
    "#         shuffle=True,\n",
    "#         seed=42\n",
    "#     )\n",
    "\n",
    "#     all_images, all_labels = [], []\n",
    "#     for images, labels in test_dataset.take(sample_size // batch_size):\n",
    "#         all_images.append(images)\n",
    "#         all_labels.append(labels)\n",
    "    \n",
    "#     all_images = tf.concat(all_images, axis=0)\n",
    "#     all_labels = tf.concat(all_labels, axis=0)\n",
    "    \n",
    "#     # Sample `sample_size` images and labels randomly from the collected images\n",
    "#     indices = random.sample(range(len(all_images)), sample_size)\n",
    "#     sampled_images = tf.gather(all_images, indices)\n",
    "#     sampled_labels = tf.gather(all_labels, indices)\n",
    "\n",
    "#     return sampled_images, sampled_labels\n",
    "\n",
    "# data_dir = \"/media/mmaheri/mohamad_ssd/imagenet/val\"\n",
    "# batch_size = 32  \n",
    "# sample_size = 64  \n",
    "\n",
    "# sampled_images, sampled_labels = load_imagenet_test_subset(data_dir, batch_size, sample_size=sample_size)\n",
    "\n",
    "# # Convert labels to one-hot encoding\n",
    "# num_classes = 1000\n",
    "# sampled_labels_one_hot = tf.keras.utils.to_categorical(sampled_labels, num_classes=num_classes)\n",
    "\n",
    "# # Preprocess the sampled images\n",
    "# sampled_images = tf.keras.applications.efficientnet.preprocess_input(sampled_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Images Shape: (50017, 224, 224, 3)\n",
      "Sampled Labels Shape (One-Hot): (50017, 1000)\n",
      "1564/1564 [==============================] - 546s 348ms/step - loss: 1.0212 - accuracy: 0.7621\n",
      "Accuracy on sampled ImageNet test set: 76.21%\n"
     ]
    }
   ],
   "source": [
    "# Compile and evaluate the model\n",
    "keras_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print shapes for debugging\n",
    "print(f\"Sampled Images Shape: {sampled_images.shape}\")\n",
    "print(f\"Sampled Labels Shape (One-Hot): {sampled_labels_one_hot.shape}\")\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = keras_model.evaluate(sampled_images, sampled_labels_one_hot, verbose=1)\n",
    "print(f\"Accuracy on sampled ImageNet test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(true_labels.shape)\n",
    "# # evaluate the keras model on imagenet\n",
    "# true_labels_one_hot = tf.keras.utils.to_categorical(true_labels, num_classes=1000)\n",
    "# tests = tf.keras.applications.efficientnet.preprocess_input(tests)\n",
    "# keras_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# # set model on evaluation mode\n",
    "# _, accuracy = keras_model.evaluate(tests, true_labels_one_hot, verbose=2)\n",
    "# print(f\"Accuracy on ImageNet test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5z5zrx8x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp5z5zrx8x/assets\n",
      "2024-11-06 21:19:41.229404: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-11-06 21:19:41.229463: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-11-06 21:19:41.229777: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp5z5zrx8x\n",
      "2024-11-06 21:19:41.311921: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-11-06 21:19:41.311976: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp5z5zrx8x\n",
      "2024-11-06 21:19:41.493102: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-11-06 21:19:42.082947: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp5z5zrx8x\n",
      "2024-11-06 21:19:42.356738: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 1126948 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# convert the model to tflite\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import os\n",
    "\n",
    "model = keras_model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert() # experimental_new_converter=False\n",
    "\n",
    "# Save the TFLite model\n",
    "os.makedirs(\"../../models/efficientnetb0\",exist_ok=True)\n",
    "with open('../../models/efficientnetb0/efficientnetb0.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the tflite model\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path='../../models/efficientnetb0/efficientnetb0.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on imagenet test set\n",
    "correct = 0\n",
    "total = 0\n",
    "# sampled_images, sampled_labels_one_hot\n",
    "for i in range(len(sampled_images)):\n",
    "    input_data = sampled_images[i:i+1]\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data.numpy().astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    pred_label = np.argmax(output_data)\n",
    "    true_label = np.argmax(sampled_labels_one_hot[i])\n",
    "    if pred_label == true_label:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on ImageNet test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load 7.npy and forward it to the model\n",
    "rand = np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "np.save(\"7.npy\", rand)\n",
    "\n",
    "data = np.load('7.npy')\n",
    "# reshape data to 4D\n",
    "data = np.reshape(data, (1, 224,224,3))\n",
    "\n",
    "# forward the data to the model\n",
    "data = tf.convert_to_tensor(data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 21:00:37.959827: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 21:00:38.002220: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-06 21:00:38.002788: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 21:00:38.691949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242}\n",
      "Add inputs:  [241, 223]\n",
      "True True\n",
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280}\n",
      "Add inputs:  [279, 261]\n",
      "True True\n",
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318}\n",
      "Add inputs:  [317, 299]\n",
      "True True\n",
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337}\n",
      "Add inputs:  [336, 318]\n",
      "True True\n",
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374}\n",
      "Add inputs:  [373, 355]\n",
      "True True\n",
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393}\n",
      "Add inputs:  [392, 374]\n",
      "True True\n",
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431}\n",
      "Add inputs:  [430, 412]\n",
      "True True\n",
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450}\n",
      "Add inputs:  [449, 431]\n",
      "True True\n",
      "{0, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469}\n",
      "Add inputs:  [468, 450]\n",
      "True True\n",
      "[{'layer_type': 'Mul', 'inp_idxes': [0, 179], 'inp_shapes': [[1, 224, 224, 3], []], 'out_idxes': [182], 'out_shapes': [[1, 224, 224, 3]], 'params': [], 'mask': []}, {'layer_type': 'Sub', 'inp_idxes': [182, 164], 'inp_shapes': [[1, 224, 224, 3], [1, 1, 1, 3]], 'out_idxes': [183], 'out_shapes': [[1, 224, 224, 3]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [183, 163], 'inp_shapes': [[1, 224, 224, 3], [1, 1, 1, 3]], 'out_idxes': [184], 'out_shapes': [[1, 224, 224, 3]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [184, 180], 'inp_shapes': [[1, 224, 224, 3], [3]], 'out_idxes': [185], 'out_shapes': [[1, 224, 224, 3]], 'params': [], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [185, 171], 'inp_shapes': [[1, 224, 224, 3], [4, 2]], 'out_idxes': [186], 'out_shapes': [[1, 225, 225, 3]], 'params': [0, 0, 0, 1, 0, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [186, 98, 17], 'inp_shapes': [[1, 225, 225, 3], [32, 3, 3, 3], [32]], 'out_idxes': [187], 'out_shapes': [[1, 112, 112, 32]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [187], 'inp_shapes': [[1, 112, 112, 32]], 'out_idxes': [188], 'out_shapes': [[1, 112, 112, 32]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [187, 188], 'inp_shapes': [[1, 112, 112, 32], [1, 112, 112, 32]], 'out_idxes': [189], 'out_shapes': [[1, 112, 112, 32]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [189, 18, 1], 'inp_shapes': [[1, 112, 112, 32], [1, 3, 3, 32], [32]], 'out_idxes': [190], 'out_shapes': [[1, 112, 112, 32]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [190], 'inp_shapes': [[1, 112, 112, 32]], 'out_idxes': [191], 'out_shapes': [[1, 112, 112, 32]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [190, 191], 'inp_shapes': [[1, 112, 112, 32], [1, 112, 112, 32]], 'out_idxes': [192], 'out_shapes': [[1, 112, 112, 32]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [192, 166], 'inp_shapes': [[1, 112, 112, 32], [2]], 'out_idxes': [193], 'out_shapes': [[1, 32]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [193], 'inp_shapes': [[1, 32]], 'out_idxes': [194], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [194, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [195], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [195, 167, 167, 168], 'inp_shapes': [[], [], [], []], 'out_idxes': [196], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [193, 196], 'inp_shapes': [[1, 32], [4]], 'out_idxes': [197], 'out_shapes': [[1, 1, 1, 32]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [197, 99, 19], 'inp_shapes': [[1, 1, 1, 32], [8, 1, 1, 32], [8]], 'out_idxes': [198], 'out_shapes': [[1, 1, 1, 8]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [198], 'inp_shapes': [[1, 1, 1, 8]], 'out_idxes': [199], 'out_shapes': [[1, 1, 1, 8]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [198, 199], 'inp_shapes': [[1, 1, 1, 8], [1, 1, 1, 8]], 'out_idxes': [200], 'out_shapes': [[1, 1, 1, 8]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [200, 100, 20], 'inp_shapes': [[1, 1, 1, 8], [32, 1, 1, 8], [32]], 'out_idxes': [201], 'out_shapes': [[1, 1, 1, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [201], 'inp_shapes': [[1, 1, 1, 32]], 'out_idxes': [202], 'out_shapes': [[1, 1, 1, 32]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [192, 202], 'inp_shapes': [[1, 112, 112, 32], [1, 1, 1, 32]], 'out_idxes': [203], 'out_shapes': [[1, 112, 112, 32]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [203, 101, 21], 'inp_shapes': [[1, 112, 112, 32], [16, 1, 1, 32], [16]], 'out_idxes': [204], 'out_shapes': [[1, 112, 112, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [204, 102, 22], 'inp_shapes': [[1, 112, 112, 16], [96, 1, 1, 16], [96]], 'out_idxes': [205], 'out_shapes': [[1, 112, 112, 96]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [205], 'inp_shapes': [[1, 112, 112, 96]], 'out_idxes': [206], 'out_shapes': [[1, 112, 112, 96]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [205, 206], 'inp_shapes': [[1, 112, 112, 96], [1, 112, 112, 96]], 'out_idxes': [207], 'out_shapes': [[1, 112, 112, 96]], 'params': [], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [207, 171], 'inp_shapes': [[1, 112, 112, 96], [4, 2]], 'out_idxes': [208], 'out_shapes': [[1, 113, 113, 96]], 'params': [0, 0, 0, 1, 0, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [208, 23, 2], 'inp_shapes': [[1, 113, 113, 96], [1, 3, 3, 96], [96]], 'out_idxes': [209], 'out_shapes': [[1, 56, 56, 96]], 'params': [1, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [209], 'inp_shapes': [[1, 56, 56, 96]], 'out_idxes': [210], 'out_shapes': [[1, 56, 56, 96]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [209, 210], 'inp_shapes': [[1, 56, 56, 96], [1, 56, 56, 96]], 'out_idxes': [211], 'out_shapes': [[1, 56, 56, 96]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [211, 166], 'inp_shapes': [[1, 56, 56, 96], [2]], 'out_idxes': [212], 'out_shapes': [[1, 96]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [212], 'inp_shapes': [[1, 96]], 'out_idxes': [213], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [213, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [214], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [214, 167, 167, 172], 'inp_shapes': [[], [], [], []], 'out_idxes': [215], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [212, 215], 'inp_shapes': [[1, 96], [4]], 'out_idxes': [216], 'out_shapes': [[1, 1, 1, 96]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [216, 103, 24], 'inp_shapes': [[1, 1, 1, 96], [4, 1, 1, 96], [4]], 'out_idxes': [217], 'out_shapes': [[1, 1, 1, 4]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [217], 'inp_shapes': [[1, 1, 1, 4]], 'out_idxes': [218], 'out_shapes': [[1, 1, 1, 4]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [217, 218], 'inp_shapes': [[1, 1, 1, 4], [1, 1, 1, 4]], 'out_idxes': [219], 'out_shapes': [[1, 1, 1, 4]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [219, 104, 25], 'inp_shapes': [[1, 1, 1, 4], [96, 1, 1, 4], [96]], 'out_idxes': [220], 'out_shapes': [[1, 1, 1, 96]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [220], 'inp_shapes': [[1, 1, 1, 96]], 'out_idxes': [221], 'out_shapes': [[1, 1, 1, 96]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [211, 221], 'inp_shapes': [[1, 56, 56, 96], [1, 1, 1, 96]], 'out_idxes': [222], 'out_shapes': [[1, 56, 56, 96]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [222, 105, 26], 'inp_shapes': [[1, 56, 56, 96], [24, 1, 1, 96], [24]], 'out_idxes': [223], 'out_shapes': [[1, 56, 56, 24]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [223, 106, 27], 'inp_shapes': [[1, 56, 56, 24], [144, 1, 1, 24], [144]], 'out_idxes': [224], 'out_shapes': [[1, 56, 56, 144]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [224], 'inp_shapes': [[1, 56, 56, 144]], 'out_idxes': [225], 'out_shapes': [[1, 56, 56, 144]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [224, 225], 'inp_shapes': [[1, 56, 56, 144], [1, 56, 56, 144]], 'out_idxes': [226], 'out_shapes': [[1, 56, 56, 144]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [226, 28, 3], 'inp_shapes': [[1, 56, 56, 144], [1, 3, 3, 144], [144]], 'out_idxes': [227], 'out_shapes': [[1, 56, 56, 144]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [227], 'inp_shapes': [[1, 56, 56, 144]], 'out_idxes': [228], 'out_shapes': [[1, 56, 56, 144]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [227, 228], 'inp_shapes': [[1, 56, 56, 144], [1, 56, 56, 144]], 'out_idxes': [229], 'out_shapes': [[1, 56, 56, 144]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [229, 166], 'inp_shapes': [[1, 56, 56, 144], [2]], 'out_idxes': [230], 'out_shapes': [[1, 144]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [230], 'inp_shapes': [[1, 144]], 'out_idxes': [231], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [231, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [232], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [232, 167, 167, 173], 'inp_shapes': [[], [], [], []], 'out_idxes': [233], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [230, 233], 'inp_shapes': [[1, 144], [4]], 'out_idxes': [234], 'out_shapes': [[1, 1, 1, 144]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [234, 107, 29], 'inp_shapes': [[1, 1, 1, 144], [6, 1, 1, 144], [6]], 'out_idxes': [235], 'out_shapes': [[1, 1, 1, 6]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [235], 'inp_shapes': [[1, 1, 1, 6]], 'out_idxes': [236], 'out_shapes': [[1, 1, 1, 6]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [235, 236], 'inp_shapes': [[1, 1, 1, 6], [1, 1, 1, 6]], 'out_idxes': [237], 'out_shapes': [[1, 1, 1, 6]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [237, 108, 30], 'inp_shapes': [[1, 1, 1, 6], [144, 1, 1, 6], [144]], 'out_idxes': [238], 'out_shapes': [[1, 1, 1, 144]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [238], 'inp_shapes': [[1, 1, 1, 144]], 'out_idxes': [239], 'out_shapes': [[1, 1, 1, 144]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [229, 239], 'inp_shapes': [[1, 56, 56, 144], [1, 1, 1, 144]], 'out_idxes': [240], 'out_shapes': [[1, 56, 56, 144]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [240, 109, 31], 'inp_shapes': [[1, 56, 56, 144], [24, 1, 1, 144], [24]], 'out_idxes': [241], 'out_shapes': [[1, 56, 56, 24]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [241, 223], 'inp_shapes': [[1, 56, 56, 24], [1, 56, 56, 24]], 'out_idxes': [242], 'out_shapes': [[1, 56, 56, 24]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [242, 110, 32], 'inp_shapes': [[1, 56, 56, 24], [144, 1, 1, 24], [144]], 'out_idxes': [243], 'out_shapes': [[1, 56, 56, 144]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [243], 'inp_shapes': [[1, 56, 56, 144]], 'out_idxes': [244], 'out_shapes': [[1, 56, 56, 144]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [243, 244], 'inp_shapes': [[1, 56, 56, 144], [1, 56, 56, 144]], 'out_idxes': [245], 'out_shapes': [[1, 56, 56, 144]], 'params': [], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [245, 174], 'inp_shapes': [[1, 56, 56, 144], [4, 2]], 'out_idxes': [246], 'out_shapes': [[1, 59, 59, 144]], 'params': [0, 0, 1, 2, 1, 2, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [246, 33, 4], 'inp_shapes': [[1, 59, 59, 144], [1, 5, 5, 144], [144]], 'out_idxes': [247], 'out_shapes': [[1, 28, 28, 144]], 'params': [1, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [247], 'inp_shapes': [[1, 28, 28, 144]], 'out_idxes': [248], 'out_shapes': [[1, 28, 28, 144]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [247, 248], 'inp_shapes': [[1, 28, 28, 144], [1, 28, 28, 144]], 'out_idxes': [249], 'out_shapes': [[1, 28, 28, 144]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [249, 166], 'inp_shapes': [[1, 28, 28, 144], [2]], 'out_idxes': [250], 'out_shapes': [[1, 144]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [250], 'inp_shapes': [[1, 144]], 'out_idxes': [251], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [251, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [252], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [252, 167, 167, 173], 'inp_shapes': [[], [], [], []], 'out_idxes': [253], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [250, 253], 'inp_shapes': [[1, 144], [4]], 'out_idxes': [254], 'out_shapes': [[1, 1, 1, 144]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [254, 111, 34], 'inp_shapes': [[1, 1, 1, 144], [6, 1, 1, 144], [6]], 'out_idxes': [255], 'out_shapes': [[1, 1, 1, 6]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [255], 'inp_shapes': [[1, 1, 1, 6]], 'out_idxes': [256], 'out_shapes': [[1, 1, 1, 6]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [255, 256], 'inp_shapes': [[1, 1, 1, 6], [1, 1, 1, 6]], 'out_idxes': [257], 'out_shapes': [[1, 1, 1, 6]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [257, 112, 35], 'inp_shapes': [[1, 1, 1, 6], [144, 1, 1, 6], [144]], 'out_idxes': [258], 'out_shapes': [[1, 1, 1, 144]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [258], 'inp_shapes': [[1, 1, 1, 144]], 'out_idxes': [259], 'out_shapes': [[1, 1, 1, 144]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [249, 259], 'inp_shapes': [[1, 28, 28, 144], [1, 1, 1, 144]], 'out_idxes': [260], 'out_shapes': [[1, 28, 28, 144]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [260, 113, 36], 'inp_shapes': [[1, 28, 28, 144], [40, 1, 1, 144], [40]], 'out_idxes': [261], 'out_shapes': [[1, 28, 28, 40]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [261, 114, 37], 'inp_shapes': [[1, 28, 28, 40], [240, 1, 1, 40], [240]], 'out_idxes': [262], 'out_shapes': [[1, 28, 28, 240]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [262], 'inp_shapes': [[1, 28, 28, 240]], 'out_idxes': [263], 'out_shapes': [[1, 28, 28, 240]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [262, 263], 'inp_shapes': [[1, 28, 28, 240], [1, 28, 28, 240]], 'out_idxes': [264], 'out_shapes': [[1, 28, 28, 240]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [264, 38, 5], 'inp_shapes': [[1, 28, 28, 240], [1, 5, 5, 240], [240]], 'out_idxes': [265], 'out_shapes': [[1, 28, 28, 240]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [265], 'inp_shapes': [[1, 28, 28, 240]], 'out_idxes': [266], 'out_shapes': [[1, 28, 28, 240]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [265, 266], 'inp_shapes': [[1, 28, 28, 240], [1, 28, 28, 240]], 'out_idxes': [267], 'out_shapes': [[1, 28, 28, 240]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [267, 166], 'inp_shapes': [[1, 28, 28, 240], [2]], 'out_idxes': [268], 'out_shapes': [[1, 240]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [268], 'inp_shapes': [[1, 240]], 'out_idxes': [269], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [269, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [270], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [270, 167, 167, 175], 'inp_shapes': [[], [], [], []], 'out_idxes': [271], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [268, 271], 'inp_shapes': [[1, 240], [4]], 'out_idxes': [272], 'out_shapes': [[1, 1, 1, 240]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [272, 115, 39], 'inp_shapes': [[1, 1, 1, 240], [10, 1, 1, 240], [10]], 'out_idxes': [273], 'out_shapes': [[1, 1, 1, 10]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [273], 'inp_shapes': [[1, 1, 1, 10]], 'out_idxes': [274], 'out_shapes': [[1, 1, 1, 10]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [273, 274], 'inp_shapes': [[1, 1, 1, 10], [1, 1, 1, 10]], 'out_idxes': [275], 'out_shapes': [[1, 1, 1, 10]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [275, 116, 40], 'inp_shapes': [[1, 1, 1, 10], [240, 1, 1, 10], [240]], 'out_idxes': [276], 'out_shapes': [[1, 1, 1, 240]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [276], 'inp_shapes': [[1, 1, 1, 240]], 'out_idxes': [277], 'out_shapes': [[1, 1, 1, 240]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [267, 277], 'inp_shapes': [[1, 28, 28, 240], [1, 1, 1, 240]], 'out_idxes': [278], 'out_shapes': [[1, 28, 28, 240]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [278, 117, 41], 'inp_shapes': [[1, 28, 28, 240], [40, 1, 1, 240], [40]], 'out_idxes': [279], 'out_shapes': [[1, 28, 28, 40]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [279, 261], 'inp_shapes': [[1, 28, 28, 40], [1, 28, 28, 40]], 'out_idxes': [280], 'out_shapes': [[1, 28, 28, 40]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [280, 118, 42], 'inp_shapes': [[1, 28, 28, 40], [240, 1, 1, 40], [240]], 'out_idxes': [281], 'out_shapes': [[1, 28, 28, 240]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [281], 'inp_shapes': [[1, 28, 28, 240]], 'out_idxes': [282], 'out_shapes': [[1, 28, 28, 240]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [281, 282], 'inp_shapes': [[1, 28, 28, 240], [1, 28, 28, 240]], 'out_idxes': [283], 'out_shapes': [[1, 28, 28, 240]], 'params': [], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [283, 171], 'inp_shapes': [[1, 28, 28, 240], [4, 2]], 'out_idxes': [284], 'out_shapes': [[1, 29, 29, 240]], 'params': [0, 0, 0, 1, 0, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [284, 43, 6], 'inp_shapes': [[1, 29, 29, 240], [1, 3, 3, 240], [240]], 'out_idxes': [285], 'out_shapes': [[1, 14, 14, 240]], 'params': [1, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [285], 'inp_shapes': [[1, 14, 14, 240]], 'out_idxes': [286], 'out_shapes': [[1, 14, 14, 240]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [285, 286], 'inp_shapes': [[1, 14, 14, 240], [1, 14, 14, 240]], 'out_idxes': [287], 'out_shapes': [[1, 14, 14, 240]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [287, 166], 'inp_shapes': [[1, 14, 14, 240], [2]], 'out_idxes': [288], 'out_shapes': [[1, 240]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [288], 'inp_shapes': [[1, 240]], 'out_idxes': [289], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [289, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [290], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [290, 167, 167, 175], 'inp_shapes': [[], [], [], []], 'out_idxes': [291], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [288, 291], 'inp_shapes': [[1, 240], [4]], 'out_idxes': [292], 'out_shapes': [[1, 1, 1, 240]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [292, 119, 44], 'inp_shapes': [[1, 1, 1, 240], [10, 1, 1, 240], [10]], 'out_idxes': [293], 'out_shapes': [[1, 1, 1, 10]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [293], 'inp_shapes': [[1, 1, 1, 10]], 'out_idxes': [294], 'out_shapes': [[1, 1, 1, 10]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [293, 294], 'inp_shapes': [[1, 1, 1, 10], [1, 1, 1, 10]], 'out_idxes': [295], 'out_shapes': [[1, 1, 1, 10]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [295, 120, 45], 'inp_shapes': [[1, 1, 1, 10], [240, 1, 1, 10], [240]], 'out_idxes': [296], 'out_shapes': [[1, 1, 1, 240]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [296], 'inp_shapes': [[1, 1, 1, 240]], 'out_idxes': [297], 'out_shapes': [[1, 1, 1, 240]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [287, 297], 'inp_shapes': [[1, 14, 14, 240], [1, 1, 1, 240]], 'out_idxes': [298], 'out_shapes': [[1, 14, 14, 240]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [298, 121, 46], 'inp_shapes': [[1, 14, 14, 240], [80, 1, 1, 240], [80]], 'out_idxes': [299], 'out_shapes': [[1, 14, 14, 80]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [299, 122, 47], 'inp_shapes': [[1, 14, 14, 80], [480, 1, 1, 80], [480]], 'out_idxes': [300], 'out_shapes': [[1, 14, 14, 480]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [300], 'inp_shapes': [[1, 14, 14, 480]], 'out_idxes': [301], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [300, 301], 'inp_shapes': [[1, 14, 14, 480], [1, 14, 14, 480]], 'out_idxes': [302], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [302, 48, 7], 'inp_shapes': [[1, 14, 14, 480], [1, 3, 3, 480], [480]], 'out_idxes': [303], 'out_shapes': [[1, 14, 14, 480]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [303], 'inp_shapes': [[1, 14, 14, 480]], 'out_idxes': [304], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [303, 304], 'inp_shapes': [[1, 14, 14, 480], [1, 14, 14, 480]], 'out_idxes': [305], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [305, 166], 'inp_shapes': [[1, 14, 14, 480], [2]], 'out_idxes': [306], 'out_shapes': [[1, 480]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [306], 'inp_shapes': [[1, 480]], 'out_idxes': [307], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [307, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [308], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [308, 167, 167, 176], 'inp_shapes': [[], [], [], []], 'out_idxes': [309], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [306, 309], 'inp_shapes': [[1, 480], [4]], 'out_idxes': [310], 'out_shapes': [[1, 1, 1, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [310, 123, 49], 'inp_shapes': [[1, 1, 1, 480], [20, 1, 1, 480], [20]], 'out_idxes': [311], 'out_shapes': [[1, 1, 1, 20]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [311], 'inp_shapes': [[1, 1, 1, 20]], 'out_idxes': [312], 'out_shapes': [[1, 1, 1, 20]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [311, 312], 'inp_shapes': [[1, 1, 1, 20], [1, 1, 1, 20]], 'out_idxes': [313], 'out_shapes': [[1, 1, 1, 20]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [313, 124, 50], 'inp_shapes': [[1, 1, 1, 20], [480, 1, 1, 20], [480]], 'out_idxes': [314], 'out_shapes': [[1, 1, 1, 480]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [314], 'inp_shapes': [[1, 1, 1, 480]], 'out_idxes': [315], 'out_shapes': [[1, 1, 1, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [305, 315], 'inp_shapes': [[1, 14, 14, 480], [1, 1, 1, 480]], 'out_idxes': [316], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [316, 125, 51], 'inp_shapes': [[1, 14, 14, 480], [80, 1, 1, 480], [80]], 'out_idxes': [317], 'out_shapes': [[1, 14, 14, 80]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [317, 299], 'inp_shapes': [[1, 14, 14, 80], [1, 14, 14, 80]], 'out_idxes': [318], 'out_shapes': [[1, 14, 14, 80]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [318, 126, 52], 'inp_shapes': [[1, 14, 14, 80], [480, 1, 1, 80], [480]], 'out_idxes': [319], 'out_shapes': [[1, 14, 14, 480]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [319], 'inp_shapes': [[1, 14, 14, 480]], 'out_idxes': [320], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [319, 320], 'inp_shapes': [[1, 14, 14, 480], [1, 14, 14, 480]], 'out_idxes': [321], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [321, 53, 8], 'inp_shapes': [[1, 14, 14, 480], [1, 3, 3, 480], [480]], 'out_idxes': [322], 'out_shapes': [[1, 14, 14, 480]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [322], 'inp_shapes': [[1, 14, 14, 480]], 'out_idxes': [323], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [322, 323], 'inp_shapes': [[1, 14, 14, 480], [1, 14, 14, 480]], 'out_idxes': [324], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [324, 166], 'inp_shapes': [[1, 14, 14, 480], [2]], 'out_idxes': [325], 'out_shapes': [[1, 480]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [325], 'inp_shapes': [[1, 480]], 'out_idxes': [326], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [326, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [327], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [327, 167, 167, 176], 'inp_shapes': [[], [], [], []], 'out_idxes': [328], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [325, 328], 'inp_shapes': [[1, 480], [4]], 'out_idxes': [329], 'out_shapes': [[1, 1, 1, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [329, 127, 54], 'inp_shapes': [[1, 1, 1, 480], [20, 1, 1, 480], [20]], 'out_idxes': [330], 'out_shapes': [[1, 1, 1, 20]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [330], 'inp_shapes': [[1, 1, 1, 20]], 'out_idxes': [331], 'out_shapes': [[1, 1, 1, 20]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [330, 331], 'inp_shapes': [[1, 1, 1, 20], [1, 1, 1, 20]], 'out_idxes': [332], 'out_shapes': [[1, 1, 1, 20]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [332, 128, 55], 'inp_shapes': [[1, 1, 1, 20], [480, 1, 1, 20], [480]], 'out_idxes': [333], 'out_shapes': [[1, 1, 1, 480]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [333], 'inp_shapes': [[1, 1, 1, 480]], 'out_idxes': [334], 'out_shapes': [[1, 1, 1, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [324, 334], 'inp_shapes': [[1, 14, 14, 480], [1, 1, 1, 480]], 'out_idxes': [335], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [335, 129, 56], 'inp_shapes': [[1, 14, 14, 480], [80, 1, 1, 480], [80]], 'out_idxes': [336], 'out_shapes': [[1, 14, 14, 80]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [336, 318], 'inp_shapes': [[1, 14, 14, 80], [1, 14, 14, 80]], 'out_idxes': [337], 'out_shapes': [[1, 14, 14, 80]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [337, 130, 57], 'inp_shapes': [[1, 14, 14, 80], [480, 1, 1, 80], [480]], 'out_idxes': [338], 'out_shapes': [[1, 14, 14, 480]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [338], 'inp_shapes': [[1, 14, 14, 480]], 'out_idxes': [339], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [338, 339], 'inp_shapes': [[1, 14, 14, 480], [1, 14, 14, 480]], 'out_idxes': [340], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [340, 58, 9], 'inp_shapes': [[1, 14, 14, 480], [1, 5, 5, 480], [480]], 'out_idxes': [341], 'out_shapes': [[1, 14, 14, 480]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [341], 'inp_shapes': [[1, 14, 14, 480]], 'out_idxes': [342], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [341, 342], 'inp_shapes': [[1, 14, 14, 480], [1, 14, 14, 480]], 'out_idxes': [343], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [343, 166], 'inp_shapes': [[1, 14, 14, 480], [2]], 'out_idxes': [344], 'out_shapes': [[1, 480]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [344], 'inp_shapes': [[1, 480]], 'out_idxes': [345], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [345, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [346], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [346, 167, 167, 176], 'inp_shapes': [[], [], [], []], 'out_idxes': [347], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [344, 347], 'inp_shapes': [[1, 480], [4]], 'out_idxes': [348], 'out_shapes': [[1, 1, 1, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [348, 131, 59], 'inp_shapes': [[1, 1, 1, 480], [20, 1, 1, 480], [20]], 'out_idxes': [349], 'out_shapes': [[1, 1, 1, 20]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [349], 'inp_shapes': [[1, 1, 1, 20]], 'out_idxes': [350], 'out_shapes': [[1, 1, 1, 20]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [349, 350], 'inp_shapes': [[1, 1, 1, 20], [1, 1, 1, 20]], 'out_idxes': [351], 'out_shapes': [[1, 1, 1, 20]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [351, 132, 60], 'inp_shapes': [[1, 1, 1, 20], [480, 1, 1, 20], [480]], 'out_idxes': [352], 'out_shapes': [[1, 1, 1, 480]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [352], 'inp_shapes': [[1, 1, 1, 480]], 'out_idxes': [353], 'out_shapes': [[1, 1, 1, 480]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [343, 353], 'inp_shapes': [[1, 14, 14, 480], [1, 1, 1, 480]], 'out_idxes': [354], 'out_shapes': [[1, 14, 14, 480]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [354, 133, 61], 'inp_shapes': [[1, 14, 14, 480], [112, 1, 1, 480], [112]], 'out_idxes': [355], 'out_shapes': [[1, 14, 14, 112]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [355, 134, 62], 'inp_shapes': [[1, 14, 14, 112], [672, 1, 1, 112], [672]], 'out_idxes': [356], 'out_shapes': [[1, 14, 14, 672]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [356], 'inp_shapes': [[1, 14, 14, 672]], 'out_idxes': [357], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [356, 357], 'inp_shapes': [[1, 14, 14, 672], [1, 14, 14, 672]], 'out_idxes': [358], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [358, 63, 10], 'inp_shapes': [[1, 14, 14, 672], [1, 5, 5, 672], [672]], 'out_idxes': [359], 'out_shapes': [[1, 14, 14, 672]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [359], 'inp_shapes': [[1, 14, 14, 672]], 'out_idxes': [360], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [359, 360], 'inp_shapes': [[1, 14, 14, 672], [1, 14, 14, 672]], 'out_idxes': [361], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [361, 166], 'inp_shapes': [[1, 14, 14, 672], [2]], 'out_idxes': [362], 'out_shapes': [[1, 672]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [362], 'inp_shapes': [[1, 672]], 'out_idxes': [363], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [363, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [364], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [364, 167, 167, 177], 'inp_shapes': [[], [], [], []], 'out_idxes': [365], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [362, 365], 'inp_shapes': [[1, 672], [4]], 'out_idxes': [366], 'out_shapes': [[1, 1, 1, 672]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [366, 135, 64], 'inp_shapes': [[1, 1, 1, 672], [28, 1, 1, 672], [28]], 'out_idxes': [367], 'out_shapes': [[1, 1, 1, 28]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [367], 'inp_shapes': [[1, 1, 1, 28]], 'out_idxes': [368], 'out_shapes': [[1, 1, 1, 28]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [367, 368], 'inp_shapes': [[1, 1, 1, 28], [1, 1, 1, 28]], 'out_idxes': [369], 'out_shapes': [[1, 1, 1, 28]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [369, 136, 65], 'inp_shapes': [[1, 1, 1, 28], [672, 1, 1, 28], [672]], 'out_idxes': [370], 'out_shapes': [[1, 1, 1, 672]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [370], 'inp_shapes': [[1, 1, 1, 672]], 'out_idxes': [371], 'out_shapes': [[1, 1, 1, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [361, 371], 'inp_shapes': [[1, 14, 14, 672], [1, 1, 1, 672]], 'out_idxes': [372], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [372, 137, 66], 'inp_shapes': [[1, 14, 14, 672], [112, 1, 1, 672], [112]], 'out_idxes': [373], 'out_shapes': [[1, 14, 14, 112]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [373, 355], 'inp_shapes': [[1, 14, 14, 112], [1, 14, 14, 112]], 'out_idxes': [374], 'out_shapes': [[1, 14, 14, 112]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [374, 138, 67], 'inp_shapes': [[1, 14, 14, 112], [672, 1, 1, 112], [672]], 'out_idxes': [375], 'out_shapes': [[1, 14, 14, 672]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [375], 'inp_shapes': [[1, 14, 14, 672]], 'out_idxes': [376], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [375, 376], 'inp_shapes': [[1, 14, 14, 672], [1, 14, 14, 672]], 'out_idxes': [377], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [377, 68, 11], 'inp_shapes': [[1, 14, 14, 672], [1, 5, 5, 672], [672]], 'out_idxes': [378], 'out_shapes': [[1, 14, 14, 672]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [378], 'inp_shapes': [[1, 14, 14, 672]], 'out_idxes': [379], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [378, 379], 'inp_shapes': [[1, 14, 14, 672], [1, 14, 14, 672]], 'out_idxes': [380], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [380, 166], 'inp_shapes': [[1, 14, 14, 672], [2]], 'out_idxes': [381], 'out_shapes': [[1, 672]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [381], 'inp_shapes': [[1, 672]], 'out_idxes': [382], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [382, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [383], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [383, 167, 167, 177], 'inp_shapes': [[], [], [], []], 'out_idxes': [384], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [381, 384], 'inp_shapes': [[1, 672], [4]], 'out_idxes': [385], 'out_shapes': [[1, 1, 1, 672]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [385, 139, 69], 'inp_shapes': [[1, 1, 1, 672], [28, 1, 1, 672], [28]], 'out_idxes': [386], 'out_shapes': [[1, 1, 1, 28]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [386], 'inp_shapes': [[1, 1, 1, 28]], 'out_idxes': [387], 'out_shapes': [[1, 1, 1, 28]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [386, 387], 'inp_shapes': [[1, 1, 1, 28], [1, 1, 1, 28]], 'out_idxes': [388], 'out_shapes': [[1, 1, 1, 28]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [388, 140, 70], 'inp_shapes': [[1, 1, 1, 28], [672, 1, 1, 28], [672]], 'out_idxes': [389], 'out_shapes': [[1, 1, 1, 672]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [389], 'inp_shapes': [[1, 1, 1, 672]], 'out_idxes': [390], 'out_shapes': [[1, 1, 1, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [380, 390], 'inp_shapes': [[1, 14, 14, 672], [1, 1, 1, 672]], 'out_idxes': [391], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [391, 141, 71], 'inp_shapes': [[1, 14, 14, 672], [112, 1, 1, 672], [112]], 'out_idxes': [392], 'out_shapes': [[1, 14, 14, 112]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [392, 374], 'inp_shapes': [[1, 14, 14, 112], [1, 14, 14, 112]], 'out_idxes': [393], 'out_shapes': [[1, 14, 14, 112]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [393, 142, 72], 'inp_shapes': [[1, 14, 14, 112], [672, 1, 1, 112], [672]], 'out_idxes': [394], 'out_shapes': [[1, 14, 14, 672]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [394], 'inp_shapes': [[1, 14, 14, 672]], 'out_idxes': [395], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [394, 395], 'inp_shapes': [[1, 14, 14, 672], [1, 14, 14, 672]], 'out_idxes': [396], 'out_shapes': [[1, 14, 14, 672]], 'params': [], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [396, 174], 'inp_shapes': [[1, 14, 14, 672], [4, 2]], 'out_idxes': [397], 'out_shapes': [[1, 17, 17, 672]], 'params': [0, 0, 1, 2, 1, 2, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [397, 73, 12], 'inp_shapes': [[1, 17, 17, 672], [1, 5, 5, 672], [672]], 'out_idxes': [398], 'out_shapes': [[1, 7, 7, 672]], 'params': [1, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [398], 'inp_shapes': [[1, 7, 7, 672]], 'out_idxes': [399], 'out_shapes': [[1, 7, 7, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [398, 399], 'inp_shapes': [[1, 7, 7, 672], [1, 7, 7, 672]], 'out_idxes': [400], 'out_shapes': [[1, 7, 7, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [400, 166], 'inp_shapes': [[1, 7, 7, 672], [2]], 'out_idxes': [401], 'out_shapes': [[1, 672]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [401], 'inp_shapes': [[1, 672]], 'out_idxes': [402], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [402, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [403], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [403, 167, 167, 177], 'inp_shapes': [[], [], [], []], 'out_idxes': [404], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [401, 404], 'inp_shapes': [[1, 672], [4]], 'out_idxes': [405], 'out_shapes': [[1, 1, 1, 672]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [405, 143, 74], 'inp_shapes': [[1, 1, 1, 672], [28, 1, 1, 672], [28]], 'out_idxes': [406], 'out_shapes': [[1, 1, 1, 28]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [406], 'inp_shapes': [[1, 1, 1, 28]], 'out_idxes': [407], 'out_shapes': [[1, 1, 1, 28]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [406, 407], 'inp_shapes': [[1, 1, 1, 28], [1, 1, 1, 28]], 'out_idxes': [408], 'out_shapes': [[1, 1, 1, 28]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [408, 144, 75], 'inp_shapes': [[1, 1, 1, 28], [672, 1, 1, 28], [672]], 'out_idxes': [409], 'out_shapes': [[1, 1, 1, 672]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [409], 'inp_shapes': [[1, 1, 1, 672]], 'out_idxes': [410], 'out_shapes': [[1, 1, 1, 672]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [400, 410], 'inp_shapes': [[1, 7, 7, 672], [1, 1, 1, 672]], 'out_idxes': [411], 'out_shapes': [[1, 7, 7, 672]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [411, 145, 76], 'inp_shapes': [[1, 7, 7, 672], [192, 1, 1, 672], [192]], 'out_idxes': [412], 'out_shapes': [[1, 7, 7, 192]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [412, 146, 77], 'inp_shapes': [[1, 7, 7, 192], [1152, 1, 1, 192], [1152]], 'out_idxes': [413], 'out_shapes': [[1, 7, 7, 1152]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [413], 'inp_shapes': [[1, 7, 7, 1152]], 'out_idxes': [414], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [413, 414], 'inp_shapes': [[1, 7, 7, 1152], [1, 7, 7, 1152]], 'out_idxes': [415], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [415, 78, 13], 'inp_shapes': [[1, 7, 7, 1152], [1, 5, 5, 1152], [1152]], 'out_idxes': [416], 'out_shapes': [[1, 7, 7, 1152]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [416], 'inp_shapes': [[1, 7, 7, 1152]], 'out_idxes': [417], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [416, 417], 'inp_shapes': [[1, 7, 7, 1152], [1, 7, 7, 1152]], 'out_idxes': [418], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [418, 166], 'inp_shapes': [[1, 7, 7, 1152], [2]], 'out_idxes': [419], 'out_shapes': [[1, 1152]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [419], 'inp_shapes': [[1, 1152]], 'out_idxes': [420], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [420, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [421], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [421, 167, 167, 178], 'inp_shapes': [[], [], [], []], 'out_idxes': [422], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [419, 422], 'inp_shapes': [[1, 1152], [4]], 'out_idxes': [423], 'out_shapes': [[1, 1, 1, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [423, 147, 79], 'inp_shapes': [[1, 1, 1, 1152], [48, 1, 1, 1152], [48]], 'out_idxes': [424], 'out_shapes': [[1, 1, 1, 48]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [424], 'inp_shapes': [[1, 1, 1, 48]], 'out_idxes': [425], 'out_shapes': [[1, 1, 1, 48]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [424, 425], 'inp_shapes': [[1, 1, 1, 48], [1, 1, 1, 48]], 'out_idxes': [426], 'out_shapes': [[1, 1, 1, 48]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [426, 148, 80], 'inp_shapes': [[1, 1, 1, 48], [1152, 1, 1, 48], [1152]], 'out_idxes': [427], 'out_shapes': [[1, 1, 1, 1152]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [427], 'inp_shapes': [[1, 1, 1, 1152]], 'out_idxes': [428], 'out_shapes': [[1, 1, 1, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [418, 428], 'inp_shapes': [[1, 7, 7, 1152], [1, 1, 1, 1152]], 'out_idxes': [429], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [429, 149, 81], 'inp_shapes': [[1, 7, 7, 1152], [192, 1, 1, 1152], [192]], 'out_idxes': [430], 'out_shapes': [[1, 7, 7, 192]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [430, 412], 'inp_shapes': [[1, 7, 7, 192], [1, 7, 7, 192]], 'out_idxes': [431], 'out_shapes': [[1, 7, 7, 192]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [431, 150, 82], 'inp_shapes': [[1, 7, 7, 192], [1152, 1, 1, 192], [1152]], 'out_idxes': [432], 'out_shapes': [[1, 7, 7, 1152]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [432], 'inp_shapes': [[1, 7, 7, 1152]], 'out_idxes': [433], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [432, 433], 'inp_shapes': [[1, 7, 7, 1152], [1, 7, 7, 1152]], 'out_idxes': [434], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [434, 83, 14], 'inp_shapes': [[1, 7, 7, 1152], [1, 5, 5, 1152], [1152]], 'out_idxes': [435], 'out_shapes': [[1, 7, 7, 1152]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [435], 'inp_shapes': [[1, 7, 7, 1152]], 'out_idxes': [436], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [435, 436], 'inp_shapes': [[1, 7, 7, 1152], [1, 7, 7, 1152]], 'out_idxes': [437], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [437, 166], 'inp_shapes': [[1, 7, 7, 1152], [2]], 'out_idxes': [438], 'out_shapes': [[1, 1152]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [438], 'inp_shapes': [[1, 1152]], 'out_idxes': [439], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [439, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [440], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [440, 167, 167, 178], 'inp_shapes': [[], [], [], []], 'out_idxes': [441], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [438, 441], 'inp_shapes': [[1, 1152], [4]], 'out_idxes': [442], 'out_shapes': [[1, 1, 1, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [442, 151, 84], 'inp_shapes': [[1, 1, 1, 1152], [48, 1, 1, 1152], [48]], 'out_idxes': [443], 'out_shapes': [[1, 1, 1, 48]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [443], 'inp_shapes': [[1, 1, 1, 48]], 'out_idxes': [444], 'out_shapes': [[1, 1, 1, 48]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [443, 444], 'inp_shapes': [[1, 1, 1, 48], [1, 1, 1, 48]], 'out_idxes': [445], 'out_shapes': [[1, 1, 1, 48]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [445, 152, 85], 'inp_shapes': [[1, 1, 1, 48], [1152, 1, 1, 48], [1152]], 'out_idxes': [446], 'out_shapes': [[1, 1, 1, 1152]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [446], 'inp_shapes': [[1, 1, 1, 1152]], 'out_idxes': [447], 'out_shapes': [[1, 1, 1, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [437, 447], 'inp_shapes': [[1, 7, 7, 1152], [1, 1, 1, 1152]], 'out_idxes': [448], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [448, 153, 86], 'inp_shapes': [[1, 7, 7, 1152], [192, 1, 1, 1152], [192]], 'out_idxes': [449], 'out_shapes': [[1, 7, 7, 192]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [449, 431], 'inp_shapes': [[1, 7, 7, 192], [1, 7, 7, 192]], 'out_idxes': [450], 'out_shapes': [[1, 7, 7, 192]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [450, 154, 87], 'inp_shapes': [[1, 7, 7, 192], [1152, 1, 1, 192], [1152]], 'out_idxes': [451], 'out_shapes': [[1, 7, 7, 1152]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [451], 'inp_shapes': [[1, 7, 7, 1152]], 'out_idxes': [452], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [451, 452], 'inp_shapes': [[1, 7, 7, 1152], [1, 7, 7, 1152]], 'out_idxes': [453], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [453, 88, 15], 'inp_shapes': [[1, 7, 7, 1152], [1, 5, 5, 1152], [1152]], 'out_idxes': [454], 'out_shapes': [[1, 7, 7, 1152]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [454], 'inp_shapes': [[1, 7, 7, 1152]], 'out_idxes': [455], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [454, 455], 'inp_shapes': [[1, 7, 7, 1152], [1, 7, 7, 1152]], 'out_idxes': [456], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [456, 166], 'inp_shapes': [[1, 7, 7, 1152], [2]], 'out_idxes': [457], 'out_shapes': [[1, 1152]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [457], 'inp_shapes': [[1, 1152]], 'out_idxes': [458], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [458, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [459], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [459, 167, 167, 178], 'inp_shapes': [[], [], [], []], 'out_idxes': [460], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [457, 460], 'inp_shapes': [[1, 1152], [4]], 'out_idxes': [461], 'out_shapes': [[1, 1, 1, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [461, 155, 89], 'inp_shapes': [[1, 1, 1, 1152], [48, 1, 1, 1152], [48]], 'out_idxes': [462], 'out_shapes': [[1, 1, 1, 48]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [462], 'inp_shapes': [[1, 1, 1, 48]], 'out_idxes': [463], 'out_shapes': [[1, 1, 1, 48]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [462, 463], 'inp_shapes': [[1, 1, 1, 48], [1, 1, 1, 48]], 'out_idxes': [464], 'out_shapes': [[1, 1, 1, 48]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [464, 156, 90], 'inp_shapes': [[1, 1, 1, 48], [1152, 1, 1, 48], [1152]], 'out_idxes': [465], 'out_shapes': [[1, 1, 1, 1152]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [465], 'inp_shapes': [[1, 1, 1, 1152]], 'out_idxes': [466], 'out_shapes': [[1, 1, 1, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [456, 466], 'inp_shapes': [[1, 7, 7, 1152], [1, 1, 1, 1152]], 'out_idxes': [467], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [467, 157, 91], 'inp_shapes': [[1, 7, 7, 1152], [192, 1, 1, 1152], [192]], 'out_idxes': [468], 'out_shapes': [[1, 7, 7, 192]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [468, 450], 'inp_shapes': [[1, 7, 7, 192], [1, 7, 7, 192]], 'out_idxes': [469], 'out_shapes': [[1, 7, 7, 192]], 'params': [0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [469, 158, 92], 'inp_shapes': [[1, 7, 7, 192], [1152, 1, 1, 192], [1152]], 'out_idxes': [470], 'out_shapes': [[1, 7, 7, 1152]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [470], 'inp_shapes': [[1, 7, 7, 1152]], 'out_idxes': [471], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [470, 471], 'inp_shapes': [[1, 7, 7, 1152], [1, 7, 7, 1152]], 'out_idxes': [472], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [472, 93, 16], 'inp_shapes': [[1, 7, 7, 1152], [1, 3, 3, 1152], [1152]], 'out_idxes': [473], 'out_shapes': [[1, 7, 7, 1152]], 'params': [1, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [473], 'inp_shapes': [[1, 7, 7, 1152]], 'out_idxes': [474], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [473, 474], 'inp_shapes': [[1, 7, 7, 1152], [1, 7, 7, 1152]], 'out_idxes': [475], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [475, 166], 'inp_shapes': [[1, 7, 7, 1152], [2]], 'out_idxes': [476], 'out_shapes': [[1, 1152]], 'params': [1, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [476], 'inp_shapes': [[1, 1152]], 'out_idxes': [477], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [477, 169, 170, 170], 'inp_shapes': [[2], [1], [1], [1]], 'out_idxes': [478], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [478, 167, 167, 178], 'inp_shapes': [[], [], [], []], 'out_idxes': [479], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [476, 479], 'inp_shapes': [[1, 1152], [4]], 'out_idxes': [480], 'out_shapes': [[1, 1, 1, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [480, 159, 94], 'inp_shapes': [[1, 1, 1, 1152], [48, 1, 1, 1152], [48]], 'out_idxes': [481], 'out_shapes': [[1, 1, 1, 48]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [481], 'inp_shapes': [[1, 1, 1, 48]], 'out_idxes': [482], 'out_shapes': [[1, 1, 1, 48]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [481, 482], 'inp_shapes': [[1, 1, 1, 48], [1, 1, 1, 48]], 'out_idxes': [483], 'out_shapes': [[1, 1, 1, 48]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [483, 160, 95], 'inp_shapes': [[1, 1, 1, 48], [1152, 1, 1, 48], [1152]], 'out_idxes': [484], 'out_shapes': [[1, 1, 1, 1152]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [484], 'inp_shapes': [[1, 1, 1, 1152]], 'out_idxes': [485], 'out_shapes': [[1, 1, 1, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [475, 485], 'inp_shapes': [[1, 7, 7, 1152], [1, 1, 1, 1152]], 'out_idxes': [486], 'out_shapes': [[1, 7, 7, 1152]], 'params': [], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [486, 161, 96], 'inp_shapes': [[1, 7, 7, 1152], [320, 1, 1, 1152], [320]], 'out_idxes': [487], 'out_shapes': [[1, 7, 7, 320]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [487, 162, 97], 'inp_shapes': [[1, 7, 7, 320], [1280, 1, 1, 320], [1280]], 'out_idxes': [488], 'out_shapes': [[1, 7, 7, 1280]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Logistic', 'inp_idxes': [488], 'inp_shapes': [[1, 7, 7, 1280]], 'out_idxes': [489], 'out_shapes': [[1, 7, 7, 1280]], 'params': [], 'mask': []}, {'layer_type': 'Mul', 'inp_idxes': [488, 489], 'inp_shapes': [[1, 7, 7, 1280], [1, 7, 7, 1280]], 'out_idxes': [490], 'out_shapes': [[1, 7, 7, 1280]], 'params': [], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [490, 166], 'inp_shapes': [[1, 7, 7, 1280], [2]], 'out_idxes': [491], 'out_shapes': [[1, 1280]], 'params': [1, 2], 'mask': []}, {'layer_type': 'FullyConnected', 'inp_idxes': [491, 181, 165], 'inp_shapes': [[1, 1280], [1000, 1280], [1000]], 'out_idxes': [492], 'out_shapes': [[1, 1000]], 'params': [0], 'mask': []}, {'layer_type': 'Softmax', 'inp_idxes': [492], 'inp_shapes': [[1, 1000]], 'out_idxes': [493], 'out_shapes': [[1, 1000]], 'params': [], 'mask': []}]\n",
      "\n",
      "keep tensors: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492}\n",
      "skipping generated tensor: 0, b'serving_default_input_1:0'\n",
      "skipping generated tensor: 182, b'efficientnetb0/rescaling/mul'\n",
      "skipping generated tensor: 183, b'efficientnetb0/normalization/sub'\n",
      "skipping generated tensor: 184, b'efficientnetb0/normalization/truediv;efficientnetb0/normalization/Sqrt1'\n",
      "skipping generated tensor: 185, b'efficientnetb0/rescaling_1/mul'\n",
      "skipping generated tensor: 186, b'efficientnetb0/stem_conv_pad/Pad'\n",
      "skipping generated tensor: 187, b'efficientnetb0/stem_bn/FusedBatchNormV3;efficientnetb0/block1a_se_expand/Conv2D;efficientnetb0/stem_conv/Conv2D'\n",
      "skipping generated tensor: 188, b'efficientnetb0/stem_activation/Sigmoid'\n",
      "skipping generated tensor: 189, b'efficientnetb0/stem_activation/mul_1'\n",
      "skipping generated tensor: 190, b'efficientnetb0/block1a_bn/FusedBatchNormV3;efficientnetb0/block1a_dwconv/depthwise;efficientnetb0/block1a_se_expand/Conv2D1'\n",
      "skipping generated tensor: 191, b'efficientnetb0/block1a_activation/Sigmoid'\n",
      "skipping generated tensor: 192, b'efficientnetb0/block1a_activation/mul_1'\n",
      "skipping generated tensor: 193, b'efficientnetb0/block1a_se_squeeze/Mean'\n",
      "skipping generated tensor: 194, b'efficientnetb0/block1a_se_reshape/Shape'\n",
      "skipping generated tensor: 195, b'efficientnetb0/block1a_se_reshape/strided_slice'\n",
      "skipping generated tensor: 196, b'efficientnetb0/block1a_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 197, b'efficientnetb0/block1a_se_reshape/Reshape'\n",
      "skipping generated tensor: 198, b'efficientnetb0/block1a_se_reduce/BiasAdd;efficientnetb0/block1a_se_reduce/Conv2D;efficientnetb0/block1a_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 199, b'efficientnetb0/block1a_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 200, b'efficientnetb0/block1a_se_reduce/mul_1'\n",
      "skipping generated tensor: 201, b'efficientnetb0/block1a_se_expand/BiasAdd;efficientnetb0/block1a_se_expand/Conv2D;efficientnetb0/block1a_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 202, b'efficientnetb0/block1a_se_expand/Sigmoid'\n",
      "skipping generated tensor: 203, b'efficientnetb0/block1a_se_excite/mul'\n",
      "skipping generated tensor: 204, b'efficientnetb0/block1a_project_bn/FusedBatchNormV3;efficientnetb0/block1a_project_conv/Conv2D'\n",
      "skipping generated tensor: 205, b'efficientnetb0/block2a_expand_bn/FusedBatchNormV3;efficientnetb0/block2a_se_expand/Conv2D;efficientnetb0/block2a_expand_conv/Conv2D'\n",
      "skipping generated tensor: 206, b'efficientnetb0/block2a_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 207, b'efficientnetb0/block2a_expand_activation/mul_1'\n",
      "skipping generated tensor: 208, b'efficientnetb0/block2a_dwconv_pad/Pad'\n",
      "skipping generated tensor: 209, b'efficientnetb0/block2a_bn/FusedBatchNormV3;efficientnetb0/block2a_se_expand/Conv2D;efficientnetb0/block2a_dwconv/depthwise'\n",
      "skipping generated tensor: 210, b'efficientnetb0/block2a_activation/Sigmoid'\n",
      "skipping generated tensor: 211, b'efficientnetb0/block2a_activation/mul_1'\n",
      "skipping generated tensor: 212, b'efficientnetb0/block2a_se_squeeze/Mean'\n",
      "skipping generated tensor: 213, b'efficientnetb0/block2a_se_reshape/Shape'\n",
      "skipping generated tensor: 214, b'efficientnetb0/block2a_se_reshape/strided_slice'\n",
      "skipping generated tensor: 215, b'efficientnetb0/block2a_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 216, b'efficientnetb0/block2a_se_reshape/Reshape'\n",
      "skipping generated tensor: 217, b'efficientnetb0/block2a_se_reduce/BiasAdd;efficientnetb0/block2a_se_reduce/Conv2D;efficientnetb0/block2a_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 218, b'efficientnetb0/block2a_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 219, b'efficientnetb0/block2a_se_reduce/mul_1'\n",
      "skipping generated tensor: 220, b'efficientnetb0/block2a_se_expand/BiasAdd;efficientnetb0/block2a_se_expand/Conv2D;efficientnetb0/block2a_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 221, b'efficientnetb0/block2a_se_expand/Sigmoid'\n",
      "skipping generated tensor: 222, b'efficientnetb0/block2a_se_excite/mul'\n",
      "skipping generated tensor: 223, b'efficientnetb0/block2a_project_bn/FusedBatchNormV3;efficientnetb0/block2b_project_conv/Conv2D;efficientnetb0/block2a_project_conv/Conv2D'\n",
      "skipping generated tensor: 224, b'efficientnetb0/block2b_expand_bn/FusedBatchNormV3;efficientnetb0/block3a_se_expand/Conv2D;efficientnetb0/block2b_expand_conv/Conv2D'\n",
      "skipping generated tensor: 225, b'efficientnetb0/block2b_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 226, b'efficientnetb0/block2b_expand_activation/mul_1'\n",
      "skipping generated tensor: 227, b'efficientnetb0/block2b_bn/FusedBatchNormV3;efficientnetb0/block2b_dwconv/depthwise;efficientnetb0/block3a_se_expand/Conv2D1'\n",
      "skipping generated tensor: 228, b'efficientnetb0/block2b_activation/Sigmoid'\n",
      "skipping generated tensor: 229, b'efficientnetb0/block2b_activation/mul_1'\n",
      "skipping generated tensor: 230, b'efficientnetb0/block2b_se_squeeze/Mean'\n",
      "skipping generated tensor: 231, b'efficientnetb0/block2b_se_reshape/Shape'\n",
      "skipping generated tensor: 232, b'efficientnetb0/block2b_se_reshape/strided_slice'\n",
      "skipping generated tensor: 233, b'efficientnetb0/block2b_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 234, b'efficientnetb0/block2b_se_reshape/Reshape'\n",
      "skipping generated tensor: 235, b'efficientnetb0/block2b_se_reduce/BiasAdd;efficientnetb0/block3a_se_reduce/Conv2D;efficientnetb0/block2b_se_reduce/Conv2D;efficientnetb0/block2b_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 236, b'efficientnetb0/block2b_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 237, b'efficientnetb0/block2b_se_reduce/mul_1'\n",
      "skipping generated tensor: 238, b'efficientnetb0/block2b_se_expand/BiasAdd;efficientnetb0/block3a_se_expand/Conv2D;efficientnetb0/block2b_se_expand/Conv2D;efficientnetb0/block2b_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 239, b'efficientnetb0/block2b_se_expand/Sigmoid'\n",
      "skipping generated tensor: 240, b'efficientnetb0/block2b_se_excite/mul'\n",
      "skipping generated tensor: 241, b'efficientnetb0/block2b_project_bn/FusedBatchNormV3;efficientnetb0/block2b_project_conv/Conv2D'\n",
      "skipping generated tensor: 242, b'efficientnetb0/block2b_add/add'\n",
      "skipping generated tensor: 243, b'efficientnetb0/block3a_expand_bn/FusedBatchNormV3;efficientnetb0/block3a_se_expand/Conv2D;efficientnetb0/block3a_expand_conv/Conv2D'\n",
      "skipping generated tensor: 244, b'efficientnetb0/block3a_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 245, b'efficientnetb0/block3a_expand_activation/mul_1'\n",
      "skipping generated tensor: 246, b'efficientnetb0/block3a_dwconv_pad/Pad'\n",
      "skipping generated tensor: 247, b'efficientnetb0/block3a_bn/FusedBatchNormV3;efficientnetb0/block3a_se_expand/Conv2D;efficientnetb0/block3a_dwconv/depthwise'\n",
      "skipping generated tensor: 248, b'efficientnetb0/block3a_activation/Sigmoid'\n",
      "skipping generated tensor: 249, b'efficientnetb0/block3a_activation/mul_1'\n",
      "skipping generated tensor: 250, b'efficientnetb0/block3a_se_squeeze/Mean'\n",
      "skipping generated tensor: 251, b'efficientnetb0/block3a_se_reshape/Shape'\n",
      "skipping generated tensor: 252, b'efficientnetb0/block3a_se_reshape/strided_slice'\n",
      "skipping generated tensor: 253, b'efficientnetb0/block3a_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 254, b'efficientnetb0/block3a_se_reshape/Reshape'\n",
      "skipping generated tensor: 255, b'efficientnetb0/block3a_se_reduce/BiasAdd;efficientnetb0/block3a_se_reduce/Conv2D;efficientnetb0/block3a_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 256, b'efficientnetb0/block3a_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 257, b'efficientnetb0/block3a_se_reduce/mul_1'\n",
      "skipping generated tensor: 258, b'efficientnetb0/block3a_se_expand/BiasAdd;efficientnetb0/block3a_se_expand/Conv2D;efficientnetb0/block3a_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 259, b'efficientnetb0/block3a_se_expand/Sigmoid'\n",
      "skipping generated tensor: 260, b'efficientnetb0/block3a_se_excite/mul'\n",
      "skipping generated tensor: 261, b'efficientnetb0/block3a_project_bn/FusedBatchNormV3;efficientnetb0/block3b_project_conv/Conv2D;efficientnetb0/block3a_project_conv/Conv2D'\n",
      "skipping generated tensor: 262, b'efficientnetb0/block3b_expand_bn/FusedBatchNormV3;efficientnetb0/block4a_se_expand/Conv2D;efficientnetb0/block3b_expand_conv/Conv2D'\n",
      "skipping generated tensor: 263, b'efficientnetb0/block3b_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 264, b'efficientnetb0/block3b_expand_activation/mul_1'\n",
      "skipping generated tensor: 265, b'efficientnetb0/block3b_bn/FusedBatchNormV3;efficientnetb0/block3b_dwconv/depthwise;efficientnetb0/block4a_se_expand/Conv2D1'\n",
      "skipping generated tensor: 266, b'efficientnetb0/block3b_activation/Sigmoid'\n",
      "skipping generated tensor: 267, b'efficientnetb0/block3b_activation/mul_1'\n",
      "skipping generated tensor: 268, b'efficientnetb0/block3b_se_squeeze/Mean'\n",
      "skipping generated tensor: 269, b'efficientnetb0/block3b_se_reshape/Shape'\n",
      "skipping generated tensor: 270, b'efficientnetb0/block3b_se_reshape/strided_slice'\n",
      "skipping generated tensor: 271, b'efficientnetb0/block3b_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 272, b'efficientnetb0/block3b_se_reshape/Reshape'\n",
      "skipping generated tensor: 273, b'efficientnetb0/block3b_se_reduce/BiasAdd;efficientnetb0/block4a_se_reduce/Conv2D;efficientnetb0/block3b_se_reduce/Conv2D;efficientnetb0/block3b_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 274, b'efficientnetb0/block3b_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 275, b'efficientnetb0/block3b_se_reduce/mul_1'\n",
      "skipping generated tensor: 276, b'efficientnetb0/block3b_se_expand/BiasAdd;efficientnetb0/block4a_se_expand/Conv2D;efficientnetb0/block3b_se_expand/Conv2D;efficientnetb0/block3b_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 277, b'efficientnetb0/block3b_se_expand/Sigmoid'\n",
      "skipping generated tensor: 278, b'efficientnetb0/block3b_se_excite/mul'\n",
      "skipping generated tensor: 279, b'efficientnetb0/block3b_project_bn/FusedBatchNormV3;efficientnetb0/block3b_project_conv/Conv2D'\n",
      "skipping generated tensor: 280, b'efficientnetb0/block3b_add/add'\n",
      "skipping generated tensor: 281, b'efficientnetb0/block4a_expand_bn/FusedBatchNormV3;efficientnetb0/block4a_se_expand/Conv2D;efficientnetb0/block4a_expand_conv/Conv2D'\n",
      "skipping generated tensor: 282, b'efficientnetb0/block4a_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 283, b'efficientnetb0/block4a_expand_activation/mul_1'\n",
      "skipping generated tensor: 284, b'efficientnetb0/block4a_dwconv_pad/Pad'\n",
      "skipping generated tensor: 285, b'efficientnetb0/block4a_bn/FusedBatchNormV3;efficientnetb0/block4a_se_expand/Conv2D;efficientnetb0/block4a_dwconv/depthwise'\n",
      "skipping generated tensor: 286, b'efficientnetb0/block4a_activation/Sigmoid'\n",
      "skipping generated tensor: 287, b'efficientnetb0/block4a_activation/mul_1'\n",
      "skipping generated tensor: 288, b'efficientnetb0/block4a_se_squeeze/Mean'\n",
      "skipping generated tensor: 289, b'efficientnetb0/block4a_se_reshape/Shape'\n",
      "skipping generated tensor: 290, b'efficientnetb0/block4a_se_reshape/strided_slice'\n",
      "skipping generated tensor: 291, b'efficientnetb0/block4a_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 292, b'efficientnetb0/block4a_se_reshape/Reshape'\n",
      "skipping generated tensor: 293, b'efficientnetb0/block4a_se_reduce/BiasAdd;efficientnetb0/block4a_se_reduce/Conv2D;efficientnetb0/block4a_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 294, b'efficientnetb0/block4a_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 295, b'efficientnetb0/block4a_se_reduce/mul_1'\n",
      "skipping generated tensor: 296, b'efficientnetb0/block4a_se_expand/BiasAdd;efficientnetb0/block4a_se_expand/Conv2D;efficientnetb0/block4a_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 297, b'efficientnetb0/block4a_se_expand/Sigmoid'\n",
      "skipping generated tensor: 298, b'efficientnetb0/block4a_se_excite/mul'\n",
      "skipping generated tensor: 299, b'efficientnetb0/block4a_project_bn/FusedBatchNormV3;efficientnetb0/block4c_project_conv/Conv2D;efficientnetb0/block4a_project_conv/Conv2D'\n",
      "skipping generated tensor: 300, b'efficientnetb0/block4b_expand_bn/FusedBatchNormV3;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block4b_expand_conv/Conv2D'\n",
      "skipping generated tensor: 301, b'efficientnetb0/block4b_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 302, b'efficientnetb0/block4b_expand_activation/mul_1'\n",
      "skipping generated tensor: 303, b'efficientnetb0/block4b_bn/FusedBatchNormV3;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block4b_dwconv/depthwise'\n",
      "skipping generated tensor: 304, b'efficientnetb0/block4b_activation/Sigmoid'\n",
      "skipping generated tensor: 305, b'efficientnetb0/block4b_activation/mul_1'\n",
      "skipping generated tensor: 306, b'efficientnetb0/block4b_se_squeeze/Mean'\n",
      "skipping generated tensor: 307, b'efficientnetb0/block4b_se_reshape/Shape'\n",
      "skipping generated tensor: 308, b'efficientnetb0/block4b_se_reshape/strided_slice'\n",
      "skipping generated tensor: 309, b'efficientnetb0/block4b_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 310, b'efficientnetb0/block4b_se_reshape/Reshape'\n",
      "skipping generated tensor: 311, b'efficientnetb0/block4b_se_reduce/BiasAdd;efficientnetb0/block5a_se_reduce/Conv2D;efficientnetb0/block4b_se_reduce/Conv2D;efficientnetb0/block4b_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 312, b'efficientnetb0/block4b_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 313, b'efficientnetb0/block4b_se_reduce/mul_1'\n",
      "skipping generated tensor: 314, b'efficientnetb0/block4b_se_expand/BiasAdd;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block4b_se_expand/Conv2D;efficientnetb0/block4b_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 315, b'efficientnetb0/block4b_se_expand/Sigmoid'\n",
      "skipping generated tensor: 316, b'efficientnetb0/block4b_se_excite/mul'\n",
      "skipping generated tensor: 317, b'efficientnetb0/block4b_project_bn/FusedBatchNormV3;efficientnetb0/block4c_project_conv/Conv2D;efficientnetb0/block4b_project_conv/Conv2D'\n",
      "skipping generated tensor: 318, b'efficientnetb0/block4b_add/add'\n",
      "skipping generated tensor: 319, b'efficientnetb0/block4c_expand_bn/FusedBatchNormV3;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block4c_expand_conv/Conv2D'\n",
      "skipping generated tensor: 320, b'efficientnetb0/block4c_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 321, b'efficientnetb0/block4c_expand_activation/mul_1'\n",
      "skipping generated tensor: 322, b'efficientnetb0/block4c_bn/FusedBatchNormV3;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block4c_dwconv/depthwise'\n",
      "skipping generated tensor: 323, b'efficientnetb0/block4c_activation/Sigmoid'\n",
      "skipping generated tensor: 324, b'efficientnetb0/block4c_activation/mul_1'\n",
      "skipping generated tensor: 325, b'efficientnetb0/block4c_se_squeeze/Mean'\n",
      "skipping generated tensor: 326, b'efficientnetb0/block4c_se_reshape/Shape'\n",
      "skipping generated tensor: 327, b'efficientnetb0/block4c_se_reshape/strided_slice'\n",
      "skipping generated tensor: 328, b'efficientnetb0/block4c_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 329, b'efficientnetb0/block4c_se_reshape/Reshape'\n",
      "skipping generated tensor: 330, b'efficientnetb0/block4c_se_reduce/BiasAdd;efficientnetb0/block5a_se_reduce/Conv2D;efficientnetb0/block4c_se_reduce/Conv2D;efficientnetb0/block4c_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 331, b'efficientnetb0/block4c_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 332, b'efficientnetb0/block4c_se_reduce/mul_1'\n",
      "skipping generated tensor: 333, b'efficientnetb0/block4c_se_expand/BiasAdd;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block4c_se_expand/Conv2D;efficientnetb0/block4c_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 334, b'efficientnetb0/block4c_se_expand/Sigmoid'\n",
      "skipping generated tensor: 335, b'efficientnetb0/block4c_se_excite/mul'\n",
      "skipping generated tensor: 336, b'efficientnetb0/block4c_project_bn/FusedBatchNormV3;efficientnetb0/block4c_project_conv/Conv2D'\n",
      "skipping generated tensor: 337, b'efficientnetb0/block4c_add/add'\n",
      "skipping generated tensor: 338, b'efficientnetb0/block5a_expand_bn/FusedBatchNormV3;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block5a_expand_conv/Conv2D'\n",
      "skipping generated tensor: 339, b'efficientnetb0/block5a_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 340, b'efficientnetb0/block5a_expand_activation/mul_1'\n",
      "skipping generated tensor: 341, b'efficientnetb0/block5a_bn/FusedBatchNormV3;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block5a_dwconv/depthwise'\n",
      "skipping generated tensor: 342, b'efficientnetb0/block5a_activation/Sigmoid'\n",
      "skipping generated tensor: 343, b'efficientnetb0/block5a_activation/mul_1'\n",
      "skipping generated tensor: 344, b'efficientnetb0/block5a_se_squeeze/Mean'\n",
      "skipping generated tensor: 345, b'efficientnetb0/block5a_se_reshape/Shape'\n",
      "skipping generated tensor: 346, b'efficientnetb0/block5a_se_reshape/strided_slice'\n",
      "skipping generated tensor: 347, b'efficientnetb0/block5a_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 348, b'efficientnetb0/block5a_se_reshape/Reshape'\n",
      "skipping generated tensor: 349, b'efficientnetb0/block5a_se_reduce/BiasAdd;efficientnetb0/block5a_se_reduce/Conv2D;efficientnetb0/block5a_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 350, b'efficientnetb0/block5a_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 351, b'efficientnetb0/block5a_se_reduce/mul_1'\n",
      "skipping generated tensor: 352, b'efficientnetb0/block5a_se_expand/BiasAdd;efficientnetb0/block5a_se_expand/Conv2D;efficientnetb0/block5a_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 353, b'efficientnetb0/block5a_se_expand/Sigmoid'\n",
      "skipping generated tensor: 354, b'efficientnetb0/block5a_se_excite/mul'\n",
      "skipping generated tensor: 355, b'efficientnetb0/block5a_project_bn/FusedBatchNormV3;efficientnetb0/block5c_project_conv/Conv2D;efficientnetb0/block5a_project_conv/Conv2D'\n",
      "skipping generated tensor: 356, b'efficientnetb0/block5b_expand_bn/FusedBatchNormV3;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block5b_expand_conv/Conv2D'\n",
      "skipping generated tensor: 357, b'efficientnetb0/block5b_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 358, b'efficientnetb0/block5b_expand_activation/mul_1'\n",
      "skipping generated tensor: 359, b'efficientnetb0/block5b_bn/FusedBatchNormV3;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block5b_dwconv/depthwise'\n",
      "skipping generated tensor: 360, b'efficientnetb0/block5b_activation/Sigmoid'\n",
      "skipping generated tensor: 361, b'efficientnetb0/block5b_activation/mul_1'\n",
      "skipping generated tensor: 362, b'efficientnetb0/block5b_se_squeeze/Mean'\n",
      "skipping generated tensor: 363, b'efficientnetb0/block5b_se_reshape/Shape'\n",
      "skipping generated tensor: 364, b'efficientnetb0/block5b_se_reshape/strided_slice'\n",
      "skipping generated tensor: 365, b'efficientnetb0/block5b_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 366, b'efficientnetb0/block5b_se_reshape/Reshape'\n",
      "skipping generated tensor: 367, b'efficientnetb0/block5b_se_reduce/BiasAdd;efficientnetb0/block6a_se_reduce/Conv2D;efficientnetb0/block5b_se_reduce/Conv2D;efficientnetb0/block5b_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 368, b'efficientnetb0/block5b_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 369, b'efficientnetb0/block5b_se_reduce/mul_1'\n",
      "skipping generated tensor: 370, b'efficientnetb0/block5b_se_expand/BiasAdd;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block5b_se_expand/Conv2D;efficientnetb0/block5b_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 371, b'efficientnetb0/block5b_se_expand/Sigmoid'\n",
      "skipping generated tensor: 372, b'efficientnetb0/block5b_se_excite/mul'\n",
      "skipping generated tensor: 373, b'efficientnetb0/block5b_project_bn/FusedBatchNormV3;efficientnetb0/block5c_project_conv/Conv2D;efficientnetb0/block5b_project_conv/Conv2D'\n",
      "skipping generated tensor: 374, b'efficientnetb0/block5b_add/add'\n",
      "skipping generated tensor: 375, b'efficientnetb0/block5c_expand_bn/FusedBatchNormV3;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block5c_expand_conv/Conv2D'\n",
      "skipping generated tensor: 376, b'efficientnetb0/block5c_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 377, b'efficientnetb0/block5c_expand_activation/mul_1'\n",
      "skipping generated tensor: 378, b'efficientnetb0/block5c_bn/FusedBatchNormV3;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block5c_dwconv/depthwise'\n",
      "skipping generated tensor: 379, b'efficientnetb0/block5c_activation/Sigmoid'\n",
      "skipping generated tensor: 380, b'efficientnetb0/block5c_activation/mul_1'\n",
      "skipping generated tensor: 381, b'efficientnetb0/block5c_se_squeeze/Mean'\n",
      "skipping generated tensor: 382, b'efficientnetb0/block5c_se_reshape/Shape'\n",
      "skipping generated tensor: 383, b'efficientnetb0/block5c_se_reshape/strided_slice'\n",
      "skipping generated tensor: 384, b'efficientnetb0/block5c_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 385, b'efficientnetb0/block5c_se_reshape/Reshape'\n",
      "skipping generated tensor: 386, b'efficientnetb0/block5c_se_reduce/BiasAdd;efficientnetb0/block6a_se_reduce/Conv2D;efficientnetb0/block5c_se_reduce/Conv2D;efficientnetb0/block5c_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 387, b'efficientnetb0/block5c_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 388, b'efficientnetb0/block5c_se_reduce/mul_1'\n",
      "skipping generated tensor: 389, b'efficientnetb0/block5c_se_expand/BiasAdd;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block5c_se_expand/Conv2D;efficientnetb0/block5c_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 390, b'efficientnetb0/block5c_se_expand/Sigmoid'\n",
      "skipping generated tensor: 391, b'efficientnetb0/block5c_se_excite/mul'\n",
      "skipping generated tensor: 392, b'efficientnetb0/block5c_project_bn/FusedBatchNormV3;efficientnetb0/block5c_project_conv/Conv2D'\n",
      "skipping generated tensor: 393, b'efficientnetb0/block5c_add/add'\n",
      "skipping generated tensor: 394, b'efficientnetb0/block6a_expand_bn/FusedBatchNormV3;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block6a_expand_conv/Conv2D'\n",
      "skipping generated tensor: 395, b'efficientnetb0/block6a_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 396, b'efficientnetb0/block6a_expand_activation/mul_1'\n",
      "skipping generated tensor: 397, b'efficientnetb0/block6a_dwconv_pad/Pad'\n",
      "skipping generated tensor: 398, b'efficientnetb0/block6a_bn/FusedBatchNormV3;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block6a_dwconv/depthwise'\n",
      "skipping generated tensor: 399, b'efficientnetb0/block6a_activation/Sigmoid'\n",
      "skipping generated tensor: 400, b'efficientnetb0/block6a_activation/mul_1'\n",
      "skipping generated tensor: 401, b'efficientnetb0/block6a_se_squeeze/Mean'\n",
      "skipping generated tensor: 402, b'efficientnetb0/block6a_se_reshape/Shape'\n",
      "skipping generated tensor: 403, b'efficientnetb0/block6a_se_reshape/strided_slice'\n",
      "skipping generated tensor: 404, b'efficientnetb0/block6a_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 405, b'efficientnetb0/block6a_se_reshape/Reshape'\n",
      "skipping generated tensor: 406, b'efficientnetb0/block6a_se_reduce/BiasAdd;efficientnetb0/block6a_se_reduce/Conv2D;efficientnetb0/block6a_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 407, b'efficientnetb0/block6a_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 408, b'efficientnetb0/block6a_se_reduce/mul_1'\n",
      "skipping generated tensor: 409, b'efficientnetb0/block6a_se_expand/BiasAdd;efficientnetb0/block6a_se_expand/Conv2D;efficientnetb0/block6a_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 410, b'efficientnetb0/block6a_se_expand/Sigmoid'\n",
      "skipping generated tensor: 411, b'efficientnetb0/block6a_se_excite/mul'\n",
      "skipping generated tensor: 412, b'efficientnetb0/block6a_project_bn/FusedBatchNormV3;efficientnetb0/block6d_project_conv/Conv2D;efficientnetb0/block6a_project_conv/Conv2D'\n",
      "skipping generated tensor: 413, b'efficientnetb0/block6b_expand_bn/FusedBatchNormV3;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6b_expand_conv/Conv2D'\n",
      "skipping generated tensor: 414, b'efficientnetb0/block6b_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 415, b'efficientnetb0/block6b_expand_activation/mul_1'\n",
      "skipping generated tensor: 416, b'efficientnetb0/block6b_bn/FusedBatchNormV3;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6b_dwconv/depthwise'\n",
      "skipping generated tensor: 417, b'efficientnetb0/block6b_activation/Sigmoid'\n",
      "skipping generated tensor: 418, b'efficientnetb0/block6b_activation/mul_1'\n",
      "skipping generated tensor: 419, b'efficientnetb0/block6b_se_squeeze/Mean'\n",
      "skipping generated tensor: 420, b'efficientnetb0/block6b_se_reshape/Shape'\n",
      "skipping generated tensor: 421, b'efficientnetb0/block6b_se_reshape/strided_slice'\n",
      "skipping generated tensor: 422, b'efficientnetb0/block6b_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 423, b'efficientnetb0/block6b_se_reshape/Reshape'\n",
      "skipping generated tensor: 424, b'efficientnetb0/block6b_se_reduce/BiasAdd;efficientnetb0/block7a_se_reduce/Conv2D;efficientnetb0/block6b_se_reduce/Conv2D;efficientnetb0/block6b_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 425, b'efficientnetb0/block6b_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 426, b'efficientnetb0/block6b_se_reduce/mul_1'\n",
      "skipping generated tensor: 427, b'efficientnetb0/block6b_se_expand/BiasAdd;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6b_se_expand/Conv2D;efficientnetb0/block6b_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 428, b'efficientnetb0/block6b_se_expand/Sigmoid'\n",
      "skipping generated tensor: 429, b'efficientnetb0/block6b_se_excite/mul'\n",
      "skipping generated tensor: 430, b'efficientnetb0/block6b_project_bn/FusedBatchNormV3;efficientnetb0/block6d_project_conv/Conv2D;efficientnetb0/block6b_project_conv/Conv2D'\n",
      "skipping generated tensor: 431, b'efficientnetb0/block6b_add/add'\n",
      "skipping generated tensor: 432, b'efficientnetb0/block6c_expand_bn/FusedBatchNormV3;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6c_expand_conv/Conv2D'\n",
      "skipping generated tensor: 433, b'efficientnetb0/block6c_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 434, b'efficientnetb0/block6c_expand_activation/mul_1'\n",
      "skipping generated tensor: 435, b'efficientnetb0/block6c_bn/FusedBatchNormV3;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6c_dwconv/depthwise'\n",
      "skipping generated tensor: 436, b'efficientnetb0/block6c_activation/Sigmoid'\n",
      "skipping generated tensor: 437, b'efficientnetb0/block6c_activation/mul_1'\n",
      "skipping generated tensor: 438, b'efficientnetb0/block6c_se_squeeze/Mean'\n",
      "skipping generated tensor: 439, b'efficientnetb0/block6c_se_reshape/Shape'\n",
      "skipping generated tensor: 440, b'efficientnetb0/block6c_se_reshape/strided_slice'\n",
      "skipping generated tensor: 441, b'efficientnetb0/block6c_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 442, b'efficientnetb0/block6c_se_reshape/Reshape'\n",
      "skipping generated tensor: 443, b'efficientnetb0/block6c_se_reduce/BiasAdd;efficientnetb0/block7a_se_reduce/Conv2D;efficientnetb0/block6c_se_reduce/Conv2D;efficientnetb0/block6c_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 444, b'efficientnetb0/block6c_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 445, b'efficientnetb0/block6c_se_reduce/mul_1'\n",
      "skipping generated tensor: 446, b'efficientnetb0/block6c_se_expand/BiasAdd;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6c_se_expand/Conv2D;efficientnetb0/block6c_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 447, b'efficientnetb0/block6c_se_expand/Sigmoid'\n",
      "skipping generated tensor: 448, b'efficientnetb0/block6c_se_excite/mul'\n",
      "skipping generated tensor: 449, b'efficientnetb0/block6c_project_bn/FusedBatchNormV3;efficientnetb0/block6d_project_conv/Conv2D;efficientnetb0/block6c_project_conv/Conv2D'\n",
      "skipping generated tensor: 450, b'efficientnetb0/block6c_add/add'\n",
      "skipping generated tensor: 451, b'efficientnetb0/block6d_expand_bn/FusedBatchNormV3;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6d_expand_conv/Conv2D'\n",
      "skipping generated tensor: 452, b'efficientnetb0/block6d_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 453, b'efficientnetb0/block6d_expand_activation/mul_1'\n",
      "skipping generated tensor: 454, b'efficientnetb0/block6d_bn/FusedBatchNormV3;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6d_dwconv/depthwise'\n",
      "skipping generated tensor: 455, b'efficientnetb0/block6d_activation/Sigmoid'\n",
      "skipping generated tensor: 456, b'efficientnetb0/block6d_activation/mul_1'\n",
      "skipping generated tensor: 457, b'efficientnetb0/block6d_se_squeeze/Mean'\n",
      "skipping generated tensor: 458, b'efficientnetb0/block6d_se_reshape/Shape'\n",
      "skipping generated tensor: 459, b'efficientnetb0/block6d_se_reshape/strided_slice'\n",
      "skipping generated tensor: 460, b'efficientnetb0/block6d_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 461, b'efficientnetb0/block6d_se_reshape/Reshape'\n",
      "skipping generated tensor: 462, b'efficientnetb0/block6d_se_reduce/BiasAdd;efficientnetb0/block7a_se_reduce/Conv2D;efficientnetb0/block6d_se_reduce/Conv2D;efficientnetb0/block6d_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 463, b'efficientnetb0/block6d_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 464, b'efficientnetb0/block6d_se_reduce/mul_1'\n",
      "skipping generated tensor: 465, b'efficientnetb0/block6d_se_expand/BiasAdd;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block6d_se_expand/Conv2D;efficientnetb0/block6d_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 466, b'efficientnetb0/block6d_se_expand/Sigmoid'\n",
      "skipping generated tensor: 467, b'efficientnetb0/block6d_se_excite/mul'\n",
      "skipping generated tensor: 468, b'efficientnetb0/block6d_project_bn/FusedBatchNormV3;efficientnetb0/block6d_project_conv/Conv2D'\n",
      "skipping generated tensor: 469, b'efficientnetb0/block6d_add/add'\n",
      "skipping generated tensor: 470, b'efficientnetb0/block7a_expand_bn/FusedBatchNormV3;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block7a_expand_conv/Conv2D'\n",
      "skipping generated tensor: 471, b'efficientnetb0/block7a_expand_activation/Sigmoid'\n",
      "skipping generated tensor: 472, b'efficientnetb0/block7a_expand_activation/mul_1'\n",
      "skipping generated tensor: 473, b'efficientnetb0/block7a_bn/FusedBatchNormV3;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block7a_dwconv/depthwise'\n",
      "skipping generated tensor: 474, b'efficientnetb0/block7a_activation/Sigmoid'\n",
      "skipping generated tensor: 475, b'efficientnetb0/block7a_activation/mul_1'\n",
      "skipping generated tensor: 476, b'efficientnetb0/block7a_se_squeeze/Mean'\n",
      "skipping generated tensor: 477, b'efficientnetb0/block7a_se_reshape/Shape'\n",
      "skipping generated tensor: 478, b'efficientnetb0/block7a_se_reshape/strided_slice'\n",
      "skipping generated tensor: 479, b'efficientnetb0/block7a_se_reshape/Reshape/shape'\n",
      "skipping generated tensor: 480, b'efficientnetb0/block7a_se_reshape/Reshape'\n",
      "skipping generated tensor: 481, b'efficientnetb0/block7a_se_reduce/BiasAdd;efficientnetb0/block7a_se_reduce/Conv2D;efficientnetb0/block7a_se_reduce/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 482, b'efficientnetb0/block7a_se_reduce/Sigmoid'\n",
      "skipping generated tensor: 483, b'efficientnetb0/block7a_se_reduce/mul_1'\n",
      "skipping generated tensor: 484, b'efficientnetb0/block7a_se_expand/BiasAdd;efficientnetb0/block7a_se_expand/Conv2D;efficientnetb0/block7a_se_expand/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 485, b'efficientnetb0/block7a_se_expand/Sigmoid'\n",
      "skipping generated tensor: 486, b'efficientnetb0/block7a_se_excite/mul'\n",
      "skipping generated tensor: 487, b'efficientnetb0/block7a_project_bn/FusedBatchNormV3;efficientnetb0/block7a_project_conv/Conv2D'\n",
      "skipping generated tensor: 488, b'efficientnetb0/top_bn/FusedBatchNormV3;efficientnetb0/top_conv/Conv2D'\n",
      "skipping generated tensor: 489, b'efficientnetb0/top_activation/Sigmoid'\n",
      "skipping generated tensor: 490, b'efficientnetb0/top_activation/mul_1'\n",
      "skipping generated tensor: 491, b'efficientnetb0/avg_pool/Mean'\n",
      "skipping generated tensor: 492, b'efficientnetb0/predictions/MatMul;efficientnetb0/predictions/BiasAdd'\n",
      "\n",
      "{'layer_type': 'Softmax', 'inp_idxes': [492], 'inp_shapes': [[1, 1000]], 'out_idxes': [493], 'out_shapes': [[1, 1000]], 'params': [], 'mask': []}\n",
      "dict_keys(['global_sf', 'k', 'num_cols', 'num_random', 'inp_idxes', 'out_idxes', 'layers', 'tensors', 'use_selectors', 'commit_before', 'commit_after'])\n",
      "[493]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/converter.py', '--model', '../../models/efficientnetb0/efficientnetb0.tflite', '--model_output', 'converted_model_new.msgpack', '--config_output', 'config_new.msgpack', '--scale_factor', '4096', '--k', '23', '--num_cols', '256', '--num_randoms', '2097152'], returncode=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert model\n",
    "# !python ./tools/converter.py --model ./model.tflite --model_output converted_model_new.msgpack --config_output config_new.msgpack --scale_factor 512 --k 20 --num_cols 20 --num_randoms 4096\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/converter.py', \n",
    "    '--model', '../../models/efficientnetb0/efficientnetb0.tflite',\n",
    "    '--model_output', 'converted_model_new.msgpack',\n",
    "    '--config_output', 'config_new.msgpack',\n",
    "    '--scale_factor', '4096',\n",
    "    '--k', '23',\n",
    "    '--num_cols', '256',\n",
    "    '--num_randoms', '2097152'\n",
    "]\n",
    "\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/input_converter.py', '--model_config', 'converted_model_new.msgpack', '--inputs', '7.npy', '--output', 'example_inp_new.msgpack'], returncode=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert input\n",
    "import subprocess\n",
    "\n",
    "# !python ./tools/input_converter.py --model_config converted_model_new.msgpack --inputs 7.npy --output example_inp_new.msgpack\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/input_converter.py', \n",
    "    '--model_config', 'converted_model_new.msgpack',\n",
    "    '--inputs', '7.npy',\n",
    "    '--output', 'example_inp_new.msgpack'\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command_dir:  ./bin/\n",
      "Processing layer 0, type: Mul, inp_idxes: [0, 179], out_idxes: [182], layer_params: []\n",
      "Out 0 shape: [1, 224, 224, 3]\n",
      "\n",
      "Processing layer 1, type: Sub, inp_idxes: [182, 164], out_idxes: [183], layer_params: []\n",
      "Out 0 shape: [1, 224, 224, 3]\n",
      "\n",
      "Processing layer 2, type: Mul, inp_idxes: [183, 163], out_idxes: [184], layer_params: []\n",
      "Out 0 shape: [1, 224, 224, 3]\n",
      "\n",
      "Processing layer 3, type: Mul, inp_idxes: [184, 180], out_idxes: [185], layer_params: []\n",
      "Out 0 shape: [1, 224, 224, 3]\n",
      "\n",
      "Processing layer 4, type: Pad, inp_idxes: [185, 171], out_idxes: [186], layer_params: [0, 0, 0, 1, 0, 1, 0, 0]\n",
      "Out 0 shape: [1, 225, 225, 3]\n",
      "\n",
      "Processing layer 5, type: Conv2D, inp_idxes: [186, 98, 17], out_idxes: [187], layer_params: [0, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 112, 112, 32]\n",
      "\n",
      "Processing layer 6, type: Logistic, inp_idxes: [187], out_idxes: [188], layer_params: []\n",
      "Out 0 shape: [1, 112, 112, 32]\n",
      "\n",
      "Processing layer 7, type: Mul, inp_idxes: [187, 188], out_idxes: [189], layer_params: []\n",
      "Out 0 shape: [1, 112, 112, 32]\n",
      "\n",
      "Processing layer 8, type: Conv2D, inp_idxes: [189, 18, 1], out_idxes: [190], layer_params: [1, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 112, 112, 32]\n",
      "\n",
      "Processing layer 9, type: Logistic, inp_idxes: [190], out_idxes: [191], layer_params: []\n",
      "Out 0 shape: [1, 112, 112, 32]\n",
      "\n",
      "Processing layer 10, type: Mul, inp_idxes: [190, 191], out_idxes: [192], layer_params: []\n",
      "Out 0 shape: [1, 112, 112, 32]\n",
      "\n",
      "Processing layer 11, type: Mean, inp_idxes: [192, 166], out_idxes: [193], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 32]\n",
      "\n",
      "Processing layer 12, type: Noop, inp_idxes: [193], out_idxes: [194], layer_params: [0]\n",
      "Out 0 shape: [1, 32]\n",
      "\n",
      "Processing layer 13, type: Noop, inp_idxes: [194, 169, 170, 170], out_idxes: [195], layer_params: [0]\n",
      "Out 0 shape: [1, 32]\n",
      "\n",
      "Processing layer 14, type: Pack, inp_idxes: [195, 167, 167, 168], out_idxes: [196], layer_params: [0]\n",
      "Out 0 shape: [1, 32]\n",
      "\n",
      "Processing layer 15, type: Reshape, inp_idxes: [193, 196], out_idxes: [197], layer_params: []\n",
      "Reshape: [1, 32] -> [1, 1, 1, 32]\n",
      "Out 0 shape: [1, 1, 1, 32]\n",
      "\n",
      "Processing layer 16, type: Conv2D, inp_idxes: [197, 99, 19], out_idxes: [198], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 8]\n",
      "\n",
      "Processing layer 17, type: Logistic, inp_idxes: [198], out_idxes: [199], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 8]\n",
      "\n",
      "Processing layer 18, type: Mul, inp_idxes: [198, 199], out_idxes: [200], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 8]\n",
      "\n",
      "Processing layer 19, type: Conv2D, inp_idxes: [200, 100, 20], out_idxes: [201], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 32]\n",
      "\n",
      "Processing layer 20, type: Logistic, inp_idxes: [201], out_idxes: [202], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 32]\n",
      "\n",
      "Processing layer 21, type: Mul, inp_idxes: [192, 202], out_idxes: [203], layer_params: []\n",
      "Out 0 shape: [1, 112, 112, 32]\n",
      "\n",
      "Processing layer 22, type: Conv2D, inp_idxes: [203, 101, 21], out_idxes: [204], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 112, 112, 16]\n",
      "\n",
      "Processing layer 23, type: Conv2D, inp_idxes: [204, 102, 22], out_idxes: [205], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 112, 112, 96]\n",
      "\n",
      "Processing layer 24, type: Logistic, inp_idxes: [205], out_idxes: [206], layer_params: []\n",
      "Out 0 shape: [1, 112, 112, 96]\n",
      "\n",
      "Processing layer 25, type: Mul, inp_idxes: [205, 206], out_idxes: [207], layer_params: []\n",
      "Out 0 shape: [1, 112, 112, 96]\n",
      "\n",
      "Processing layer 26, type: Pad, inp_idxes: [207, 171], out_idxes: [208], layer_params: [0, 0, 0, 1, 0, 1, 0, 0]\n",
      "Out 0 shape: [1, 113, 113, 96]\n",
      "\n",
      "Processing layer 27, type: Conv2D, inp_idxes: [208, 23, 2], out_idxes: [209], layer_params: [1, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 56, 56, 96]\n",
      "\n",
      "Processing layer 28, type: Logistic, inp_idxes: [209], out_idxes: [210], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 96]\n",
      "\n",
      "Processing layer 29, type: Mul, inp_idxes: [209, 210], out_idxes: [211], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 96]\n",
      "\n",
      "Processing layer 30, type: Mean, inp_idxes: [211, 166], out_idxes: [212], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 96]\n",
      "\n",
      "Processing layer 31, type: Noop, inp_idxes: [212], out_idxes: [213], layer_params: [0]\n",
      "Out 0 shape: [1, 96]\n",
      "\n",
      "Processing layer 32, type: Noop, inp_idxes: [213, 169, 170, 170], out_idxes: [214], layer_params: [0]\n",
      "Out 0 shape: [1, 96]\n",
      "\n",
      "Processing layer 33, type: Pack, inp_idxes: [214, 167, 167, 172], out_idxes: [215], layer_params: [0]\n",
      "Out 0 shape: [1, 96]\n",
      "\n",
      "Processing layer 34, type: Reshape, inp_idxes: [212, 215], out_idxes: [216], layer_params: []\n",
      "Reshape: [1, 96] -> [1, 1, 1, 96]\n",
      "Out 0 shape: [1, 1, 1, 96]\n",
      "\n",
      "Processing layer 35, type: Conv2D, inp_idxes: [216, 103, 24], out_idxes: [217], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 4]\n",
      "\n",
      "Processing layer 36, type: Logistic, inp_idxes: [217], out_idxes: [218], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 4]\n",
      "\n",
      "Processing layer 37, type: Mul, inp_idxes: [217, 218], out_idxes: [219], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 4]\n",
      "\n",
      "Processing layer 38, type: Conv2D, inp_idxes: [219, 104, 25], out_idxes: [220], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 96]\n",
      "\n",
      "Processing layer 39, type: Logistic, inp_idxes: [220], out_idxes: [221], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 96]\n",
      "\n",
      "Processing layer 40, type: Mul, inp_idxes: [211, 221], out_idxes: [222], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 96]\n",
      "\n",
      "Processing layer 41, type: Conv2D, inp_idxes: [222, 105, 26], out_idxes: [223], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 56, 56, 24]\n",
      "\n",
      "Processing layer 42, type: Conv2D, inp_idxes: [223, 106, 27], out_idxes: [224], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 43, type: Logistic, inp_idxes: [224], out_idxes: [225], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 44, type: Mul, inp_idxes: [224, 225], out_idxes: [226], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 45, type: Conv2D, inp_idxes: [226, 28, 3], out_idxes: [227], layer_params: [1, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 46, type: Logistic, inp_idxes: [227], out_idxes: [228], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 47, type: Mul, inp_idxes: [227, 228], out_idxes: [229], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 48, type: Mean, inp_idxes: [229, 166], out_idxes: [230], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 144]\n",
      "\n",
      "Processing layer 49, type: Noop, inp_idxes: [230], out_idxes: [231], layer_params: [0]\n",
      "Out 0 shape: [1, 144]\n",
      "\n",
      "Processing layer 50, type: Noop, inp_idxes: [231, 169, 170, 170], out_idxes: [232], layer_params: [0]\n",
      "Out 0 shape: [1, 144]\n",
      "\n",
      "Processing layer 51, type: Pack, inp_idxes: [232, 167, 167, 173], out_idxes: [233], layer_params: [0]\n",
      "Out 0 shape: [1, 144]\n",
      "\n",
      "Processing layer 52, type: Reshape, inp_idxes: [230, 233], out_idxes: [234], layer_params: []\n",
      "Reshape: [1, 144] -> [1, 1, 1, 144]\n",
      "Out 0 shape: [1, 1, 1, 144]\n",
      "\n",
      "Processing layer 53, type: Conv2D, inp_idxes: [234, 107, 29], out_idxes: [235], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 6]\n",
      "\n",
      "Processing layer 54, type: Logistic, inp_idxes: [235], out_idxes: [236], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 6]\n",
      "\n",
      "Processing layer 55, type: Mul, inp_idxes: [235, 236], out_idxes: [237], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 6]\n",
      "\n",
      "Processing layer 56, type: Conv2D, inp_idxes: [237, 108, 30], out_idxes: [238], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 144]\n",
      "\n",
      "Processing layer 57, type: Logistic, inp_idxes: [238], out_idxes: [239], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 144]\n",
      "\n",
      "Processing layer 58, type: Mul, inp_idxes: [229, 239], out_idxes: [240], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 59, type: Conv2D, inp_idxes: [240, 109, 31], out_idxes: [241], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 56, 56, 24]\n",
      "\n",
      "Processing layer 60, type: Add, inp_idxes: [241, 223], out_idxes: [242], layer_params: [0]\n",
      "Out 0 shape: [1, 56, 56, 24]\n",
      "\n",
      "Processing layer 61, type: Conv2D, inp_idxes: [242, 110, 32], out_idxes: [243], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 62, type: Logistic, inp_idxes: [243], out_idxes: [244], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 63, type: Mul, inp_idxes: [243, 244], out_idxes: [245], layer_params: []\n",
      "Out 0 shape: [1, 56, 56, 144]\n",
      "\n",
      "Processing layer 64, type: Pad, inp_idxes: [245, 174], out_idxes: [246], layer_params: [0, 0, 1, 2, 1, 2, 0, 0]\n",
      "Out 0 shape: [1, 59, 59, 144]\n",
      "\n",
      "Processing layer 65, type: Conv2D, inp_idxes: [246, 33, 4], out_idxes: [247], layer_params: [1, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 28, 28, 144]\n",
      "\n",
      "Processing layer 66, type: Logistic, inp_idxes: [247], out_idxes: [248], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 144]\n",
      "\n",
      "Processing layer 67, type: Mul, inp_idxes: [247, 248], out_idxes: [249], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 144]\n",
      "\n",
      "Processing layer 68, type: Mean, inp_idxes: [249, 166], out_idxes: [250], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 144]\n",
      "\n",
      "Processing layer 69, type: Noop, inp_idxes: [250], out_idxes: [251], layer_params: [0]\n",
      "Out 0 shape: [1, 144]\n",
      "\n",
      "Processing layer 70, type: Noop, inp_idxes: [251, 169, 170, 170], out_idxes: [252], layer_params: [0]\n",
      "Out 0 shape: [1, 144]\n",
      "\n",
      "Processing layer 71, type: Pack, inp_idxes: [252, 167, 167, 173], out_idxes: [253], layer_params: [0]\n",
      "Out 0 shape: [1, 144]\n",
      "\n",
      "Processing layer 72, type: Reshape, inp_idxes: [250, 253], out_idxes: [254], layer_params: []\n",
      "Reshape: [1, 144] -> [1, 1, 1, 144]\n",
      "Out 0 shape: [1, 1, 1, 144]\n",
      "\n",
      "Processing layer 73, type: Conv2D, inp_idxes: [254, 111, 34], out_idxes: [255], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 6]\n",
      "\n",
      "Processing layer 74, type: Logistic, inp_idxes: [255], out_idxes: [256], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 6]\n",
      "\n",
      "Processing layer 75, type: Mul, inp_idxes: [255, 256], out_idxes: [257], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 6]\n",
      "\n",
      "Processing layer 76, type: Conv2D, inp_idxes: [257, 112, 35], out_idxes: [258], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 144]\n",
      "\n",
      "Processing layer 77, type: Logistic, inp_idxes: [258], out_idxes: [259], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 144]\n",
      "\n",
      "Processing layer 78, type: Mul, inp_idxes: [249, 259], out_idxes: [260], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 144]\n",
      "\n",
      "Processing layer 79, type: Conv2D, inp_idxes: [260, 113, 36], out_idxes: [261], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 28, 28, 40]\n",
      "\n",
      "Processing layer 80, type: Conv2D, inp_idxes: [261, 114, 37], out_idxes: [262], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 81, type: Logistic, inp_idxes: [262], out_idxes: [263], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 82, type: Mul, inp_idxes: [262, 263], out_idxes: [264], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 83, type: Conv2D, inp_idxes: [264, 38, 5], out_idxes: [265], layer_params: [1, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 84, type: Logistic, inp_idxes: [265], out_idxes: [266], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 85, type: Mul, inp_idxes: [265, 266], out_idxes: [267], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 86, type: Mean, inp_idxes: [267, 166], out_idxes: [268], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 240]\n",
      "\n",
      "Processing layer 87, type: Noop, inp_idxes: [268], out_idxes: [269], layer_params: [0]\n",
      "Out 0 shape: [1, 240]\n",
      "\n",
      "Processing layer 88, type: Noop, inp_idxes: [269, 169, 170, 170], out_idxes: [270], layer_params: [0]\n",
      "Out 0 shape: [1, 240]\n",
      "\n",
      "Processing layer 89, type: Pack, inp_idxes: [270, 167, 167, 175], out_idxes: [271], layer_params: [0]\n",
      "Out 0 shape: [1, 240]\n",
      "\n",
      "Processing layer 90, type: Reshape, inp_idxes: [268, 271], out_idxes: [272], layer_params: []\n",
      "Reshape: [1, 240] -> [1, 1, 1, 240]\n",
      "Out 0 shape: [1, 1, 1, 240]\n",
      "\n",
      "Processing layer 91, type: Conv2D, inp_idxes: [272, 115, 39], out_idxes: [273], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 10]\n",
      "\n",
      "Processing layer 92, type: Logistic, inp_idxes: [273], out_idxes: [274], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 10]\n",
      "\n",
      "Processing layer 93, type: Mul, inp_idxes: [273, 274], out_idxes: [275], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 10]\n",
      "\n",
      "Processing layer 94, type: Conv2D, inp_idxes: [275, 116, 40], out_idxes: [276], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 240]\n",
      "\n",
      "Processing layer 95, type: Logistic, inp_idxes: [276], out_idxes: [277], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 240]\n",
      "\n",
      "Processing layer 96, type: Mul, inp_idxes: [267, 277], out_idxes: [278], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 97, type: Conv2D, inp_idxes: [278, 117, 41], out_idxes: [279], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 28, 28, 40]\n",
      "\n",
      "Processing layer 98, type: Add, inp_idxes: [279, 261], out_idxes: [280], layer_params: [0]\n",
      "Out 0 shape: [1, 28, 28, 40]\n",
      "\n",
      "Processing layer 99, type: Conv2D, inp_idxes: [280, 118, 42], out_idxes: [281], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 100, type: Logistic, inp_idxes: [281], out_idxes: [282], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 101, type: Mul, inp_idxes: [281, 282], out_idxes: [283], layer_params: []\n",
      "Out 0 shape: [1, 28, 28, 240]\n",
      "\n",
      "Processing layer 102, type: Pad, inp_idxes: [283, 171], out_idxes: [284], layer_params: [0, 0, 0, 1, 0, 1, 0, 0]\n",
      "Out 0 shape: [1, 29, 29, 240]\n",
      "\n",
      "Processing layer 103, type: Conv2D, inp_idxes: [284, 43, 6], out_idxes: [285], layer_params: [1, 1, 0, 2, 2]\n",
      "Out 0 shape: [1, 14, 14, 240]\n",
      "\n",
      "Processing layer 104, type: Logistic, inp_idxes: [285], out_idxes: [286], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 240]\n",
      "\n",
      "Processing layer 105, type: Mul, inp_idxes: [285, 286], out_idxes: [287], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 240]\n",
      "\n",
      "Processing layer 106, type: Mean, inp_idxes: [287, 166], out_idxes: [288], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 240]\n",
      "\n",
      "Processing layer 107, type: Noop, inp_idxes: [288], out_idxes: [289], layer_params: [0]\n",
      "Out 0 shape: [1, 240]\n",
      "\n",
      "Processing layer 108, type: Noop, inp_idxes: [289, 169, 170, 170], out_idxes: [290], layer_params: [0]\n",
      "Out 0 shape: [1, 240]\n",
      "\n",
      "Processing layer 109, type: Pack, inp_idxes: [290, 167, 167, 175], out_idxes: [291], layer_params: [0]\n",
      "Out 0 shape: [1, 240]\n",
      "\n",
      "Processing layer 110, type: Reshape, inp_idxes: [288, 291], out_idxes: [292], layer_params: []\n",
      "Reshape: [1, 240] -> [1, 1, 1, 240]\n",
      "Out 0 shape: [1, 1, 1, 240]\n",
      "\n",
      "Processing layer 111, type: Conv2D, inp_idxes: [292, 119, 44], out_idxes: [293], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 10]\n",
      "\n",
      "Processing layer 112, type: Logistic, inp_idxes: [293], out_idxes: [294], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 10]\n",
      "\n",
      "Processing layer 113, type: Mul, inp_idxes: [293, 294], out_idxes: [295], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 10]\n",
      "\n",
      "Processing layer 114, type: Conv2D, inp_idxes: [295, 120, 45], out_idxes: [296], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 240]\n",
      "\n",
      "Processing layer 115, type: Logistic, inp_idxes: [296], out_idxes: [297], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 240]\n",
      "\n",
      "Processing layer 116, type: Mul, inp_idxes: [287, 297], out_idxes: [298], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 240]\n",
      "\n",
      "Processing layer 117, type: Conv2D, inp_idxes: [298, 121, 46], out_idxes: [299], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 14, 14, 80]\n",
      "\n",
      "Processing layer 118, type: Conv2D, inp_idxes: [299, 122, 47], out_idxes: [300], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 119, type: Logistic, inp_idxes: [300], out_idxes: [301], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 120, type: Mul, inp_idxes: [300, 301], out_idxes: [302], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 121, type: Conv2D, inp_idxes: [302, 48, 7], out_idxes: [303], layer_params: [1, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 122, type: Logistic, inp_idxes: [303], out_idxes: [304], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 123, type: Mul, inp_idxes: [303, 304], out_idxes: [305], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 124, type: Mean, inp_idxes: [305, 166], out_idxes: [306], layer_params: [1, 2]\n",
      "Out 0 shape: [1, 480]\n",
      "\n",
      "Processing layer 125, type: Noop, inp_idxes: [306], out_idxes: [307], layer_params: [0]\n",
      "Out 0 shape: [1, 480]\n",
      "\n",
      "Processing layer 126, type: Noop, inp_idxes: [307, 169, 170, 170], out_idxes: [308], layer_params: [0]\n",
      "Out 0 shape: [1, 480]\n",
      "\n",
      "Processing layer 127, type: Pack, inp_idxes: [308, 167, 167, 176], out_idxes: [309], layer_params: [0]\n",
      "Out 0 shape: [1, 480]\n",
      "\n",
      "Processing layer 128, type: Reshape, inp_idxes: [306, 309], out_idxes: [310], layer_params: []\n",
      "Reshape: [1, 480] -> [1, 1, 1, 480]\n",
      "Out 0 shape: [1, 1, 1, 480]\n",
      "\n",
      "Processing layer 129, type: Conv2D, inp_idxes: [310, 123, 49], out_idxes: [311], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 20]\n",
      "\n",
      "Processing layer 130, type: Logistic, inp_idxes: [311], out_idxes: [312], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 20]\n",
      "\n",
      "Processing layer 131, type: Mul, inp_idxes: [311, 312], out_idxes: [313], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 20]\n",
      "\n",
      "Processing layer 132, type: Conv2D, inp_idxes: [313, 124, 50], out_idxes: [314], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 1, 1, 480]\n",
      "\n",
      "Processing layer 133, type: Logistic, inp_idxes: [314], out_idxes: [315], layer_params: []\n",
      "Out 0 shape: [1, 1, 1, 480]\n",
      "\n",
      "Processing layer 134, type: Mul, inp_idxes: [305, 315], out_idxes: [316], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 135, type: Conv2D, inp_idxes: [316, 125, 51], out_idxes: [317], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 14, 14, 80]\n",
      "\n",
      "Processing layer 136, type: Add, inp_idxes: [317, 299], out_idxes: [318], layer_params: [0]\n",
      "Out 0 shape: [1, 14, 14, 80]\n",
      "\n",
      "Processing layer 137, type: Conv2D, inp_idxes: [318, 126, 52], out_idxes: [319], layer_params: [0, 0, 0, 1, 1]\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 138, type: Logistic, inp_idxes: [319], out_idxes: [320], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 139, type: Mul, inp_idxes: [319, 320], out_idxes: [321], layer_params: []\n",
      "Out 0 shape: [1, 14, 14, 480]\n",
      "\n",
      "Processing layer 140, type: Conv2D, inp_idxes: [321, 53, 8], out_idxes: [322], layer_params: [1, 0, 0, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread 'main' panicked at /home/guy1m0/.cargo/git/checkouts/halo2-afe2d0b0be6b3c3a/17e9765/halo2_proofs/src/dev.rs:381:9:\n",
      "row=4194298 not in usable_rows=0..4194298, k=22\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['./bin/test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']' returned non-zero exit status 101.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m command \u001b[38;5;241m=\u001b[39m [command_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_circuit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverted_model_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample_inp_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkzg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the command\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/zkml_bench_env/lib/python3.9/subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['./bin/test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']' returned non-zero exit status 101."
     ]
    }
   ],
   "source": [
    "import platform\n",
    "command_dir = './bin/m1_mac/' if platform.processor() == \"arm\" else './bin/'\n",
    "print(\"command_dir: \", command_dir)\n",
    "\n",
    "# Command to run\n",
    "command = [command_dir + 'test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to run\n",
    "command = [command_dir + 'time_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobilenetv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:onnx2keras:avgpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x34d102820> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x34d102820>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x34d102820> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x34d102820>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x34d102820> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x34d102820>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "ONNX Model Output: [[ -5.6887074  -8.627259   -5.799383   -9.938003   -9.698364  -10.885633\n",
      "    3.3272264  -8.930378  -11.69671    -7.798205 ]]\n",
      "Keras Model Output: [[ -5.6887093  -8.627256   -5.7993846  -9.938006   -9.698366  -10.8856325\n",
      "    3.3272266  -8.930379  -11.696707   -7.7982063]]\n",
      "Are the outputs close? True\n"
     ]
    }
   ],
   "source": [
    "# load onnx file\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Define model path and load ONNX model\n",
    "model_path = \"../../models/mobilenetv1/mobilenetv1.onnx\"\n",
    "onnx_model = onnx.load(model_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Convert the ONNX model to a Keras model\n",
    "import onnx2keras\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "# Convert the ONNX model to a Keras model\n",
    "# k_model = onnx2keras.onnx_to_keras(onnx_model, ['input'], name_policy='renumerate')\n",
    "k_model = onnx2keras.onnx_to_keras(onnx_model, ['input'], name_policy='renumerate', change_ordering=True)\n",
    "\n",
    "# Create a session for the ONNX model\n",
    "ort_session = ort.InferenceSession(model_path)\n",
    "\n",
    "# Create a dummy CIFAR-10 input for testing\n",
    "input_data = np.random.randn(1, 3, 32, 32).astype(np.float32)\n",
    "\n",
    "# Run inference on the ONNX model\n",
    "ort_input_name = ort_session.get_inputs()[0].name\n",
    "onnx_output = ort_session.run(None, {ort_input_name: input_data})\n",
    "\n",
    "# Run inference on the Keras model\n",
    "# keras_input = input_data\n",
    "keras_input = np.transpose(input_data, (0, 2, 3, 1))\n",
    "keras_output = k_model.predict(keras_input)\n",
    "\n",
    "# Compare the outputs\n",
    "print(\"ONNX Model Output:\", onnx_output[0])\n",
    "print(\"Keras Model Output:\", keras_output)\n",
    "\n",
    "# Check if the outputs are close\n",
    "are_outputs_close = np.allclose(onnx_output[0], keras_output, atol=1e-5)\n",
    "print(\"Are the outputs close?\", are_outputs_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpthl1pt8u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpthl1pt8u/assets\n",
      "2024-11-08 22:35:34.320850: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-11-08 22:35:34.321200: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-11-08 22:35:34.322038: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpthl1pt8u\n",
      "2024-11-08 22:35:34.326125: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-11-08 22:35:34.326133: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpthl1pt8u\n",
      "2024-11-08 22:35:34.338442: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-11-08 22:35:34.420152: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpthl1pt8u\n",
      "2024-11-08 22:35:34.444748: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 122716 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# convert the keras modoel to tflite\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "import os\n",
    "\n",
    "model = k_model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert() # experimental_new_converter=False\n",
    "\n",
    "# Save the TFLite model\n",
    "os.makedirs(\"../../models/mobilenetv1\",exist_ok=True)\n",
    "with open('../../models/mobilenetv1/mobilenetv1.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy on CIFAR-10 test set: 87.75%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the tflite model\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path='../../models/mobilenetv1/mobilenetv1.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on cifar10 test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# import transforms from torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "for data, target in test_loader:\n",
    "    for i in range(len(data)):\n",
    "        input_data = data[i:i+1]\n",
    "        # reshape to 4D\n",
    "        input_data = input_data.numpy()\n",
    "        input_data = np.transpose(input_data, (0, 2, 3, 1))\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        pred_label = np.argmax(output_data)\n",
    "        true_label = target[i].item()\n",
    "        if pred_label == true_label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on CIFAR-10 test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on CIFAR-10 test set: 87.75%\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy of onnx model on cifar10 test set\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the ONNX model\n",
    "model_path = \"../../models/mobilenetv1/mobilenetv1.onnx\"\n",
    "ort_session = ort.InferenceSession(model_path)\n",
    "\n",
    "# Run inference on the ONNX model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    for i in range(len(data)):\n",
    "        input_data = data[i:i+1]\n",
    "        input_data = input_data.numpy()\n",
    "        ort_input = {ort_session.get_inputs()[0].name: input_data}\n",
    "        ort_output = ort_session.run(None, ort_input)\n",
    "        pred_label = np.argmax(ort_output[0])\n",
    "        true_label = target[i].item()\n",
    "        if pred_label == true_label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on CIFAR-10 test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/zkml_bench_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'layer_type': 'Pad', 'inp_idxes': [0, 60], 'inp_shapes': [[1, 32, 32, 3], [4, 2]], 'out_idxes': [62], 'out_shapes': [[1, 34, 34, 3]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [62, 28, 1], 'inp_shapes': [[1, 34, 34, 3], [19, 3, 3, 3], [19]], 'out_idxes': [63], 'out_shapes': [[1, 32, 32, 19]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [63, 60], 'inp_shapes': [[1, 32, 32, 19], [4, 2]], 'out_idxes': [64], 'out_shapes': [[1, 34, 34, 19]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [64, 29, 2], 'inp_shapes': [[1, 34, 34, 19], [1, 3, 3, 19], [19]], 'out_idxes': [65], 'out_shapes': [[1, 32, 32, 19]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [65, 30, 3], 'inp_shapes': [[1, 32, 32, 19], [37, 1, 1, 19], [37]], 'out_idxes': [66], 'out_shapes': [[1, 32, 32, 37]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [66, 60], 'inp_shapes': [[1, 32, 32, 37], [4, 2]], 'out_idxes': [67], 'out_shapes': [[1, 34, 34, 37]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [67, 31, 4], 'inp_shapes': [[1, 34, 34, 37], [1, 3, 3, 37], [37]], 'out_idxes': [68], 'out_shapes': [[1, 16, 16, 37]], 'params': [1, 1, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [68, 32, 5], 'inp_shapes': [[1, 16, 16, 37], [87, 1, 1, 37], [87]], 'out_idxes': [69], 'out_shapes': [[1, 16, 16, 87]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [69, 60], 'inp_shapes': [[1, 16, 16, 87], [4, 2]], 'out_idxes': [70], 'out_shapes': [[1, 18, 18, 87]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [70, 33, 6], 'inp_shapes': [[1, 18, 18, 87], [1, 3, 3, 87], [87]], 'out_idxes': [71], 'out_shapes': [[1, 16, 16, 87]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [71, 34, 7], 'inp_shapes': [[1, 16, 16, 87], [93, 1, 1, 87], [93]], 'out_idxes': [72], 'out_shapes': [[1, 16, 16, 93]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [72, 60], 'inp_shapes': [[1, 16, 16, 93], [4, 2]], 'out_idxes': [73], 'out_shapes': [[1, 18, 18, 93]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [73, 35, 8], 'inp_shapes': [[1, 18, 18, 93], [1, 3, 3, 93], [93]], 'out_idxes': [74], 'out_shapes': [[1, 8, 8, 93]], 'params': [1, 1, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [74, 36, 9], 'inp_shapes': [[1, 8, 8, 93], [193, 1, 1, 93], [193]], 'out_idxes': [75], 'out_shapes': [[1, 8, 8, 193]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [75, 60], 'inp_shapes': [[1, 8, 8, 193], [4, 2]], 'out_idxes': [76], 'out_shapes': [[1, 10, 10, 193]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [76, 37, 10], 'inp_shapes': [[1, 10, 10, 193], [1, 3, 3, 193], [193]], 'out_idxes': [77], 'out_shapes': [[1, 8, 8, 193]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [77, 38, 11], 'inp_shapes': [[1, 8, 8, 193], [205, 1, 1, 193], [205]], 'out_idxes': [78], 'out_shapes': [[1, 8, 8, 205]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [78, 60], 'inp_shapes': [[1, 8, 8, 205], [4, 2]], 'out_idxes': [79], 'out_shapes': [[1, 10, 10, 205]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [79, 39, 12], 'inp_shapes': [[1, 10, 10, 205], [1, 3, 3, 205], [205]], 'out_idxes': [80], 'out_shapes': [[1, 4, 4, 205]], 'params': [1, 1, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [80, 40, 13], 'inp_shapes': [[1, 4, 4, 205], [461, 1, 1, 205], [461]], 'out_idxes': [81], 'out_shapes': [[1, 4, 4, 461]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [81, 60], 'inp_shapes': [[1, 4, 4, 461], [4, 2]], 'out_idxes': [82], 'out_shapes': [[1, 6, 6, 461]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [82, 41, 14], 'inp_shapes': [[1, 6, 6, 461], [1, 3, 3, 461], [461]], 'out_idxes': [83], 'out_shapes': [[1, 4, 4, 461]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [83, 42, 15], 'inp_shapes': [[1, 4, 4, 461], [471, 1, 1, 461], [471]], 'out_idxes': [84], 'out_shapes': [[1, 4, 4, 471]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [84, 60], 'inp_shapes': [[1, 4, 4, 471], [4, 2]], 'out_idxes': [85], 'out_shapes': [[1, 6, 6, 471]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [85, 43, 16], 'inp_shapes': [[1, 6, 6, 471], [1, 3, 3, 471], [471]], 'out_idxes': [86], 'out_shapes': [[1, 4, 4, 471]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [86, 44, 17], 'inp_shapes': [[1, 4, 4, 471], [453, 1, 1, 471], [453]], 'out_idxes': [87], 'out_shapes': [[1, 4, 4, 453]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [87, 60], 'inp_shapes': [[1, 4, 4, 453], [4, 2]], 'out_idxes': [88], 'out_shapes': [[1, 6, 6, 453]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [88, 45, 18], 'inp_shapes': [[1, 6, 6, 453], [1, 3, 3, 453], [453]], 'out_idxes': [89], 'out_shapes': [[1, 4, 4, 453]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [89, 46, 19], 'inp_shapes': [[1, 4, 4, 453], [440, 1, 1, 453], [440]], 'out_idxes': [90], 'out_shapes': [[1, 4, 4, 440]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [90, 60], 'inp_shapes': [[1, 4, 4, 440], [4, 2]], 'out_idxes': [91], 'out_shapes': [[1, 6, 6, 440]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [91, 47, 20], 'inp_shapes': [[1, 6, 6, 440], [1, 3, 3, 440], [440]], 'out_idxes': [92], 'out_shapes': [[1, 4, 4, 440]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [92, 48, 21], 'inp_shapes': [[1, 4, 4, 440], [394, 1, 1, 440], [394]], 'out_idxes': [93], 'out_shapes': [[1, 4, 4, 394]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [93, 60], 'inp_shapes': [[1, 4, 4, 394], [4, 2]], 'out_idxes': [94], 'out_shapes': [[1, 6, 6, 394]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [94, 49, 22], 'inp_shapes': [[1, 6, 6, 394], [1, 3, 3, 394], [394]], 'out_idxes': [95], 'out_shapes': [[1, 4, 4, 394]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [95, 50, 23], 'inp_shapes': [[1, 4, 4, 394], [321, 1, 1, 394], [321]], 'out_idxes': [96], 'out_shapes': [[1, 4, 4, 321]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [96, 60], 'inp_shapes': [[1, 4, 4, 321], [4, 2]], 'out_idxes': [97], 'out_shapes': [[1, 6, 6, 321]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [97, 51, 24], 'inp_shapes': [[1, 6, 6, 321], [1, 3, 3, 321], [321]], 'out_idxes': [98], 'out_shapes': [[1, 2, 2, 321]], 'params': [1, 1, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [98, 52, 25], 'inp_shapes': [[1, 2, 2, 321], [415, 1, 1, 321], [415]], 'out_idxes': [99], 'out_shapes': [[1, 2, 2, 415]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [99, 60], 'inp_shapes': [[1, 2, 2, 415], [4, 2]], 'out_idxes': [100], 'out_shapes': [[1, 4, 4, 415]], 'params': [0, 0, 1, 1, 1, 1, 0, 0], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [100, 53, 26], 'inp_shapes': [[1, 4, 4, 415], [1, 3, 3, 415], [415]], 'out_idxes': [101], 'out_shapes': [[1, 2, 2, 415]], 'params': [1, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [101, 54, 27], 'inp_shapes': [[1, 2, 2, 415], [719, 1, 1, 415], [719]], 'out_idxes': [102], 'out_shapes': [[1, 2, 2, 719]], 'params': [0, 1, 1, 1, 1], 'mask': []}, {'layer_type': 'Pad', 'inp_idxes': [102, 59], 'inp_shapes': [[1, 2, 2, 719], [4, 2]], 'out_idxes': [103], 'out_shapes': [[1, 2, 2, 719]], 'params': [0, 0, 0, 0, 0, 0, 0, 0], 'mask': []}, {'layer_type': 'AveragePool2D', 'inp_idxes': [103], 'inp_shapes': [[1, 2, 2, 719]], 'out_idxes': [104], 'out_shapes': [[1, 1, 1, 719]], 'params': [2, 2, 2, 2], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [104], 'inp_shapes': [[1, 1, 1, 719]], 'out_idxes': [105], 'out_shapes': [[4]], 'params': [0], 'mask': []}, {'layer_type': 'Noop', 'inp_idxes': [105, 57, 56, 56], 'inp_shapes': [[4], [1], [1], [1]], 'out_idxes': [106], 'out_shapes': [[]], 'params': [0], 'mask': []}, {'layer_type': 'Pack', 'inp_idxes': [106, 58], 'inp_shapes': [[], []], 'out_idxes': [107], 'out_shapes': [[2]], 'params': [0], 'mask': []}, {'layer_type': 'Reshape', 'inp_idxes': [104, 107], 'inp_shapes': [[1, 1, 1, 719], [2]], 'out_idxes': [108], 'out_shapes': [[1, 719]], 'params': [], 'mask': []}, {'layer_type': 'FullyConnected', 'inp_idxes': [108, 61, 55], 'inp_shapes': [[1, 719], [10, 719], [10]], 'out_idxes': [109], 'out_shapes': [[1, 10]], 'params': [0], 'mask': []}]\n",
      "\n",
      "keep tensors: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108}\n",
      "skipping generated tensor: 0, b'serving_default_input:0'\n",
      "skipping generated tensor: 62, b'model_9/LAYER_0_pad/Pad'\n",
      "skipping generated tensor: 63, b'model_9/LAYER_1/Relu;model_9/LAYER_0/BiasAdd;model_9/LAYER_2/depthwise;model_9/LAYER_0/Conv2D;model_9/LAYER_0/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 64, b'model_9/LAYER_2_pad/Pad'\n",
      "skipping generated tensor: 65, b'model_9/LAYER_3/Relu;model_9/LAYER_2/BiasAdd;model_9/LAYER_2/depthwise;model_9/LAYER_2/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 66, b'model_9/LAYER_5/Relu;model_9/LAYER_4/BiasAdd;model_9/LAYER_6/depthwise;model_9/LAYER_4/Conv2D;model_9/LAYER_4/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 67, b'model_9/LAYER_6_pad/Pad'\n",
      "skipping generated tensor: 68, b'model_9/LAYER_7/Relu;model_9/LAYER_6/BiasAdd;model_9/LAYER_6/depthwise;model_9/LAYER_6/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 69, b'model_9/LAYER_9/Relu;model_9/LAYER_8/BiasAdd;model_9/LAYER_10/depthwise;model_9/LAYER_8/Conv2D;model_9/LAYER_8/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 70, b'model_9/LAYER_10_pad/Pad'\n",
      "skipping generated tensor: 71, b'model_9/LAYER_11/Relu;model_9/LAYER_10/BiasAdd;model_9/LAYER_10/depthwise;model_9/LAYER_10/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 72, b'model_9/LAYER_13/Relu;model_9/LAYER_12/BiasAdd;model_9/LAYER_14/depthwise;model_9/LAYER_12/Conv2D;model_9/LAYER_12/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 73, b'model_9/LAYER_14_pad/Pad'\n",
      "skipping generated tensor: 74, b'model_9/LAYER_15/Relu;model_9/LAYER_14/BiasAdd;model_9/LAYER_14/depthwise;model_9/LAYER_14/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 75, b'model_9/LAYER_17/Relu;model_9/LAYER_16/BiasAdd;model_9/LAYER_18/depthwise;model_9/LAYER_16/Conv2D;model_9/LAYER_16/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 76, b'model_9/LAYER_18_pad/Pad'\n",
      "skipping generated tensor: 77, b'model_9/LAYER_19/Relu;model_9/LAYER_18/BiasAdd;model_9/LAYER_18/depthwise;model_9/LAYER_18/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 78, b'model_9/LAYER_21/Relu;model_9/LAYER_20/BiasAdd;model_9/LAYER_22/depthwise;model_9/LAYER_20/Conv2D;model_9/LAYER_20/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 79, b'model_9/LAYER_22_pad/Pad'\n",
      "skipping generated tensor: 80, b'model_9/LAYER_23/Relu;model_9/LAYER_22/BiasAdd;model_9/LAYER_22/depthwise;model_9/LAYER_22/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 81, b'model_9/LAYER_25/Relu;model_9/LAYER_24/BiasAdd;model_9/LAYER_26/depthwise;model_9/LAYER_24/Conv2D;model_9/LAYER_24/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 82, b'model_9/LAYER_26_pad/Pad'\n",
      "skipping generated tensor: 83, b'model_9/LAYER_27/Relu;model_9/LAYER_26/BiasAdd;model_9/LAYER_26/depthwise;model_9/LAYER_26/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 84, b'model_9/LAYER_29/Relu;model_9/LAYER_28/BiasAdd;model_9/LAYER_30/depthwise;model_9/LAYER_28/Conv2D;model_9/LAYER_28/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 85, b'model_9/LAYER_30_pad/Pad'\n",
      "skipping generated tensor: 86, b'model_9/LAYER_31/Relu;model_9/LAYER_30/BiasAdd;model_9/LAYER_30/depthwise;model_9/LAYER_30/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 87, b'model_9/LAYER_33/Relu;model_9/LAYER_32/BiasAdd;model_9/LAYER_34/depthwise;model_9/LAYER_32/Conv2D;model_9/LAYER_32/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 88, b'model_9/LAYER_34_pad/Pad'\n",
      "skipping generated tensor: 89, b'model_9/LAYER_35/Relu;model_9/LAYER_34/BiasAdd;model_9/LAYER_34/depthwise;model_9/LAYER_34/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 90, b'model_9/LAYER_37/Relu;model_9/LAYER_36/BiasAdd;model_9/LAYER_38/depthwise;model_9/LAYER_36/Conv2D;model_9/LAYER_36/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 91, b'model_9/LAYER_38_pad/Pad'\n",
      "skipping generated tensor: 92, b'model_9/LAYER_39/Relu;model_9/LAYER_38/BiasAdd;model_9/LAYER_38/depthwise;model_9/LAYER_38/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 93, b'model_9/LAYER_41/Relu;model_9/LAYER_40/BiasAdd;model_9/LAYER_42/depthwise;model_9/LAYER_40/Conv2D;model_9/LAYER_40/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 94, b'model_9/LAYER_42_pad/Pad'\n",
      "skipping generated tensor: 95, b'model_9/LAYER_43/Relu;model_9/LAYER_42/BiasAdd;model_9/LAYER_42/depthwise;model_9/LAYER_42/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 96, b'model_9/LAYER_45/Relu;model_9/LAYER_44/BiasAdd;model_9/LAYER_46/depthwise;model_9/LAYER_44/Conv2D;model_9/LAYER_44/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 97, b'model_9/LAYER_46_pad/Pad'\n",
      "skipping generated tensor: 98, b'model_9/LAYER_47/Relu;model_9/LAYER_46/BiasAdd;model_9/LAYER_46/depthwise;model_9/LAYER_46/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 99, b'model_9/LAYER_49/Relu;model_9/LAYER_48/BiasAdd;model_9/LAYER_50/depthwise;model_9/LAYER_48/Conv2D;model_9/LAYER_48/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 100, b'model_9/LAYER_50_pad/Pad'\n",
      "skipping generated tensor: 101, b'model_9/LAYER_51/Relu;model_9/LAYER_50/BiasAdd;model_9/LAYER_50/depthwise;model_9/LAYER_50/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 102, b'model_9/LAYER_53/Relu;model_9/LAYER_52/BiasAdd;model_9/LAYER_52/Conv2D;model_9/LAYER_52/BiasAdd/ReadVariableOp'\n",
      "skipping generated tensor: 103, b'model_9/LAYER_54_pad/Pad'\n",
      "skipping generated tensor: 104, b'model_9/LAYER_54/AvgPool'\n",
      "skipping generated tensor: 105, b'model_9/LAYER_56/Shape'\n",
      "skipping generated tensor: 106, b'model_9/LAYER_56/strided_slice'\n",
      "skipping generated tensor: 107, b'model_9/LAYER_56/Reshape/shape'\n",
      "skipping generated tensor: 108, b'model_9/LAYER_56/Reshape'\n",
      "\n",
      "{'layer_type': 'FullyConnected', 'inp_idxes': [108, 61, 55], 'inp_shapes': [[1, 719], [10, 719], [10]], 'out_idxes': [109], 'out_shapes': [[1, 10]], 'params': [0], 'mask': []}\n",
      "dict_keys(['global_sf', 'k', 'num_cols', 'num_random', 'inp_idxes', 'out_idxes', 'layers', 'tensors', 'use_selectors', 'commit_before', 'commit_after'])\n",
      "[109]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/converter.py', '--model', '../../models/mobilenetv1/mobilenetv1.tflite', '--model_output', 'converted_model_new.msgpack', '--config_output', 'config_new.msgpack', '--scale_factor', '4096', '--k', '21', '--num_cols', '64', '--num_randoms', '65536'], returncode=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert model\n",
    "# !python ./tools/converter.py --model ./model.tflite --model_output converted_model_new.msgpack --config_output config_new.msgpack --scale_factor 512 --k 20 --num_cols 20 --num_randoms 4096\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/converter.py', \n",
    "    '--model', '../../models/mobilenetv1/mobilenetv1.tflite',\n",
    "    '--model_output', 'converted_model_new.msgpack',\n",
    "    '--config_output', 'config_new.msgpack',\n",
    "    '--scale_factor', '4096',\n",
    "    '--k', '21',\n",
    "    '--num_cols', '64',\n",
    "    '--num_randoms', '65536'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export 7.npy\n",
    "import numpy as np\n",
    "\n",
    "# load 7.npy and forward it to the model\n",
    "rand = np.random.rand(1, 32, 32, 3).astype(np.float32)\n",
    "np.save(\"7.npy\", rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/input_converter.py', '--model_config', 'converted_model_new.msgpack', '--inputs', '7.npy', '--output', 'example_inp_new.msgpack'], returncode=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert input\n",
    "import subprocess\n",
    "\n",
    "# !python ./tools/input_converter.py --model_config converted_model_new.msgpack --inputs 7.npy --output example_inp_new.msgpack\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/input_converter.py', \n",
    "    '--model_config', 'converted_model_new.msgpack',\n",
    "    '--inputs', '7.npy',\n",
    "    '--output', 'example_inp_new.msgpack'\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command_dir:  ./bin/m1_mac/\n",
      "Processing layer 0, type: Pad, inp_idxes: [0, 60], out_idxes: [62], layer_params: [0, 0, 1, 1, 1, 1, 0, 0]\n",
      "Out 0 shape: [1, 34, 34, 3]\n",
      "\n",
      "Processing layer 1, type: Conv2D, inp_idxes: [62, 28, 1], out_idxes: [63], layer_params: [0, 1, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 19]\n",
      "\n",
      "Processing layer 2, type: Pad, inp_idxes: [63, 60], out_idxes: [64], layer_params: [0, 0, 1, 1, 1, 1, 0, 0]\n",
      "Out 0 shape: [1, 34, 34, 19]\n",
      "\n",
      "Processing layer 3, type: Conv2D, inp_idxes: [64, 29, 2], out_idxes: [65], layer_params: [1, 1, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 19]\n",
      "\n",
      "Processing layer 4, type: Conv2D, inp_idxes: [65, 30, 3], out_idxes: [66], layer_params: [0, 1, 1, 1, 1]\n",
      "Out 0 shape: [1, 32, 32, 37]\n",
      "\n",
      "Processing layer 5, type: Pad, inp_idxes: [66, 60], out_idxes: [67], layer_params: [0, 0, 1, 1, 1, 1, 0, 0]\n",
      "Out 0 shape: [1, 34, 34, 37]\n",
      "\n",
      "Processing layer 6, type: Conv2D, inp_idxes: [67, 31, 4], out_idxes: [68], layer_params: [1, 1, 1, 2, 2]\n",
      "Out 0 shape: [1, 16, 16, 37]\n",
      "\n",
      "Processing layer 7, type: Conv2D, inp_idxes: [68, 32, 5], out_idxes: [69], layer_params: [0, 1, 1, 1, 1]\n",
      "Out 0 shape: [1, 16, 16, 87]\n",
      "\n",
      "Processing layer 8, type: Pad, inp_idxes: [69, 60], out_idxes: [70], layer_params: [0, 0, 1, 1, 1, 1, 0, 0]\n",
      "Out 0 shape: [1, 18, 18, 87]\n",
      "\n",
      "Processing layer 9, type: Conv2D, inp_idxes: [70, 33, 6], out_idxes: [71], layer_params: [1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m command \u001b[38;5;241m=\u001b[39m [command_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_circuit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverted_model_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample_inp_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkzg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the command\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:507\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    509\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1126\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1189\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1917\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1875\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1875\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1879\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import platform\n",
    "command_dir = './bin/m1_mac/' if platform.processor() == \"arm\" else './bin/'\n",
    "print(\"command_dir: \", command_dir)\n",
    "\n",
    "# Command to run\n",
    "command = [command_dir + 'test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (zkml_bench_env)",
   "language": "python",
   "name": "zkml_bench_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
