{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 50 CPUs with lowest load: [7, 6, 3, 5, 4, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def get_cpu_load():\n",
    "    # Get CPU usage for each core\n",
    "    cpu_loads = psutil.cpu_percent(interval=1, percpu=True)\n",
    "    return cpu_loads\n",
    "\n",
    "def select_k_cpus_with_lowest_load(k):\n",
    "    # Get CPU usage for each core\n",
    "    cpu_loads = get_cpu_load()\n",
    "    \n",
    "    # Create a list of tuples (core_id, load)\n",
    "    cpu_load_tuples = list(enumerate(cpu_loads))\n",
    "    \n",
    "    # Sort the list based on load\n",
    "    sorted_cpu_loads = sorted(cpu_load_tuples, key=lambda x: x[1])\n",
    "    \n",
    "    # Get the IDs of the K cores with lowest load\n",
    "    selected_cpus = [core[0] for core in sorted_cpu_loads[:k]]\n",
    "    \n",
    "    return selected_cpus\n",
    "\n",
    "# Example usage\n",
    "k = 50  # Number of CPUs with lowest load\n",
    "selected_cpus = select_k_cpus_with_lowest_load(k)\n",
    "print(f\"Selected {k} CPUs with lowest load:\", selected_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Process' object has no attribute 'cpu_affinity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Set the CPU affinity to only CPU core 0\u001b[39;00m\n\u001b[1;32m     18\u001b[0m cpu_list \u001b[38;5;241m=\u001b[39m selected_cpus\n\u001b[0;32m---> 19\u001b[0m \u001b[43mset_cpu_affinity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpu_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[163], line 7\u001b[0m, in \u001b[0;36mset_cpu_affinity\u001b[0;34m(pid, cpu_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     p \u001b[38;5;241m=\u001b[39m psutil\u001b[38;5;241m.\u001b[39mProcess(pid)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_affinity\u001b[49m(cpu_list)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU affinity for process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m set to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcpu_list\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m psutil\u001b[38;5;241m.\u001b[39mNoSuchProcess:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Process' object has no attribute 'cpu_affinity'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "\n",
    "def set_cpu_affinity(pid, cpu_list):\n",
    "    try:\n",
    "        p = psutil.Process(pid)\n",
    "        p.cpu_affinity(cpu_list)\n",
    "        print(f\"CPU affinity for process {pid} set to: {cpu_list}\")\n",
    "    except psutil.NoSuchProcess:\n",
    "        print(f\"Process with PID {pid} does not exist.\")\n",
    "    except psutil.AccessDenied:\n",
    "        print(\"Permission denied. You may need sudo privileges to set CPU affinity.\")\n",
    "\n",
    "# Get the process ID of the current process\n",
    "pid = os.getpid()\n",
    "\n",
    "# Set the CPU affinity to only CPU core 0\n",
    "cpu_list = selected_cpus\n",
    "set_cpu_affinity(pid, cpu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# class ResNet20Cifar100(tf.keras.Model):\n",
    "#     def __init__(self, num_classes=100):\n",
    "#         super(ResNet20Cifar100, self).__init__()\n",
    "\n",
    "#         # Initial Conv Layer\n",
    "#         self.conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.bn1 = layers.BatchNormalization()\n",
    "#         self.relu1 = layers.ReLU()\n",
    "\n",
    "#         # Layer 1 Block 1\n",
    "#         self.layer1_0_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_0_bn1 = layers.BatchNormalization()\n",
    "#         self.layer1_0_relu1 = layers.ReLU()\n",
    "#         self.layer1_0_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_0_bn2 = layers.BatchNormalization()\n",
    "#         self.layer1_0_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 1 Block 2\n",
    "#         self.layer1_1_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_1_bn1 = layers.BatchNormalization()\n",
    "#         self.layer1_1_relu1 = layers.ReLU()\n",
    "#         self.layer1_1_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_1_bn2 = layers.BatchNormalization()\n",
    "#         self.layer1_1_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 1 Block 3\n",
    "#         self.layer1_2_conv1 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_2_bn1 = layers.BatchNormalization()\n",
    "#         self.layer1_2_relu1 = layers.ReLU()\n",
    "#         self.layer1_2_conv2 = layers.Conv2D(16, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer1_2_bn2 = layers.BatchNormalization()\n",
    "#         self.layer1_2_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 2 Block 1 (with downsampling)\n",
    "#         self.layer2_0_conv1 = layers.Conv2D(32, kernel_size=3, strides=2, padding='same', use_bias=False)\n",
    "#         self.layer2_0_bn1 = layers.BatchNormalization()\n",
    "#         self.layer2_0_relu1 = layers.ReLU()\n",
    "#         self.layer2_0_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_0_bn2 = layers.BatchNormalization()\n",
    "#         self.layer2_0_relu2 = layers.ReLU()\n",
    "#         self.layer2_0_downsample = models.Sequential([\n",
    "#             layers.Conv2D(32, kernel_size=1, strides=2, use_bias=False),\n",
    "#             layers.BatchNormalization()\n",
    "#         ])\n",
    "\n",
    "#         # Layer 2 Block 2\n",
    "#         self.layer2_1_conv1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_1_bn1 = layers.BatchNormalization()\n",
    "#         self.layer2_1_relu1 = layers.ReLU()\n",
    "#         self.layer2_1_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_1_bn2 = layers.BatchNormalization()\n",
    "#         self.layer2_1_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 2 Block 3\n",
    "#         self.layer2_2_conv1 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_2_bn1 = layers.BatchNormalization()\n",
    "#         self.layer2_2_relu1 = layers.ReLU()\n",
    "#         self.layer2_2_conv2 = layers.Conv2D(32, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer2_2_bn2 = layers.BatchNormalization()\n",
    "#         self.layer2_2_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 3 Block 1 (with downsampling)\n",
    "#         self.layer3_0_conv1 = layers.Conv2D(64, kernel_size=3, strides=2, padding='same', use_bias=False)\n",
    "#         self.layer3_0_bn1 = layers.BatchNormalization()\n",
    "#         self.layer3_0_relu1 = layers.ReLU()\n",
    "#         self.layer3_0_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_0_bn2 = layers.BatchNormalization()\n",
    "#         self.layer3_0_downsample = models.Sequential([\n",
    "#             layers.Conv2D(64, kernel_size=1, strides=2, use_bias=False),\n",
    "#             layers.BatchNormalization()\n",
    "#         ])\n",
    "#         self.layer3_0_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 3 Block 2\n",
    "#         self.layer3_1_conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_1_bn1 = layers.BatchNormalization()\n",
    "#         self.layer3_1_relu1 = layers.ReLU()\n",
    "#         self.layer3_1_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_1_bn2 = layers.BatchNormalization()\n",
    "#         self.layer3_1_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Layer 3 Block 3\n",
    "#         self.layer3_2_conv1 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_2_bn1 = layers.BatchNormalization()\n",
    "#         self.layer3_2_relu1 = layers.ReLU()\n",
    "#         self.layer3_2_conv2 = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False)\n",
    "#         self.layer3_2_bn2 = layers.BatchNormalization()\n",
    "#         self.layer3_2_relu2 = layers.ReLU()\n",
    "\n",
    "#         # Pooling and classification layers\n",
    "#         self.avgpool = layers.GlobalAveragePooling2D()\n",
    "#         self.fc = layers.Dense(num_classes)\n",
    "\n",
    "#     def call(self, x, training=False):\n",
    "#         # Initial layer\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x, training=training)\n",
    "#         x = self.relu1(x)\n",
    "\n",
    "#         # Layer 1 Block 1\n",
    "#         residual = x\n",
    "#         x = self.layer1_0_conv1(x)\n",
    "#         x = self.layer1_0_bn1(x, training=training)\n",
    "#         x = self.layer1_0_relu1(x)\n",
    "#         x = self.layer1_0_conv2(x)\n",
    "#         x = self.layer1_0_bn2(x, training=training)\n",
    "#         x += residual  # Add operation\n",
    "#         x = self.layer1_0_relu2(x)\n",
    "\n",
    "#         # Layer 1 Block 2\n",
    "#         residual = x\n",
    "#         x = self.layer1_1_conv1(x)\n",
    "#         x = self.layer1_1_bn1(x, training=training)\n",
    "#         x = self.layer1_1_relu1(x)\n",
    "#         x = self.layer1_1_conv2(x)\n",
    "#         x = self.layer1_1_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer1_1_relu2(x)\n",
    "\n",
    "#         # Layer 1 Block 3\n",
    "#         residual = x\n",
    "#         x = self.layer1_2_conv1(x)\n",
    "#         x = self.layer1_2_bn1(x, training=training)\n",
    "#         x = self.layer1_2_relu1(x)\n",
    "#         x = self.layer1_2_conv2(x)\n",
    "#         x = self.layer1_2_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer1_2_relu2(x)\n",
    "\n",
    "#         # Layer 2 Block 1 (with downsampling)\n",
    "#         residual = self.layer2_0_downsample(x, training=training)\n",
    "#         x = self.layer2_0_conv1(x)\n",
    "#         x = self.layer2_0_bn1(x, training=training)\n",
    "#         x = self.layer2_0_relu1(x)\n",
    "#         x = self.layer2_0_conv2(x)\n",
    "#         x = self.layer2_0_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer2_0_relu2(x)\n",
    "\n",
    "#         # Layer 2 Block 2\n",
    "#         residual = x\n",
    "#         x = self.layer2_1_conv1(x)\n",
    "#         x = self.layer2_1_bn1(x, training=training)\n",
    "#         x = self.layer2_1_relu1(x)\n",
    "#         x = self.layer2_1_conv2(x)\n",
    "#         x = self.layer2_1_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer2_1_relu2(x)\n",
    "\n",
    "#         # Layer 2 Block 3\n",
    "#         residual = x\n",
    "#         x = self.layer2_2_conv1(x)\n",
    "#         x = self.layer2_2_bn1(x, training=training)\n",
    "#         x = self.layer2_2_relu1(x)\n",
    "#         x = self.layer2_2_conv2(x)\n",
    "#         x = self.layer2_2_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer2_2_relu2(x)\n",
    "\n",
    "#         # Layer 3 Block 1 (with downsampling)\n",
    "#         residual = self.layer3_0_downsample(x, training=training)\n",
    "#         x = self.layer3_0_conv1(x)\n",
    "#         x = self.layer3_0_bn1(x, training=training)\n",
    "#         x = self.layer3_0_relu1(x)\n",
    "#         x = self.layer3_0_conv2(x)\n",
    "#         x = self.layer3_0_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer3_0_relu2(x)\n",
    "\n",
    "#         # Layer 3 Block 2\n",
    "#         residual = x\n",
    "#         x = self.layer3_1_conv1(x)\n",
    "#         x = self.layer3_1_bn1(x, training=training)\n",
    "#         x = self.layer3_1_relu1(x)\n",
    "#         x = self.layer3_1_conv2(x)\n",
    "#         x = self.layer3_1_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer3_1_relu2(x)\n",
    "\n",
    "#         # Layer 3 Block 3\n",
    "#         residual = x\n",
    "#         x = self.layer3_2_conv1(x)\n",
    "#         x = self.layer3_2_bn1(x, training=training)\n",
    "#         x = self.layer3_2_relu1(x)\n",
    "#         x = self.layer3_2_conv2(x)\n",
    "#         x = self.layer3_2_bn2(x, training=training)\n",
    "#         x += residual\n",
    "#         x = self.layer3_2_relu2(x)\n",
    "\n",
    "#         # Pooling and classification\n",
    "#         x = self.avgpool(x)\n",
    "#         x = self.fc(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Layer === :  input_3\n",
      "------------- Skipping layer input_3\n",
      "=== Layer === :  conv1\n",
      "shape pytroch:  torch.Size([16, 3, 3, 3])  \t shape keras:  (3, 3, 3, 16)\n",
      "=== Layer === :  bn1\n",
      "=== Layer === :  re_lu_38\n",
      "------------- Skipping layer re_lu_38\n",
      "=== Layer === :  layer1.0.conv1\n",
      "shape pytroch:  torch.Size([16, 16, 3, 3])  \t shape keras:  (3, 3, 16, 16)\n",
      "=== Layer === :  layer1.0.bn1\n",
      "=== Layer === :  re_lu_39\n",
      "------------- Skipping layer re_lu_39\n",
      "=== Layer === :  layer1.0.conv2\n",
      "shape pytroch:  torch.Size([16, 16, 3, 3])  \t shape keras:  (3, 3, 16, 16)\n",
      "=== Layer === :  layer1.0.bn2\n",
      "=== Layer === :  add_18\n",
      "------------- Skipping layer add_18\n",
      "=== Layer === :  re_lu_40\n",
      "------------- Skipping layer re_lu_40\n",
      "=== Layer === :  layer1.1.conv1\n",
      "shape pytroch:  torch.Size([16, 16, 3, 3])  \t shape keras:  (3, 3, 16, 16)\n",
      "=== Layer === :  layer1.1.bn1\n",
      "=== Layer === :  re_lu_41\n",
      "------------- Skipping layer re_lu_41\n",
      "=== Layer === :  layer1.1.conv2\n",
      "shape pytroch:  torch.Size([16, 16, 3, 3])  \t shape keras:  (3, 3, 16, 16)\n",
      "=== Layer === :  layer1.1.bn2\n",
      "=== Layer === :  add_19\n",
      "------------- Skipping layer add_19\n",
      "=== Layer === :  re_lu_42\n",
      "------------- Skipping layer re_lu_42\n",
      "=== Layer === :  layer1.2.conv1\n",
      "shape pytroch:  torch.Size([16, 16, 3, 3])  \t shape keras:  (3, 3, 16, 16)\n",
      "=== Layer === :  layer1.2.bn1\n",
      "=== Layer === :  re_lu_43\n",
      "------------- Skipping layer re_lu_43\n",
      "=== Layer === :  layer1.2.conv2\n",
      "shape pytroch:  torch.Size([16, 16, 3, 3])  \t shape keras:  (3, 3, 16, 16)\n",
      "=== Layer === :  layer1.2.bn2\n",
      "=== Layer === :  add_20\n",
      "------------- Skipping layer add_20\n",
      "=== Layer === :  re_lu_44\n",
      "------------- Skipping layer re_lu_44\n",
      "=== Layer === :  layer2.0.conv1\n",
      "shape pytroch:  torch.Size([32, 16, 3, 3])  \t shape keras:  (3, 3, 16, 32)\n",
      "=== Layer === :  layer2.0.bn1\n",
      "=== Layer === :  re_lu_45\n",
      "------------- Skipping layer re_lu_45\n",
      "=== Layer === :  layer2.0.conv2\n",
      "shape pytroch:  torch.Size([32, 32, 3, 3])  \t shape keras:  (3, 3, 32, 32)\n",
      "=== Layer === :  layer2.0.downsample.0\n",
      "shape pytroch:  torch.Size([32, 16, 1, 1])  \t shape keras:  (1, 1, 16, 32)\n",
      "=== Layer === :  layer2.0.bn2\n",
      "=== Layer === :  layer2.0.downsample.1\n",
      "=== Layer === :  add_21\n",
      "------------- Skipping layer add_21\n",
      "=== Layer === :  re_lu_46\n",
      "------------- Skipping layer re_lu_46\n",
      "=== Layer === :  layer2.1.conv1\n",
      "shape pytroch:  torch.Size([32, 32, 3, 3])  \t shape keras:  (3, 3, 32, 32)\n",
      "=== Layer === :  layer2.1.bn1\n",
      "=== Layer === :  re_lu_47\n",
      "------------- Skipping layer re_lu_47\n",
      "=== Layer === :  layer2.1.conv2\n",
      "shape pytroch:  torch.Size([32, 32, 3, 3])  \t shape keras:  (3, 3, 32, 32)\n",
      "=== Layer === :  layer2.1.bn2\n",
      "=== Layer === :  add_22\n",
      "------------- Skipping layer add_22\n",
      "=== Layer === :  re_lu_48\n",
      "------------- Skipping layer re_lu_48\n",
      "=== Layer === :  layer2.2.conv1\n",
      "shape pytroch:  torch.Size([32, 32, 3, 3])  \t shape keras:  (3, 3, 32, 32)\n",
      "=== Layer === :  layer2.2.bn1\n",
      "=== Layer === :  re_lu_49\n",
      "------------- Skipping layer re_lu_49\n",
      "=== Layer === :  layer2.2.conv2\n",
      "shape pytroch:  torch.Size([32, 32, 3, 3])  \t shape keras:  (3, 3, 32, 32)\n",
      "=== Layer === :  layer2.2.bn2\n",
      "=== Layer === :  add_23\n",
      "------------- Skipping layer add_23\n",
      "=== Layer === :  re_lu_50\n",
      "------------- Skipping layer re_lu_50\n",
      "=== Layer === :  layer3.0.conv1\n",
      "shape pytroch:  torch.Size([64, 32, 3, 3])  \t shape keras:  (3, 3, 32, 64)\n",
      "=== Layer === :  layer3.0.bn1\n",
      "=== Layer === :  re_lu_51\n",
      "------------- Skipping layer re_lu_51\n",
      "=== Layer === :  layer3.0.conv2\n",
      "shape pytroch:  torch.Size([64, 64, 3, 3])  \t shape keras:  (3, 3, 64, 64)\n",
      "=== Layer === :  layer3.0.downsample.0\n",
      "shape pytroch:  torch.Size([64, 32, 1, 1])  \t shape keras:  (1, 1, 32, 64)\n",
      "=== Layer === :  layer3.0.bn2\n",
      "=== Layer === :  layer3.0.downsample.1\n",
      "=== Layer === :  add_24\n",
      "------------- Skipping layer add_24\n",
      "=== Layer === :  re_lu_52\n",
      "------------- Skipping layer re_lu_52\n",
      "=== Layer === :  layer3.1.conv1\n",
      "shape pytroch:  torch.Size([64, 64, 3, 3])  \t shape keras:  (3, 3, 64, 64)\n",
      "=== Layer === :  layer3.1.bn1\n",
      "=== Layer === :  re_lu_53\n",
      "------------- Skipping layer re_lu_53\n",
      "=== Layer === :  layer3.1.conv2\n",
      "shape pytroch:  torch.Size([64, 64, 3, 3])  \t shape keras:  (3, 3, 64, 64)\n",
      "=== Layer === :  layer3.1.bn2\n",
      "=== Layer === :  add_25\n",
      "------------- Skipping layer add_25\n",
      "=== Layer === :  re_lu_54\n",
      "------------- Skipping layer re_lu_54\n",
      "=== Layer === :  layer3.2.conv1\n",
      "shape pytroch:  torch.Size([64, 64, 3, 3])  \t shape keras:  (3, 3, 64, 64)\n",
      "=== Layer === :  layer3.2.bn1\n",
      "=== Layer === :  re_lu_55\n",
      "------------- Skipping layer re_lu_55\n",
      "=== Layer === :  layer3.2.conv2\n",
      "shape pytroch:  torch.Size([64, 64, 3, 3])  \t shape keras:  (3, 3, 64, 64)\n",
      "=== Layer === :  layer3.2.bn2\n",
      "=== Layer === :  add_26\n",
      "------------- Skipping layer add_26\n",
      "=== Layer === :  re_lu_56\n",
      "------------- Skipping layer re_lu_56\n",
      "=== Layer === :  global_average_pooling2d_2\n",
      "------------- Skipping layer global_average_pooling2d_2\n",
      "=== Layer === :  fc\n",
      "Weights successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Dense, Add, Input, ReLU, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import torch\n",
    "\n",
    "# Define Keras model with named layers that match PyTorch `state_dict` keys\n",
    "def build_keras_model():\n",
    "    input = Input(shape=(32, 32, 3))  # Adjust based on input shape (e.g., CIFAR-10 dimensions)\n",
    "    x = Conv2D(16, (3, 3), padding='same', name='conv1',use_bias=False)(input)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Residual block layers\n",
    "    x = residual_block(x, filters=16, block_prefix='layer1.0')\n",
    "    x = residual_block(x, filters=16, block_prefix='layer1.1')\n",
    "    x = residual_block(x, filters=16, block_prefix='layer1.2')\n",
    "    \n",
    "    x = residual_block(x, filters=32, block_prefix='layer2.0', downsample=True)\n",
    "    x = residual_block(x, filters=32, block_prefix='layer2.1')\n",
    "    x = residual_block(x, filters=32, block_prefix='layer2.2')\n",
    "    \n",
    "    x = residual_block(x, filters=64, block_prefix='layer3.0', downsample=True)\n",
    "    x = residual_block(x, filters=64, block_prefix='layer3.1')\n",
    "    x = residual_block(x, filters=64, block_prefix='layer3.2')\n",
    "    \n",
    "    # Fully connected (dense) layer\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Dense(100, name='fc',use_bias=True)(x)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Helper function to create a named residual block\n",
    "def residual_block(x, filters, block_prefix, downsample=False):\n",
    "    identity = x\n",
    "    if downsample:\n",
    "        identity = Conv2D(filters, (1, 1), strides=2, name=f'{block_prefix}.downsample.0',use_bias=False)(identity)\n",
    "        identity = BatchNormalization(name=f'{block_prefix}.downsample.1')(identity)\n",
    "        x = Conv2D(filters, (3, 3), strides=2, padding='same', name=f'{block_prefix}.conv1',use_bias=False)(x)\n",
    "    else:\n",
    "        x = Conv2D(filters, (3, 3), padding='same', name=f'{block_prefix}.conv1',use_bias=False)(x)\n",
    "    \n",
    "    x = BatchNormalization(name=f'{block_prefix}.bn1')(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters, (3, 3), padding='same', name=f'{block_prefix}.conv2',use_bias=False)(x)\n",
    "    x = BatchNormalization(name=f'{block_prefix}.bn2')(x)\n",
    "    \n",
    "    x = Add()([x, identity])\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_pytorch_weights_to_keras(pytorch_state_dict, keras_model):\n",
    "    for layer in keras_model.layers:\n",
    "        print(\"=== Layer === : \", layer.name)\n",
    "        # Prepare PyTorch keys for corresponding Keras layer\n",
    "        layer_name = layer.name\n",
    "        if isinstance(layer, Conv2D):\n",
    "            # weight_orig_key = f'{layer_name}.weight_orig'\n",
    "            weight_orig_key = f'{layer_name}.weight'\n",
    "            # weight_mask_key = f'{layer_name}.weight_mask'\n",
    "            if weight_orig_key in pytorch_state_dict:\n",
    "                print(\"shape pytroch: \", pytorch_state_dict[weight_orig_key].shape,\" \\t shape keras: \", layer.get_weights()[0].shape)\n",
    "\n",
    "                layer.set_weights([pytorch_state_dict[weight_orig_key].numpy().transpose(2, 3, 1, 0)])\n",
    "            # elif weight_mask_key in pytorch_state_dict:\n",
    "            #     layer.set_weights([pytorch_state_dict[weight_mask_key].numpy()])\n",
    "            else:\n",
    "                print(f\"Error: Weights not found for layer {layer_name}\")\n",
    "                return\n",
    "            \n",
    "            # check if conv needs bias\n",
    "            if len(layer.get_weights()) > 1:\n",
    "                bias_key = f'{layer_name}.bias'\n",
    "                if bias_key in pytorch_state_dict:\n",
    "                    layer.set_weights([pytorch_state_dict[weight_orig_key].numpy().transpose(2, 3, 1, 0), pytorch_state_dict[bias_key].numpy()])\n",
    "                else:\n",
    "                    print(f\"Error: Bias not found for layer {layer_name}\")\n",
    "                    return\n",
    "\n",
    "        elif isinstance(layer, BatchNormalization):\n",
    "            weight_key = f'{layer_name}.weight'\n",
    "            bias_key = f'{layer_name}.bias'\n",
    "            mean_key = f'{layer_name}.running_mean'\n",
    "            var_key = f'{layer_name}.running_var'\n",
    "            if all(key in pytorch_state_dict for key in [weight_key, bias_key, mean_key, var_key]):\n",
    "                layer.set_weights([\n",
    "                    pytorch_state_dict[weight_key].numpy(),\n",
    "                    pytorch_state_dict[bias_key].numpy(),\n",
    "                    pytorch_state_dict[mean_key].numpy(),\n",
    "                    pytorch_state_dict[var_key].numpy()\n",
    "                ])\n",
    "            else:\n",
    "                print(f\"Error: Weights not found for layer {layer_name}\")\n",
    "                return\n",
    "\n",
    "        elif isinstance(layer, Dense):\n",
    "            weight_orig_key = f'{layer_name}.weight'\n",
    "            # weight_mask_key = f'{layer_name}.weight_mask'\n",
    "            bias_key = f'{layer_name}.bias'\n",
    "            if weight_orig_key in pytorch_state_dict and bias_key in pytorch_state_dict:\n",
    "                layer.set_weights([\n",
    "                    pytorch_state_dict[weight_orig_key].numpy().T,  # Keras uses [input_dim, output_dim]\n",
    "                    pytorch_state_dict[bias_key].numpy()\n",
    "                ])\n",
    "            # elif weight_mask_key in pytorch_state_dict and bias_key in pytorch_state_dict:\n",
    "            #     layer.set_weights([\n",
    "            #         pytorch_state_dict[weight_mask_key].numpy().T,\n",
    "            #         pytorch_state_dict[bias_key].numpy()\n",
    "            #     ])\n",
    "            else:\n",
    "                print(f\"Error: Weights not found for layer {layer_name}\")\n",
    "                return\n",
    "            \n",
    "        else:\n",
    "            print(f\"------------- Skipping layer {layer_name}\")\n",
    "\n",
    "    print(\"Weights successfully loaded!\")\n",
    "\n",
    "# Example usage:\n",
    "pytorch_model = torch.load('../../models/resnet20/unpruned.pth.tar',map_location=\"cpu\")  # Load your PyTorch model\n",
    "# state_dict = pytorch_model['state_dict']  # or pytorch_model.state_dict() if it's a torch.nn.Module\n",
    "state_dict = pytorch_model\n",
    "keras_model = build_keras_model()\n",
    "\n",
    "# load the weights\n",
    "def apply_mask_and_zero_out(state_dict):\n",
    "    new_state_dict = {}\n",
    "    \n",
    "    for key, value in state_dict.items():\n",
    "        if \"weight_mask\" in key:\n",
    "            # Extract corresponding weight_orig and weight_mask\n",
    "            weight_orig_key = key.replace(\"weight_mask\", \"weight_orig\")\n",
    "            weight_mask = value\n",
    "            weight_orig = state_dict[weight_orig_key]\n",
    "\n",
    "            # Apply the mask: keep values in weight_orig corresponding to mask = 1, zero out others\n",
    "            new_weights = weight_orig * weight_mask\n",
    "\n",
    "            # Update the new_state_dict with the proper key (removing _orig)\n",
    "            new_key = weight_orig_key.replace(\"weight_orig\", \"weight\")\n",
    "            new_state_dict[new_key] = new_weights\n",
    "        else:\n",
    "            # Keep other parameters (bias, running_mean, running_var, etc.) as they are\n",
    "            if \"weight_orig\" not in key and \"weight_mask\" not in key:\n",
    "                new_state_dict[key] = value\n",
    "    return new_state_dict\n",
    "\n",
    "new_state_dict = apply_mask_and_zero_out(state_dict)\n",
    "load_pytorch_weights_to_keras(new_state_dict, keras_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 100s 253ms/step - loss: 0.7733 - accuracy: 0.7712\n",
      "313/313 [==============================] - 6s 16ms/step - loss: 16.0823 - accuracy: 0.6612\n",
      "Accuracy on CIFAR-100 test set: 66.12%\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of keras_model on CIFAR-100 test set\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "cifar100_nm = [[0.5071,0.4867,0.4408],[0.2675,0.2565,0.2761]]\n",
    "\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "# apply cifar100_nm to x_test\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_test = x_test - cifar100_nm[1]\n",
    "x_test = x_test / cifar100_nm[0]\n",
    "y_test = to_categorical(y_test, num_classes=100)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_train = x_train - cifar100_nm[1]\n",
    "x_train = x_train / cifar100_nm[0]\n",
    "y_train = to_categorical(y_train, num_classes=100)\n",
    "\n",
    "# train the model\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# define small learning rate\n",
    "keras_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=loss, metrics=['accuracy'])\n",
    "keras_model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "keras_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# set model on evaluation mode\n",
    "_, accuracy = keras_model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"Accuracy on CIFAR-100 test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "y_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import math\n",
    "# import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "# __all__ = ['resnet20_cifar','resnet20_cifar100', 'resnet32_cifar', 'resnet44_cifar', 'resnet56_cifar']\n",
    "# weight_dict = {'resnet32_cifar': \"\", #/raid/kaixin/programs/layer-adaptive-sparsity/pretrained/latest_resnet32_cifar.pth.tar\n",
    "#                 'resnet20_cifar': \"\"} #/raid/kaixin/programs/layer-adaptive-sparsity/pretrained/latest_resnet20_cifar.pth.tar\n",
    "\n",
    "# NUM_CLASSES = 10\n",
    "\n",
    "# def conv3x3(in_planes, out_planes, stride=1):\n",
    "#     \"\"\"3x3 convolution with padding\"\"\"\n",
    "#     return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "#                      padding=1, bias=False)\n",
    "\n",
    "# class BasicBlock(nn.Module):\n",
    "#     expansion = 1\n",
    "\n",
    "#     def __init__(self, block_gates, inplanes, planes, stride=1, downsample=None):\n",
    "#         super(BasicBlock, self).__init__()\n",
    "#         self.block_gates = block_gates\n",
    "#         self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "#         self.bn1 = nn.BatchNorm2d(planes)\n",
    "#         self.relu1 = nn.ReLU(inplace=False)  # To enable layer removal inplace must be False\n",
    "#         self.conv2 = conv3x3(planes, planes)\n",
    "#         self.bn2 = nn.BatchNorm2d(planes)\n",
    "#         self.relu2 = nn.ReLU(inplace=False)\n",
    "#         self.downsample = downsample\n",
    "#         self.stride = stride\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         residual = out = x\n",
    "\n",
    "#         if self.block_gates[0]:\n",
    "#             out = self.conv1(x)\n",
    "#             out = self.bn1(out)\n",
    "#             out = self.relu1(out)\n",
    "\n",
    "#         if self.block_gates[1]:\n",
    "#             out = self.conv2(out)\n",
    "#             out = self.bn2(out)\n",
    "\n",
    "#         if self.downsample is not None:\n",
    "#             residual = self.downsample(x)\n",
    "\n",
    "#         out = residual + out\n",
    "#         out = self.relu2(out)\n",
    "\n",
    "#         return out\n",
    "\n",
    "\n",
    "# class ResNetCifar(nn.Module):\n",
    "\n",
    "#     def __init__(self, block, layers, num_classes=NUM_CLASSES):\n",
    "#         self.nlayers = 0\n",
    "#         # Each layer manages its own gates\n",
    "#         self.layer_gates = []\n",
    "#         for layer in range(3):\n",
    "#             # For each of the 3 layers, create block gates: each block has two layers\n",
    "#             self.layer_gates.append([])  # [True, True] * layers[layer])\n",
    "#             for blk in range(layers[layer]):\n",
    "#                 self.layer_gates[layer].append([True, True])\n",
    "\n",
    "#         self.inplanes = 16  # 64\n",
    "#         super(ResNetCifar, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.layer1 = self._make_layer(self.layer_gates[0], block, 16, layers[0])\n",
    "#         self.layer2 = self._make_layer(self.layer_gates[1], block, 32, layers[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(self.layer_gates[2], block, 64, layers[2], stride=2)\n",
    "#         self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "#         self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 m.weight.data.fill_(1)\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "#     def _make_layer(self, layer_gates, block, planes, blocks, stride=1):\n",
    "#         downsample = None\n",
    "#         if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "#             downsample = nn.Sequential(\n",
    "#                 nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "#                           kernel_size=1, stride=stride, bias=False),\n",
    "#                 nn.BatchNorm2d(planes * block.expansion),\n",
    "#             )\n",
    "\n",
    "#         layers = []\n",
    "#         layers.append(block(layer_gates[0], self.inplanes, planes, stride, downsample))\n",
    "#         self.inplanes = planes * block.expansion\n",
    "#         for i in range(1, blocks):\n",
    "#             layers.append(block(layer_gates[i], self.inplanes, planes))\n",
    "\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "\n",
    "#         return x\n",
    "    \n",
    "# def resnet20_cifar100(pretrained=False, **kwargs):\n",
    "#     model = ResNetCifar(BasicBlock, [3, 3, 3], **kwargs)\n",
    "#     if pretrained:\n",
    "#         model.load_state_dict(torch.load(weight_dict['resnet20_cifar'])[\"model_state_dict\"])\n",
    "#     return model\n",
    "\n",
    "# torch_model = resnet20_cifar100(pretrained=False, num_classes=100)\n",
    "\n",
    "# def apply_mask_and_zero_out(state_dict):\n",
    "#     new_state_dict = {}\n",
    "    \n",
    "#     for key, value in state_dict.items():\n",
    "#         if \"weight_mask\" in key:\n",
    "#             # Extract corresponding weight_orig and weight_mask\n",
    "#             weight_orig_key = key.replace(\"weight_mask\", \"weight_orig\")\n",
    "#             weight_mask = value\n",
    "#             weight_orig = state_dict[weight_orig_key]\n",
    "\n",
    "#             # Apply the mask: keep values in weight_orig corresponding to mask = 1, zero out others\n",
    "#             new_weights = weight_orig * weight_mask\n",
    "\n",
    "#             # Update the new_state_dict with the proper key (removing _orig)\n",
    "#             new_key = weight_orig_key.replace(\"weight_orig\", \"weight\")\n",
    "#             new_state_dict[new_key] = new_weights\n",
    "#         else:\n",
    "#             # Keep other parameters (bias, running_mean, running_var, etc.) as they are\n",
    "#             if \"weight_orig\" not in key and \"weight_mask\" not in key:\n",
    "#                 new_state_dict[key] = value\n",
    "#     return new_state_dict\n",
    "\n",
    "# new_state_dict = apply_mask_and_zero_out(state_dict)\n",
    "# torch_model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate accuracy of the pythorch model on CIFAR-100 test set\n",
    "# import torch\n",
    "# import torchvision.transforms as transforms\n",
    "# from torchvision.datasets import CIFAR100\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torch import nn\n",
    "# import numpy as np\n",
    "\n",
    "# # Load CIFAR-100 dataset\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(cifar100_nm[0], cifar100_nm[1])])\n",
    "# test_dataset = CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# # evaluate on torch_model\n",
    "# torch_model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         outputs = torch_model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# accuracy = correct / total\n",
    "# print(f\"Accuracy on CIFAR-100 test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load onnx file - dense model trained on cifar100 with resnet20 architecture\n",
    "# import onnx\n",
    "# import onnxruntime as ort\n",
    "\n",
    "# onnx_path = \"../../models/resnet20/resnet20_cifar100_dense_v2.onnx\"\n",
    "# onnx_model = onnx.load(onnx_path)\n",
    "# ort_session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# # get the input name for the model\n",
    "# input_name = ort_session.get_inputs()[0].name\n",
    "# output_name = ort_session.get_outputs\n",
    "\n",
    "# # load the image\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "\n",
    "# # Load the image\n",
    "# image = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# # Convert the image to a numpy array\n",
    "# image_np = image.numpy()\n",
    "\n",
    "# # Run the model\n",
    "# ort_inputs = {input_name: image_np}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# # Get the predicted class\n",
    "# predicted_class = np.argmax(ort_outs[0])\n",
    "# print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "# tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.7843741  -1.4789039   2.3753865   3.5402687   1.8999168  -3.2317297\n",
      "   2.7143314   0.63953024  2.6151376  -1.4918125   0.06948037  1.1175079\n",
      "  -3.8698897  -0.5297159   3.7554712   4.4577184   0.49322167  0.47873765\n",
      "  -0.8673161   9.253324   -2.5381029   0.33410478 -1.0929856  -3.568278\n",
      "  -2.3266678   0.6484118   0.5271331  -2.5334227  -2.5681252   1.016406\n",
      "  -3.968857    3.4909167   1.3832017  -0.15196204  2.0189972   0.94015527\n",
      "   0.36541107  2.5023901   4.491131   -2.931189   -1.0155636   2.521766\n",
      "   2.1847847   3.0698605  -1.908736   -0.16996153  0.75252354 -1.1392367\n",
      "   3.3628707  -0.62917477  2.9287121   2.1253362  -1.5417162  -3.2286441\n",
      "   2.4740171   1.7161465  -0.81996936  1.3826659  -2.413763    0.25392666\n",
      "  -1.7173617  -1.7794143   1.0224409  -2.70311     1.2284832   3.569923\n",
      "   2.3190382   0.7575056  -2.7425761  -3.0991342   1.2331629  -5.880378\n",
      "   0.7281624  -3.0917003   1.8738917   0.2389269  -2.4675617  -0.11519422\n",
      "  -0.6453781  -0.8296769   1.3465298  -3.8121881   0.73303056 -1.5333856\n",
      "  -0.26830685 -1.8492717  -1.1058418  -2.1134307   4.289868    2.8305826\n",
      "  -0.5931842  -1.3261147   2.2445416  -2.142495   -3.8754482  -5.634035\n",
      "  -1.7085124   0.08085093 -0.9341868  -2.2095299 ]], shape=(1, 100), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz/assets\n",
      "2024-11-05 01:28:40.839995: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2024-11-05 01:28:40.840312: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2024-11-05 01:28:40.841398: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz\n",
      "2024-11-05 01:28:40.846239: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2024-11-05 01:28:40.846245: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz\n",
      "2024-11-05 01:28:40.865756: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2024-11-05 01:28:41.006232: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/mh/wt0s4pwn1w52cl7dn_5mj92m0000gp/T/tmpaz37xdnz\n",
      "2024-11-05 01:28:41.043913: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 202518 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = keras_model\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "cifar100 = tf.keras.datasets.cifar100\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "# apply cifar100_nm to x_test\n",
    "train_images = train_images.astype('float32')\n",
    "train_images = train_images - cifar100_nm[1]\n",
    "train_images = train_images / cifar100_nm[0]\n",
    "train_labels = train_labels.astype('int32')\n",
    "test_images = test_images.astype('float32')\n",
    "test_images = test_images - cifar100_nm[1]\n",
    "test_images = test_images / cifar100_nm[0]\n",
    "test_labels = test_labels.astype('int32')\n",
    "\n",
    "\n",
    "# Compile the model (necessary for training, but for inference, itâ€™s optional)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Perform inference with a sample image from CIFAR-100\n",
    "sample_image = train_images[0:1]  # Select one sample\n",
    "sample_image = tf.convert_to_tensor(sample_image, dtype=tf.float32)\n",
    "\n",
    "# Ensure the model is in evaluation mode (no training mode needed)\n",
    "predictions = model(sample_image, training=False)  # training=False ensures evaluation mode\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "# Convert the model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert() # experimental_new_converter=False\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('../../models/resnet20/resnet20.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on CIFAR-100 test set: 66.12%\n"
     ]
    }
   ],
   "source": [
    "# compute acc of tflite model\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path='../../models/resnet20/resnet20.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on cifar100 test set\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(test_images)):\n",
    "    input_data = test_images[i:i+1]\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    pred_label = np.argmax(output_data)\n",
    "    true_label = test_labels[i]\n",
    "    if pred_label == true_label:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on CIFAR-100 test set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, 32, 32, 16)           432       ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " bn1 (BatchNormalization)    (None, 32, 32, 16)           64        ['conv1[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)             (None, 32, 32, 16)           0         ['bn1[0][0]']                 \n",
      "                                                                                                  \n",
      " layer1.0.conv1 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_38[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.0.bn1 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.0.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)             (None, 32, 32, 16)           0         ['layer1.0.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer1.0.conv2 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_39[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.0.bn2 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.0.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 32, 32, 16)           0         ['layer1.0.bn2[0][0]',        \n",
      "                                                                     're_lu_38[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)             (None, 32, 32, 16)           0         ['add_18[0][0]']              \n",
      "                                                                                                  \n",
      " layer1.1.conv1 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_40[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.1.bn1 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.1.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)             (None, 32, 32, 16)           0         ['layer1.1.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer1.1.conv2 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_41[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.1.bn2 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.1.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 32, 32, 16)           0         ['layer1.1.bn2[0][0]',        \n",
      "                                                                     're_lu_40[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)             (None, 32, 32, 16)           0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " layer1.2.conv1 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_42[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.2.bn1 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.2.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)             (None, 32, 32, 16)           0         ['layer1.2.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer1.2.conv2 (Conv2D)     (None, 32, 32, 16)           2304      ['re_lu_43[0][0]']            \n",
      "                                                                                                  \n",
      " layer1.2.bn2 (BatchNormali  (None, 32, 32, 16)           64        ['layer1.2.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, 32, 32, 16)           0         ['layer1.2.bn2[0][0]',        \n",
      "                                                                     're_lu_42[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)             (None, 32, 32, 16)           0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " layer2.0.conv1 (Conv2D)     (None, 16, 16, 32)           4608      ['re_lu_44[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.0.bn1 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.0.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)             (None, 16, 16, 32)           0         ['layer2.0.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer2.0.conv2 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_45[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.0.downsample.0 (Con  (None, 16, 16, 32)           512       ['re_lu_44[0][0]']            \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer2.0.bn2 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.0.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " layer2.0.downsample.1 (Bat  (None, 16, 16, 32)           128       ['layer2.0.downsample.0[0][0]'\n",
      " chNormalization)                                                   ]                             \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, 16, 16, 32)           0         ['layer2.0.bn2[0][0]',        \n",
      "                                                                     'layer2.0.downsample.1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)             (None, 16, 16, 32)           0         ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " layer2.1.conv1 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_46[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.1.bn1 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.1.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)             (None, 16, 16, 32)           0         ['layer2.1.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer2.1.conv2 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_47[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.1.bn2 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.1.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, 16, 16, 32)           0         ['layer2.1.bn2[0][0]',        \n",
      "                                                                     're_lu_46[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)             (None, 16, 16, 32)           0         ['add_22[0][0]']              \n",
      "                                                                                                  \n",
      " layer2.2.conv1 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_48[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.2.bn1 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.2.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)             (None, 16, 16, 32)           0         ['layer2.2.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer2.2.conv2 (Conv2D)     (None, 16, 16, 32)           9216      ['re_lu_49[0][0]']            \n",
      "                                                                                                  \n",
      " layer2.2.bn2 (BatchNormali  (None, 16, 16, 32)           128       ['layer2.2.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, 16, 16, 32)           0         ['layer2.2.bn2[0][0]',        \n",
      "                                                                     're_lu_48[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)             (None, 16, 16, 32)           0         ['add_23[0][0]']              \n",
      "                                                                                                  \n",
      " layer3.0.conv1 (Conv2D)     (None, 8, 8, 64)             18432     ['re_lu_50[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.0.bn1 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.0.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)             (None, 8, 8, 64)             0         ['layer3.0.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer3.0.conv2 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_51[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.0.downsample.0 (Con  (None, 8, 8, 64)             2048      ['re_lu_50[0][0]']            \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " layer3.0.bn2 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.0.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " layer3.0.downsample.1 (Bat  (None, 8, 8, 64)             256       ['layer3.0.downsample.0[0][0]'\n",
      " chNormalization)                                                   ]                             \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, 8, 8, 64)             0         ['layer3.0.bn2[0][0]',        \n",
      "                                                                     'layer3.0.downsample.1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)             (None, 8, 8, 64)             0         ['add_24[0][0]']              \n",
      "                                                                                                  \n",
      " layer3.1.conv1 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.1.bn1 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.1.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)             (None, 8, 8, 64)             0         ['layer3.1.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer3.1.conv2 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_53[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.1.bn2 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.1.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, 8, 8, 64)             0         ['layer3.1.bn2[0][0]',        \n",
      "                                                                     're_lu_52[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)             (None, 8, 8, 64)             0         ['add_25[0][0]']              \n",
      "                                                                                                  \n",
      " layer3.2.conv1 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_54[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.2.bn1 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.2.conv1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)             (None, 8, 8, 64)             0         ['layer3.2.bn1[0][0]']        \n",
      "                                                                                                  \n",
      " layer3.2.conv2 (Conv2D)     (None, 8, 8, 64)             36864     ['re_lu_55[0][0]']            \n",
      "                                                                                                  \n",
      " layer3.2.bn2 (BatchNormali  (None, 8, 8, 64)             256       ['layer3.2.conv2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, 8, 8, 64)             0         ['layer3.2.bn2[0][0]',        \n",
      "                                                                     're_lu_54[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)             (None, 8, 8, 64)             0         ['add_26[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 64)                   0         ['re_lu_56[0][0]']            \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " fc (Dense)                  (None, 100)                  6500      ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 279892 (1.07 MB)\n",
      "Trainable params: 278324 (1.06 MB)\n",
      "Non-trainable params: 1568 (6.12 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to .h5 file\n",
    "# model.save_weights(\"resnet20.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 7.npy and forward it to the model\n",
    "import numpy as np\n",
    "data = np.load('7.npy')\n",
    "# reshape data to 4D\n",
    "data = np.reshape(data, (1, 3,32,32))\n",
    "\n",
    "# forward the data to the model\n",
    "data = tf.convert_to_tensor(data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/zkml_bench_env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 46, 47, 48, 49}\n",
      "Add inputs:  [48, 46]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52}\n",
      "Add inputs:  [51, 49]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55}\n",
      "Add inputs:  [54, 52]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59}\n",
      "Add inputs:  [57, 58]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62}\n",
      "Add inputs:  [61, 59]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65}\n",
      "Add inputs:  [64, 62]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69}\n",
      "Add inputs:  [67, 68]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72}\n",
      "Add inputs:  [71, 69]\n",
      "True True\n",
      "{0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75}\n",
      "Add inputs:  [74, 72]\n",
      "True True\n",
      "[{'layer_type': 'Conv2D', 'inp_idxes': [0, 22, 1], 'inp_shapes': [[1, 32, 32, 3], [16, 3, 3, 3], [16]], 'out_idxes': [46], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [46, 23, 2], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [47], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [47, 24, 11], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [48], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [48, 46], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [49], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [49, 25, 3], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [50], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [50, 26, 12], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [51], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [51, 49], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [52], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [52, 27, 4], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [53], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [53, 28, 13], 'inp_shapes': [[1, 32, 32, 16], [16, 3, 3, 16], [16]], 'out_idxes': [54], 'out_shapes': [[1, 32, 32, 16]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [54, 52], 'inp_shapes': [[1, 32, 32, 16], [1, 32, 32, 16]], 'out_idxes': [55], 'out_shapes': [[1, 32, 32, 16]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [55, 29, 5], 'inp_shapes': [[1, 32, 32, 16], [32, 3, 3, 16], [32]], 'out_idxes': [56], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [56, 30, 14], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [57], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [55, 31, 15], 'inp_shapes': [[1, 32, 32, 16], [32, 1, 1, 16], [32]], 'out_idxes': [58], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [57, 58], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [59], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [59, 32, 6], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [60], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [60, 33, 16], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [61], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [61, 59], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [62], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [62, 34, 7], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [63], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [63, 35, 17], 'inp_shapes': [[1, 16, 16, 32], [32, 3, 3, 32], [32]], 'out_idxes': [64], 'out_shapes': [[1, 16, 16, 32]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [64, 62], 'inp_shapes': [[1, 16, 16, 32], [1, 16, 16, 32]], 'out_idxes': [65], 'out_shapes': [[1, 16, 16, 32]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [65, 36, 8], 'inp_shapes': [[1, 16, 16, 32], [64, 3, 3, 32], [64]], 'out_idxes': [66], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 2, 2], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [66, 37, 18], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [67], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [65, 38, 19], 'inp_shapes': [[1, 16, 16, 32], [64, 1, 1, 32], [64]], 'out_idxes': [68], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 1, 0, 2, 2], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [67, 68], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [69], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [69, 39, 9], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [70], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [70, 40, 20], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [71], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [71, 69], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [72], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [72, 41, 10], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [73], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 1, 1, 1], 'mask': []}, {'layer_type': 'Conv2D', 'inp_idxes': [73, 42, 21], 'inp_shapes': [[1, 8, 8, 64], [64, 3, 3, 64], [64]], 'out_idxes': [74], 'out_shapes': [[1, 8, 8, 64]], 'params': [0, 0, 0, 1, 1], 'mask': []}, {'layer_type': 'Add', 'inp_idxes': [74, 72], 'inp_shapes': [[1, 8, 8, 64], [1, 8, 8, 64]], 'out_idxes': [75], 'out_shapes': [[1, 8, 8, 64]], 'params': [1], 'mask': []}, {'layer_type': 'Mean', 'inp_idxes': [75, 44], 'inp_shapes': [[1, 8, 8, 64], [2]], 'out_idxes': [76], 'out_shapes': [[1, 64]], 'params': [1, 2], 'mask': []}, {'layer_type': 'FullyConnected', 'inp_idxes': [76, 45, 43], 'inp_shapes': [[1, 64], [100, 64], [100]], 'out_idxes': [77], 'out_shapes': [[1, 100]], 'params': [0], 'mask': []}]\n",
      "\n",
      "keep tensors: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76}\n",
      "skipping generated tensor: 0, b'serving_default_input_3:0'\n",
      "skipping generated tensor: 46, b'model_2/re_lu_38/Relu;model_2/bn1/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/conv1/Conv2D'\n",
      "skipping generated tensor: 47, b'model_2/re_lu_39/Relu;model_2/layer1.0.bn1/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.0.conv1/Conv2D'\n",
      "skipping generated tensor: 48, b'model_2/layer1.0.bn2/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.0.conv2/Conv2D'\n",
      "skipping generated tensor: 49, b'model_2/re_lu_40/Relu;model_2/add_18/add'\n",
      "skipping generated tensor: 50, b'model_2/re_lu_41/Relu;model_2/layer1.1.bn1/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.1.conv1/Conv2D'\n",
      "skipping generated tensor: 51, b'model_2/layer1.1.bn2/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.1.conv2/Conv2D'\n",
      "skipping generated tensor: 52, b'model_2/re_lu_42/Relu;model_2/add_19/add'\n",
      "skipping generated tensor: 53, b'model_2/re_lu_43/Relu;model_2/layer1.2.bn1/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D;model_2/layer1.2.conv1/Conv2D'\n",
      "skipping generated tensor: 54, b'model_2/layer1.2.bn2/FusedBatchNormV3;model_2/layer1.2.conv2/Conv2D'\n",
      "skipping generated tensor: 55, b'model_2/re_lu_44/Relu;model_2/add_20/add'\n",
      "skipping generated tensor: 56, b'model_2/re_lu_45/Relu;model_2/layer2.0.bn1/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.0.conv1/Conv2D'\n",
      "skipping generated tensor: 57, b'model_2/layer2.0.bn2/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.0.conv2/Conv2D'\n",
      "skipping generated tensor: 58, b'model_2/layer2.0.downsample.1/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.0.downsample.0/Conv2D'\n",
      "skipping generated tensor: 59, b'model_2/re_lu_46/Relu;model_2/add_21/add'\n",
      "skipping generated tensor: 60, b'model_2/re_lu_47/Relu;model_2/layer2.1.bn1/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.1.conv1/Conv2D'\n",
      "skipping generated tensor: 61, b'model_2/layer2.1.bn2/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.1.conv2/Conv2D'\n",
      "skipping generated tensor: 62, b'model_2/re_lu_48/Relu;model_2/add_22/add'\n",
      "skipping generated tensor: 63, b'model_2/re_lu_49/Relu;model_2/layer2.2.bn1/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D;model_2/layer2.2.conv1/Conv2D'\n",
      "skipping generated tensor: 64, b'model_2/layer2.2.bn2/FusedBatchNormV3;model_2/layer2.2.conv2/Conv2D'\n",
      "skipping generated tensor: 65, b'model_2/re_lu_50/Relu;model_2/add_23/add'\n",
      "skipping generated tensor: 66, b'model_2/re_lu_51/Relu;model_2/layer3.0.bn1/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.0.conv1/Conv2D'\n",
      "skipping generated tensor: 67, b'model_2/layer3.0.bn2/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.0.conv2/Conv2D'\n",
      "skipping generated tensor: 68, b'model_2/layer3.0.downsample.1/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.0.downsample.0/Conv2D'\n",
      "skipping generated tensor: 69, b'model_2/re_lu_52/Relu;model_2/add_24/add'\n",
      "skipping generated tensor: 70, b'model_2/re_lu_53/Relu;model_2/layer3.1.bn1/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.1.conv1/Conv2D'\n",
      "skipping generated tensor: 71, b'model_2/layer3.1.bn2/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.1.conv2/Conv2D'\n",
      "skipping generated tensor: 72, b'model_2/re_lu_54/Relu;model_2/add_25/add'\n",
      "skipping generated tensor: 73, b'model_2/re_lu_55/Relu;model_2/layer3.2.bn1/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D;model_2/layer3.2.conv1/Conv2D'\n",
      "skipping generated tensor: 74, b'model_2/layer3.2.bn2/FusedBatchNormV3;model_2/layer3.2.conv2/Conv2D'\n",
      "skipping generated tensor: 75, b'model_2/re_lu_56/Relu;model_2/add_26/add'\n",
      "skipping generated tensor: 76, b'model_2/global_average_pooling2d_2/Mean'\n",
      "\n",
      "{'layer_type': 'FullyConnected', 'inp_idxes': [76, 45, 43], 'inp_shapes': [[1, 64], [100, 64], [100]], 'out_idxes': [77], 'out_shapes': [[1, 100]], 'params': [0], 'mask': []}\n",
      "dict_keys(['global_sf', 'k', 'num_cols', 'num_random', 'inp_idxes', 'out_idxes', 'layers', 'tensors', 'use_selectors', 'commit_before', 'commit_after'])\n",
      "[77]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/converter.py', '--model', '../../models/resnet20/resnet20.tflite', '--model_output', 'converted_model_new.msgpack', '--config_output', 'config_new.msgpack', '--scale_factor', '4096', '--k', '21', '--num_cols', '128', '--num_randoms', '262144'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert model\n",
    "# !python ./tools/converter.py --model ./model.tflite --model_output converted_model_new.msgpack --config_output config_new.msgpack --scale_factor 512 --k 20 --num_cols 20 --num_randoms 4096\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/converter.py', \n",
    "    '--model', '../../models/resnet20/resnet20.tflite',\n",
    "    # '--model', '../../models/resnet20/resnet20_cifar100_dense.tflite',\n",
    "    '--model_output', 'converted_model_new.msgpack',\n",
    "    '--config_output', 'config_new.msgpack',\n",
    "    '--scale_factor', '4096',\n",
    "    '--k', '21',\n",
    "    '--num_cols', '128',\n",
    "    # '--num_randoms', '16384'\n",
    "    '--num_randoms', '262144'\n",
    "]\n",
    "\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './tools/input_converter.py', '--model_config', 'converted_model_new.msgpack', '--inputs', '7.npy', '--output', 'example_inp_new.msgpack'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert input\n",
    "import subprocess\n",
    "\n",
    "# !python ./tools/input_converter.py --model_config converted_model_new.msgpack --inputs 7.npy --output example_inp_new.msgpack\n",
    "\n",
    "# Command to run\n",
    "command = [\n",
    "    'python', './tools/input_converter.py', \n",
    "    '--model_config', 'converted_model_new.msgpack',\n",
    "    '--inputs', '7.npy',\n",
    "    '--output', 'example_inp_new.msgpack'\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command_dir:  ./bin/m1_mac/\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "command_dir = './bin/m1_mac/' if platform.processor() == \"arm\" else './bin/'\n",
    "print(\"command_dir: \", command_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./bin/test_circuit ./converted_model_new.msgpack ./example_inp_new.msgpack kzg\n",
    "\n",
    "\n",
    "# Command to run\n",
    "command = [command_dir + 'test_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m command \u001b[38;5;241m=\u001b[39m [command_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_circuit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconverted_model_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample_inp_new.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkzg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Run the command\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:507\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    509\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1126\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1126\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1189\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1917\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1917\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1875\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1875\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1879\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Command to run\n",
    "command = [command_dir + 'time_circuit', 'converted_model_new.msgpack', 'example_inp_new.msgpack', 'kzg']\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !onnx2tf -i ./model_simplified.onnx -o model_tf --not_use_onnxsim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx_tf.backend import prepare\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.python.framework import convert_to_constants\n",
    "# import numpy as np\n",
    "\n",
    "# # Step 1: Convert ONNX model to TensorFlow\n",
    "# def onnx_to_tf(onnx_model_path, output_tf_model_path):\n",
    "#     onnx_model = onnx.load(onnx_model_path)\n",
    "#     tf_rep = prepare(onnx_model)\n",
    "#     tf_rep.export_graph(output_tf_model_path)\n",
    "#     print(f\"ONNX model converted to TensorFlow and saved at {output_tf_model_path}\")\n",
    "\n",
    "# # Step 2: Modify the TensorFlow computation graph\n",
    "# def modify_tf_model_graph(concrete_func):\n",
    "#     frozen_func = convert_to_constants.convert_variables_to_constants_v2(concrete_func)\n",
    "#     frozen_func.graph.as_graph_def()\n",
    "\n",
    "#     modified_graph_def = tf.compat.v1.GraphDef()\n",
    "\n",
    "#     for node in frozen_func.graph.as_graph_def().node:\n",
    "#         if \"Dense\" in node.op:  # Check for fully connected layer\n",
    "#             # Find the input to the dense layer and check its shape\n",
    "#             input_node = node.input[0]\n",
    "            \n",
    "#             # Get the input tensor shape properly using frozen_func inputs\n",
    "#             input_tensor = None\n",
    "#             for input_tensor_item in frozen_func.inputs:\n",
    "#                 if input_node in input_tensor_item.name or input_tensor_item.name.startswith(input_node):\n",
    "#                     input_tensor = input_tensor_item\n",
    "#                     break\n",
    "\n",
    "#             if input_tensor is None:\n",
    "#                 print(f\"Input tensor {input_node} not found in frozen_func.inputs. Skipping node {node.name}.\")\n",
    "#                 continue\n",
    "            \n",
    "#             input_shape = input_tensor.shape.as_list()\n",
    "\n",
    "#             if len(input_shape) > 2:\n",
    "#                 print(f\"Input to {node.name} is more than 2D: {input_shape}, adding Flatten.\")\n",
    "#                 # Modify the graph to add a Flatten operation before this node\n",
    "#                 flatten_node = tf.raw_ops.Flatten(input=input_node, name=f\"{node.name}_flatten\")\n",
    "#                 node.input[0] = flatten_node.name  # Redirect input to the Flatten node\n",
    "        \n",
    "#         modified_graph_def.node.extend([node])\n",
    "\n",
    "#     return modified_graph_def\n",
    "\n",
    "# # Step 3: Convert TensorFlow Model to TFLite\n",
    "# def tf_to_tflite(concrete_func, output_tflite_path):\n",
    "#     converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
    "#     tflite_model = converter.convert()\n",
    "\n",
    "#     # Save the TFLite model\n",
    "#     with open(output_tflite_path, 'wb') as f:\n",
    "#         f.write(tflite_model)\n",
    "#     print(f\"TensorFlow model converted to TFLite and saved at {output_tflite_path}\")\n",
    "\n",
    "# # Main function to handle everything\n",
    "# def convert_onnx_to_tflite(onnx_model_path, output_tf_model_path, output_tflite_path):\n",
    "#     # Step 1: Convert ONNX to TensorFlow\n",
    "#     onnx_to_tf(onnx_model_path, output_tf_model_path)\n",
    "\n",
    "#     # Step 2: Load the converted TensorFlow SavedModel\n",
    "#     loaded_model = tf.saved_model.load(output_tf_model_path)\n",
    "    \n",
    "#     # Get the concrete function from the loaded model\n",
    "#     concrete_func = loaded_model.signatures['serving_default']\n",
    "\n",
    "#     # Step 3: Modify the TensorFlow computation graph (add reshape/flatten layers if needed)\n",
    "#     modified_graph = modify_tf_model_graph(concrete_func)\n",
    "\n",
    "#     # Step 4: Convert the modified TensorFlow model to TFLite\n",
    "#     tf_to_tflite(concrete_func, output_tflite_path)\n",
    "\n",
    "# # Example usage\n",
    "# onnx_model_path = 'resnet20_cifar100_dense.onnx'  # Replace with your ONNX model path\n",
    "# output_tf_model_path = 'converted_model'  # Path to save the converted TensorFlow model\n",
    "# output_tflite_path = 'final_model.tflite'  # Path to save the TFLite model\n",
    "\n",
    "# convert_onnx_to_tflite(onnx_model_path, output_tf_model_path, output_tflite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# model_path = '/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/frameworks/zkml/tmp/inputs/unpruned.pth.tar'\n",
    "# model_state_dict = torch.load(model_path)  # Load your PyTorch model\n",
    "# model \n",
    "\n",
    "# # Export to ONNX with opset version 10\n",
    "# dummy_input = torch.randn(1, 3, 224, 224)  # Adjust to your input size\n",
    "# torch.onnx.export(model, dummy_input, \"model_opset_10.onnx\", opset_version=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx import helper\n",
    "# from onnx import TensorProto\n",
    "\n",
    "# # Load the ONNX model\n",
    "# model = onnx.load('./tmp/inputs/model_simplified.onnx')\n",
    "\n",
    "# # Find the Reshape node\n",
    "# reshape_node = None\n",
    "# for node in model.graph.node:\n",
    "#     if node.op_type == 'Reshape':\n",
    "#         reshape_node = node\n",
    "#         break\n",
    "\n",
    "# if reshape_node is None:\n",
    "#     raise ValueError(\"Reshape node not found in the model.\")\n",
    "\n",
    "# # Create an Identity node after the Reshape\n",
    "# identity_output = reshape_node.output[0] + '_identity'\n",
    "# identity_node = helper.make_node(\n",
    "#     'Identity',\n",
    "#     inputs=[reshape_node.output[0]],\n",
    "#     outputs=[identity_output],\n",
    "#     name='Identity_after_Reshape'\n",
    "# )\n",
    "\n",
    "# # Update the next node to use the output of the Identity node\n",
    "# for node in model.graph.node:\n",
    "#     for idx, inp in enumerate(node.input):\n",
    "#         if inp == reshape_node.output[0]:\n",
    "#             node.input[idx] = identity_output\n",
    "\n",
    "# # Add the Identity node to the graph\n",
    "# model.graph.node.append(identity_node)\n",
    "\n",
    "# # Save the modified model\n",
    "# onnx.save(model, 'modified_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx import version_converter\n",
    "\n",
    "# # Load the ONNX model\n",
    "# onnx_model_path = '/Users/mm6322/Phd research/ZKML-Benchmark/ZKML-Benchmark/frameworks/zkml/tmp/inputs/resnet20_cifar100_dense.onnx'  # Replace with your ONNX file path\n",
    "# onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "# # Check the current opset version of the model\n",
    "# current_opset = onnx_model.opset_import[0].version\n",
    "# print(f\"Current opset version: {current_opset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Convert the ONNX model to opset version 10\n",
    "# converted_model = version_converter.convert_version(onnx_model, 14)\n",
    "\n",
    "# # Save the converted model\n",
    "# converted_model_path = 'model_opset_10.onnx'  # Replace with your desired output path\n",
    "# onnx.save(converted_model, converted_model_path)\n",
    "\n",
    "# print(f\"Model saved with opset version 10 at {converted_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Load the TensorFlow SavedModel\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(\"model_tf\")\n",
    "\n",
    "# # (Optional) Enable optimizations\n",
    "# # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# # Convert the model\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the TFLite model\n",
    "# with open(\"model.tflite\", \"wb\") as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from onnx_tf.backend import prepare\n",
    "# import onnx\n",
    "\n",
    "# # Load the ONNX model\n",
    "# onnx_model = onnx.load(\"./tmp/inputs/resnet20_cifar_dense.onnx\")\n",
    "\n",
    "# # Convert the ONNX model to TensorFlow\n",
    "# tf_rep = prepare(onnx_model)\n",
    "\n",
    "# # Export the TensorFlow model\n",
    "# tf_rep.export_graph(\"model_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# from onnx_tf.backend import prepare\n",
    "# import tensorflow as tf\n",
    "# import os\n",
    "\n",
    "# # Step 1: Load the ONNX model\n",
    "# onnx_model_path = './tmp/inputs/resnet20_cifar_dense.onnx' # Replace with your ONNX model path\n",
    "# onnx_model = onnx.load(onnx_model_path)\n",
    "# print(\"ONNX model loaded successfully.\")\n",
    "\n",
    "# # Step 2: Convert ONNX model to TensorFlow SavedModel\n",
    "# print(\"Converting ONNX model to TensorFlow format...\")\n",
    "# tf_rep = prepare(onnx_model)\n",
    "\n",
    "# # Define the path to save the TensorFlow SavedModel\n",
    "# tf_model_path = 'saved_model'\n",
    "# if not os.path.exists(tf_model_path):\n",
    "#     os.makedirs(tf_model_path)\n",
    "\n",
    "# # Export the TensorFlow model\n",
    "# tf_rep.export_graph(tf_model_path)\n",
    "# print(f\"TensorFlow SavedModel exported to {tf_model_path}.\")\n",
    "\n",
    "# # Step 3: Convert TensorFlow SavedModel to TFLite model\n",
    "# print(\"Converting TensorFlow SavedModel to TFLite format...\")\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "\n",
    "# # Optional: Set optimization flags (e.g., for quantization)\n",
    "# # converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# # Perform the conversion\n",
    "# tflite_model = converter.convert()\n",
    "# print(\"Conversion to TFLite format completed.\")\n",
    "\n",
    "# # Step 4: Save the TFLite model\n",
    "# tflite_model_path = 'model.tflite'  # Replace with your desired TFLite model path\n",
    "# with open(tflite_model_path, 'wb') as f:\n",
    "#     f.write(tflite_model)\n",
    "# print(f\"TFLite model saved to {tflite_model_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zkml_bench_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
